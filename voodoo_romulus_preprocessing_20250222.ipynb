{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+fnTIp/jOAPSuTCv0YaLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/voodoo_romulus_preprocessing_20250222.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess data for Romulus gel sets"
      ],
      "metadata": {
        "id": "5mfO6FxsKpi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Upload input files to /content/daily"
      ],
      "metadata": {
        "id": "bO_dTio-K0TL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj3BV4XVq5C-",
        "outputId": "174aeeba-68f5-43bd-86fc-15143f89691d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed XLY successfully\n",
            "Processed XLB successfully\n",
            "Processed VOO successfully\n",
            "Processed XLU successfully\n",
            "Processed VTI successfully\n",
            "Processed XLV successfully\n",
            "Processed XLF successfully\n",
            "Processed UVXY successfully\n",
            "Processed XLP successfully\n",
            "Processed XLI successfully\n",
            "Processed XLE successfully\n",
            "Processed USO successfully\n",
            "Processed XLK successfully\n",
            "\n",
            "Processing complete!\n"
          ]
        }
      ],
      "source": [
        "###hack program that preloads prior parent fields to work around issue in romulus\n",
        "###only supports W and ME\n",
        "###export does not label which parent it is--easy fix BUT it requires changes elsewhere, so for later\n",
        "###second cell exports a zip\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.child_period = 'D'  # Fixed for now\n",
        "        self.parent_period = 'ME'\n",
        "        if self.parent_period not in ['W', 'ME']:\n",
        "            raise ValueError(\"Parent period must be W or ME\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('/content/gelset_prep', exist_ok=True)\n",
        "\n",
        "def load_daily_data(ticker):\n",
        "    \"\"\"Load daily data from the input file\"\"\"\n",
        "    file_path = f'/content/daily/{ticker}_daily.csv'\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['date'] = pd.to_datetime(df['Date'])  # Keep original Date column for now\n",
        "    return df[['date', 'Open', 'High', 'Low', 'Close']]\n",
        "\n",
        "def create_parent_labels(df, parent_period):\n",
        "    \"\"\"Create parent period labels\"\"\"\n",
        "    if parent_period == 'ME':\n",
        "        # Monthly format YYYY/MM\n",
        "        df['parent'] = df['date'].dt.strftime('%Y/%m')\n",
        "    else:  # Weekly\n",
        "        # Get the year and week number of the first day of each week\n",
        "        df['temp_week'] = df['date'].dt.strftime('%Y-%U')\n",
        "        first_dates = df.groupby('temp_week')['date'].transform('first')\n",
        "        df['parent'] = first_dates.dt.strftime('%Y/%U')\n",
        "        df.drop('temp_week', axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "def add_sequence(df):\n",
        "    \"\"\"Add sequence numbers that restart at 1 for each parent period\"\"\"\n",
        "    df['sequence'] = df.groupby('parent').cumcount() + 1\n",
        "    return df\n",
        "\n",
        "def calculate_parent_values(df):\n",
        "    \"\"\"Calculate parent period OHLC values\"\"\"\n",
        "    parent_values = df.groupby('parent').agg({\n",
        "        'High': 'max',\n",
        "        'Low': 'min',\n",
        "        'Close': 'last'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Shift parent values forward one period\n",
        "    parent_values['next_parent'] = parent_values['parent'].shift(-1)\n",
        "    parent_values = parent_values.rename(columns={\n",
        "        'High': 'pph',\n",
        "        'Low': 'ppl',\n",
        "        'Close': 'ppc'\n",
        "    })\n",
        "    return parent_values\n",
        "\n",
        "def process_ticker(ticker, config):\n",
        "    \"\"\"Process a single ticker\"\"\"\n",
        "    try:\n",
        "        # Load and process data\n",
        "        df = load_daily_data(ticker)\n",
        "\n",
        "        # Create parent labels\n",
        "        df = create_parent_labels(df, config.parent_period)\n",
        "\n",
        "        # Add sequence numbers\n",
        "        df = add_sequence(df)\n",
        "\n",
        "        # Calculate parent values\n",
        "        parent_values = calculate_parent_values(df)\n",
        "\n",
        "        # Merge parent values back to daily data\n",
        "        df = pd.merge(df, parent_values[['next_parent', 'pph', 'ppl', 'ppc']],\n",
        "                     left_on='parent', right_on='next_parent', how='left')\n",
        "\n",
        "        # Clean up and rename columns\n",
        "        df = df[[\n",
        "            'date', 'Open', 'High', 'Low', 'Close',\n",
        "            'parent', 'sequence', 'pph', 'ppl', 'ppc'\n",
        "        ]].rename(columns={\n",
        "            'Open': 'open',\n",
        "            'High': 'high',\n",
        "            'Low': 'low',\n",
        "            'Close': 'close'\n",
        "        })\n",
        "\n",
        "        # Remove rows with any missing values\n",
        "        df = df.dropna()\n",
        "\n",
        "        # Save to output directory\n",
        "        output_path = f'/content/gelset_prep/{ticker}_D.csv'\n",
        "        df.to_csv(output_path, index=False)\n",
        "        print(f\"Processed {ticker} successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {ticker}: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    # Initialize configuration\n",
        "    config = Config()\n",
        "\n",
        "    # Get list of tickers from daily directory\n",
        "    daily_files = [f.split('_')[0] for f in os.listdir('/content/daily') if f.endswith('_daily.csv')]\n",
        "\n",
        "    # Process each ticker\n",
        "    for ticker in daily_files:\n",
        "        process_ticker(ticker, config)\n",
        "\n",
        "    print(\"\\nProcessing complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zip_and_download(source_dir, period):\n",
        "    # Count files\n",
        "    file_count = len([name for name in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, name))])\n",
        "    print(f\"Found {file_count} gelset prep files\")\n",
        "\n",
        "    # Create zip file\n",
        "    zip_filename = f'gelset_prep_files.zip'\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for file in os.listdir(source_dir):\n",
        "            file_path = os.path.join(source_dir, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                zipf.write(file_path, arcname=file)\n",
        "\n",
        "    # Download zip file\n",
        "    files.download(zip_filename)\n",
        "    print(f\"Downloaded {zip_filename}\")\n",
        "\n",
        "# Create and download zip\n",
        "print(\"\\nCreating and downloading zip file...\\n\")\n",
        "zip_and_download('/content/gelset_prep', 'gelset_prep')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Vu_Kn_m7rTUP",
        "outputId": "e715bd31-297a-4f6e-aaea-56cc2b383656"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating and downloading zip file...\n",
            "\n",
            "Found 13 gelset prep files\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a4e8b2cb-0738-4f35-9399-ffb869ce13c9\", \"gelset_prep_files.zip\", 9372392)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded gelset_prep_files.zip\n"
          ]
        }
      ]
    }
  ]
}