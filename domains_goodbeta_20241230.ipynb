{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME//OJ8v1prQTZF+eIszbO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/domains_goodbeta_20241230.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Domains"
      ],
      "metadata": {
        "id": "T01VFbnq9E9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "1.   Determine rolling ranges up to N depth.\n",
        "2.   Identify domains established with a rolling range fails to expand.\n",
        "3.   Assign a domain type to each domain: primary, nested, inside.\n",
        "4.   Assign \"true\" domains by rolling range duration.\n",
        "5.   Track time-to-expand (TTE) and continuation.\n"
      ],
      "metadata": {
        "id": "RG1i3cpr9Kdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional\n",
        "import logging\n",
        "\n",
        "# Configuration settings\n",
        "INPUT_DIRECTORY = '/content/input'  # Set your input directory path here\n",
        "FILE_FORMAT = '{TICKER}_{PERIOD}.csv'    # Expected format of input files\n",
        "VALID_PERIODS = ['D', 'W', 'M', 'Q', 'Y']  # Valid period values\n",
        "DOMAIN_DEPTH = 12  # Set your desired depth\n",
        "DOMAIN_PRIMARY_CHECK_DURATION = 20\n",
        "FIRST_EXPANSION_DISTANCE = 6\n",
        "SECOND_EXPANSION_DISTANCE = 12\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class Domain:\n",
        "    domain_id: int\n",
        "    ticker: str\n",
        "    domain_rolling_range_duration: int\n",
        "    domain_captive_date: str\n",
        "    domain_row: int\n",
        "    domain_forecast_bars: int\n",
        "    domain_type: int\n",
        "    domain_open: float\n",
        "    domain_high: float\n",
        "    domain_low: float\n",
        "    domain_close_original: float\n",
        "    domain_close_first_captive: float\n",
        "    domain_range: float\n",
        "    domain_percentr_original: float\n",
        "    domain_bias_dir_original: int  # 1=Up, 2=Down\n",
        "    domain_expansion_dir: Optional[int] = None  # 1=Up, 2=Down\n",
        "    domain_bias_ftt: Optional[int] = None\n",
        "    first_expansion_reu: Optional[float] = None\n",
        "    first_expansion_red: Optional[float] = None\n",
        "    second_expansion_reu: Optional[float] = None\n",
        "    second_expansion_red: Optional[float] = None\n",
        "    domain_captive_count: int = 1\n",
        "    domain_captive_high: float = None\n",
        "    domain_captive_low: float = None\n",
        "    domain_percentr_active: float = None\n",
        "    domain_bias_active: int = None\n",
        "    domain_close_last: float = None\n",
        "    domain_true_flag: int = None\n",
        "    domain_true_duration: Optional[int] = None\n",
        "    status: str = 'open'\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.domain_captive_high is None:\n",
        "            self.domain_captive_high = float('-inf')\n",
        "        if self.domain_captive_low is None:\n",
        "            self.domain_captive_low = float('inf')\n",
        "\n",
        "class DomainProcessor:\n",
        "    def __init__(self,\n",
        "                 domain_depth: int = DOMAIN_DEPTH,\n",
        "                 domain_primary_check_duration: int = DOMAIN_PRIMARY_CHECK_DURATION,\n",
        "                 first_expansion_distance: int = FIRST_EXPANSION_DISTANCE,\n",
        "                 second_expansion_distance: int = SECOND_EXPANSION_DISTANCE):\n",
        "        self.domain_depth = domain_depth\n",
        "        self.domain_primary_check_duration = domain_primary_check_duration\n",
        "        self.first_expansion_distance = first_expansion_distance\n",
        "        self.second_expansion_distance = second_expansion_distance\n",
        "        self.domain_counter = 100000\n",
        "        self.domains: List[Domain] = []\n",
        "        self.ticker = None\n",
        "\n",
        "    def process_file(self, filepath: str) -> pd.DataFrame:\n",
        "        \"\"\"Process a single input file and return domains DataFrame.\"\"\"\n",
        "        try:\n",
        "            # Extract ticker from filepath\n",
        "            filename = os.path.basename(filepath)\n",
        "            self.ticker = filename.replace('.csv', '').split('_')[0]\n",
        "\n",
        "            df = pd.read_csv(filepath)\n",
        "            required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "            if not all(col in df.columns for col in required_cols):\n",
        "                raise ValueError(f\"Missing required columns. Required: {required_cols}\")\n",
        "\n",
        "            df.columns = df.columns.str.lower()\n",
        "            df['row_num'] = range(1, len(df) + 1)\n",
        "\n",
        "            for duration in range(1, self.domain_depth + 1):\n",
        "                self._process_rolling_range(df, duration)\n",
        "\n",
        "            self._reduce_overlapping_domains()\n",
        "\n",
        "            domains_df = pd.DataFrame([vars(d) for d in self.domains])\n",
        "            return domains_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _process_rolling_range(self, df: pd.DataFrame, duration: int):\n",
        "        total_rows = len(df)\n",
        "\n",
        "        for i in range(duration, total_rows):\n",
        "            rolling_range = df.iloc[i-duration:i]\n",
        "            current_bar = df.iloc[i]\n",
        "\n",
        "            rolling_high = rolling_range['high'].max()\n",
        "            rolling_low = rolling_range['low'].min()\n",
        "            rolling_open = rolling_range.iloc[0]['open']\n",
        "            rolling_close = rolling_range.iloc[-1]['close']\n",
        "\n",
        "            if (current_bar['high'] <= rolling_high and\n",
        "                current_bar['low'] >= rolling_low):\n",
        "\n",
        "                domain_type = self._determine_domain_type(df.iloc[i]['row_num'], duration)\n",
        "                forecast_bars = total_rows - i - 1\n",
        "\n",
        "                new_domain = Domain(\n",
        "                    domain_id=self.domain_counter,\n",
        "                    ticker=self.ticker,\n",
        "                    domain_rolling_range_duration=duration,\n",
        "                    domain_captive_date=str(current_bar['date']),\n",
        "                    domain_row=current_bar['row_num'],\n",
        "                    domain_forecast_bars=forecast_bars,\n",
        "                    domain_type=domain_type,\n",
        "                    domain_open=rolling_open,\n",
        "                    domain_high=rolling_high,\n",
        "                    domain_low=rolling_low,\n",
        "                    domain_close_original=rolling_close,\n",
        "                    domain_close_first_captive=current_bar['close'],\n",
        "                    domain_range=rolling_high - rolling_low,\n",
        "                    domain_percentr_original=(rolling_close - rolling_low) / (rolling_high - rolling_low),\n",
        "                    domain_bias_dir_original=1 if (rolling_close - rolling_low) / (rolling_high - rolling_low) >= 0.5 else 2,\n",
        "                )\n",
        "\n",
        "                self.domains.append(new_domain)\n",
        "                self.domain_counter += 1\n",
        "\n",
        "            self._update_open_domains(df, current_bar, i, duration)\n",
        "\n",
        "    def _determine_domain_type(self, current_row: int, duration: int) -> int:\n",
        "        \"\"\"Determine domain type (1=Primary, 2=Nested, 3=Inside).\"\"\"\n",
        "        relevant_domains = [d for d in self.domains\n",
        "                          if d.status == 'open' and\n",
        "                          d.domain_rolling_range_duration == duration and\n",
        "                          current_row - d.domain_row <= self.domain_primary_check_duration]\n",
        "\n",
        "        if not relevant_domains:\n",
        "            return 1  # Primary\n",
        "\n",
        "        last_domain = relevant_domains[-1]\n",
        "        row_diff = current_row - last_domain.domain_row\n",
        "\n",
        "        if row_diff == 1:\n",
        "            return 3  # Inside\n",
        "\n",
        "        # Check if nested within any primary domain\n",
        "        primary_domains = [d for d in relevant_domains if d.domain_type == 1]\n",
        "        for domain in primary_domains:\n",
        "            if (domain.domain_high >= last_domain.domain_high and\n",
        "                domain.domain_low <= last_domain.domain_low):\n",
        "                return 2  # Nested\n",
        "\n",
        "        return 1  # Primary\n",
        "\n",
        "    def _update_open_domains(self, df: pd.DataFrame, current_bar: pd.Series,\n",
        "                           current_idx: int, duration: int):\n",
        "        \"\"\"Update metrics for open domains and calculate expansions.\"\"\"\n",
        "        for domain in [d for d in self.domains if d.status == 'open' and\n",
        "                      d.domain_rolling_range_duration == duration]:\n",
        "\n",
        "            # Check if domain is expanded\n",
        "            if (current_bar['high'] > domain.domain_high or\n",
        "                current_bar['low'] < domain.domain_low):\n",
        "\n",
        "                domain.status = 'closed'\n",
        "                domain.domain_expansion_dir = 1 if current_bar['high'] > domain.domain_high else 2\n",
        "                domain.domain_bias_ftt = 1 if domain.domain_expansion_dir == domain.domain_bias_dir_original else 0\n",
        "\n",
        "                # Calculate expansion metrics if enough forecast bars available\n",
        "                if domain.domain_forecast_bars >= max(self.first_expansion_distance,\n",
        "                                                    self.second_expansion_distance):\n",
        "                    self._calculate_expansions(df, domain, current_idx)\n",
        "            else:\n",
        "                # Update captive metrics\n",
        "                domain.domain_captive_count += 1\n",
        "                domain.domain_captive_high = max(domain.domain_captive_high, current_bar['high'])\n",
        "                domain.domain_captive_low = min(domain.domain_captive_low, current_bar['low'])\n",
        "                domain.domain_close_last = current_bar['close']\n",
        "                domain.domain_percentr_active = ((current_bar['close'] - domain.domain_low) /\n",
        "                                               domain.domain_range)\n",
        "                domain.domain_bias_active = 1 if domain.domain_percentr_active >= 0.5 else 2\n",
        "\n",
        "    def _calculate_expansions(self, df: pd.DataFrame, domain: Domain, current_idx: int):\n",
        "        \"\"\"Calculate first and second expansion metrics.\"\"\"\n",
        "        # First expansion window\n",
        "        first_window = df.iloc[current_idx:current_idx + self.first_expansion_distance]\n",
        "        domain.first_expansion_reu = max(0, first_window['high'].max() - domain.domain_high)\n",
        "        domain.first_expansion_red = max(0, domain.domain_low - first_window['low'].min())\n",
        "\n",
        "        # Second expansion window\n",
        "        if domain.domain_forecast_bars >= self.second_expansion_distance:\n",
        "            second_window = df.iloc[current_idx:current_idx + self.second_expansion_distance]\n",
        "            domain.second_expansion_reu = max(0, second_window['high'].max() - domain.domain_high)\n",
        "            domain.second_expansion_red = max(0, domain.domain_low - second_window['low'].min())\n",
        "\n",
        "    def _reduce_overlapping_domains(self):\n",
        "        \"\"\"Identify true domains and update related fields.\"\"\"\n",
        "        domains_by_date = {}\n",
        "        for domain in self.domains:\n",
        "            if domain.domain_captive_date not in domains_by_date:\n",
        "                domains_by_date[domain.domain_captive_date] = []\n",
        "            domains_by_date[domain.domain_captive_date].append(domain)\n",
        "\n",
        "        for date_domains in domains_by_date.values():\n",
        "            date_domains.sort(key=lambda x: x.domain_rolling_range_duration)\n",
        "\n",
        "            current_high = None\n",
        "            current_low = None\n",
        "            current_true_duration = None\n",
        "\n",
        "            for domain in date_domains:\n",
        "                if current_high is None or current_low is None:\n",
        "                    current_high = domain.domain_high\n",
        "                    current_low = domain.domain_low\n",
        "                    current_true_duration = domain.domain_rolling_range_duration\n",
        "                    domain.domain_true_flag = 1\n",
        "                elif domain.domain_high == current_high and domain.domain_low == current_low:\n",
        "                    domain.domain_true_flag = 0\n",
        "                    domain.domain_true_duration = current_true_duration\n",
        "                else:\n",
        "                    current_high = domain.domain_high\n",
        "                    current_low = domain.domain_low\n",
        "                    current_true_duration = domain.domain_rolling_range_duration\n",
        "                    domain.domain_true_flag = 1\n",
        "\n",
        "def process_input_directory(input_dir: str = INPUT_DIRECTORY,\n",
        "                          domain_depth: int = DOMAIN_DEPTH,\n",
        "                          domain_primary_check_duration: int = DOMAIN_PRIMARY_CHECK_DURATION,\n",
        "                          first_expansion_distance: int = FIRST_EXPANSION_DISTANCE,\n",
        "                          second_expansion_distance: int = SECOND_EXPANSION_DISTANCE):\n",
        "    \"\"\"Process all files in the input directory.\"\"\"\n",
        "    try:\n",
        "        os.makedirs('domain_output', exist_ok=True)\n",
        "        os.makedirs('domain_summary', exist_ok=True)\n",
        "\n",
        "        for filename in os.listdir(input_dir):\n",
        "            if filename.endswith('.csv'):\n",
        "                logger.info(f\"Processing {filename}\")\n",
        "\n",
        "                processor = DomainProcessor(\n",
        "                    domain_depth=domain_depth,\n",
        "                    domain_primary_check_duration=domain_primary_check_duration,\n",
        "                    first_expansion_distance=first_expansion_distance,\n",
        "                    second_expansion_distance=second_expansion_distance\n",
        "                )\n",
        "\n",
        "                filepath = os.path.join(input_dir, filename)\n",
        "                domains_df = processor.process_file(filepath)\n",
        "\n",
        "                ticker, temporal = filename.replace('.csv', '').split('_')\n",
        "\n",
        "                detailed_output = f\"domain_output/{ticker}_Domains_{temporal}.csv\"\n",
        "                domains_df.to_csv(detailed_output, index=False)\n",
        "\n",
        "                summary_df = create_summary(domains_df)\n",
        "                summary_output = f\"domain_summary/{ticker}_DomainSum_{temporal}.csv\"\n",
        "                summary_df.to_csv(summary_output, index=False)\n",
        "\n",
        "                logger.info(f\"Completed processing {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in process_input_directory: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def create_summary(domains_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Create summary statistics for domains.\"\"\"\n",
        "    grouped = domains_df.groupby(['domain_rolling_range_duration', 'domain_type'])\n",
        "\n",
        "    summary_data = []\n",
        "    for (duration, domain_type), group in grouped:\n",
        "        total_count = len(group)\n",
        "        follow_thru_count = group['domain_bias_ftt'].sum()\n",
        "        follow_thru_pct = (follow_thru_count / total_count * 100) if total_count > 0 else 0\n",
        "\n",
        "        summary_data.append({\n",
        "            'rolling_range_duration': duration,\n",
        "            'domain_type': domain_type,\n",
        "            'count': total_count,\n",
        "            'edge_bias_follow_count': follow_thru_count,\n",
        "            'edge_bias_follow_pct': follow_thru_pct\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        process_input_directory()\n",
        "        logger.info(f\"Completed processing all files in {INPUT_DIRECTORY}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Program terminated with error: {str(e)}\")"
      ],
      "metadata": {
        "id": "JtKpyzvy9UvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional\n",
        "import logging\n",
        "\n",
        "# Configuration settings\n",
        "INPUT_DIRECTORY = '/content/input'  # Set your input directory path here\n",
        "FILE_FORMAT = '{TICKER}_{PERIOD}.csv'    # Expected format of input files\n",
        "VALID_PERIODS = ['D', 'W', 'M', 'Q', 'Y']  # Valid period values\n",
        "RRDURATION = 4  # Set your desired rolling range duration\n",
        "DOMAIN_PRIMARY_CHECK_DURATION = 20\n",
        "FIRST_EXPANSION_DISTANCE = 6\n",
        "SECOND_EXPANSION_DISTANCE = 12\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class Domain:\n",
        "    domain_id: int\n",
        "    ticker: str\n",
        "    domain_rolling_range_duration: int\n",
        "    domain_captive_date: str\n",
        "    domain_row: int\n",
        "    domain_forecast_bars: int\n",
        "    domain_type: int\n",
        "    domain_open: float\n",
        "    domain_high: float\n",
        "    domain_low: float\n",
        "    domain_close_original: float\n",
        "    domain_close_first_captive: float\n",
        "    domain_range: float\n",
        "    domain_percentr_original: float\n",
        "    domain_bias_dir_original: int  # 1=Up, 2=Down\n",
        "    domain_expansion_dir: Optional[int] = None  # 1=Up, 2=Down\n",
        "    domain_bias_ftt: Optional[int] = None\n",
        "    first_expansion_reu: Optional[float] = None\n",
        "    first_expansion_red: Optional[float] = None\n",
        "    second_expansion_reu: Optional[float] = None\n",
        "    second_expansion_red: Optional[float] = None\n",
        "    domain_captive_count: int = 1\n",
        "    domain_captive_high: float = None\n",
        "    domain_captive_low: float = None\n",
        "    domain_percentr_active: float = None\n",
        "    domain_bias_active: int = None\n",
        "    domain_close_last: float = None\n",
        "    domain_true_flag: int = None\n",
        "    domain_true_duration: Optional[int] = None\n",
        "    status: str = 'open'\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.domain_captive_high is None:\n",
        "            self.domain_captive_high = float('-inf')\n",
        "        if self.domain_captive_low is None:\n",
        "            self.domain_captive_low = float('inf')\n",
        "\n",
        "class DomainProcessor:\n",
        "    def __init__(self,\n",
        "                 rrduration: int = RRDURATION,\n",
        "                 domain_primary_check_duration: int = DOMAIN_PRIMARY_CHECK_DURATION,\n",
        "                 first_expansion_distance: int = FIRST_EXPANSION_DISTANCE,\n",
        "                 second_expansion_distance: int = SECOND_EXPANSION_DISTANCE):\n",
        "        self.rrduration = rrduration\n",
        "        self.domain_primary_check_duration = domain_primary_check_duration\n",
        "        self.first_expansion_distance = first_expansion_distance\n",
        "        self.second_expansion_distance = second_expansion_distance\n",
        "        self.domain_counter = 100000\n",
        "        self.domains: List[Domain] = []\n",
        "        self.ticker = None\n",
        "\n",
        "    def process_file(self, filepath: str) -> pd.DataFrame:\n",
        "        \"\"\"Process a single input file and return domains DataFrame.\"\"\"\n",
        "        try:\n",
        "            # Extract ticker from filepath\n",
        "            filename = os.path.basename(filepath)\n",
        "            self.ticker = filename.replace('.csv', '').split('_')[0]\n",
        "\n",
        "            df = pd.read_csv(filepath)\n",
        "            required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "            if not all(col in df.columns for col in required_cols):\n",
        "                raise ValueError(f\"Missing required columns. Required: {required_cols}\")\n",
        "\n",
        "            df.columns = df.columns.str.lower()\n",
        "            df['row_num'] = range(1, len(df) + 1)\n",
        "\n",
        "            self._process_rolling_range(df)\n",
        "            self._reduce_overlapping_domains()\n",
        "\n",
        "            domains_df = pd.DataFrame([vars(d) for d in self.domains])\n",
        "            return domains_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _process_rolling_range(self, df: pd.DataFrame):\n",
        "        total_rows = len(df)\n",
        "        duration = self.rrduration\n",
        "\n",
        "        for i in range(duration, total_rows):\n",
        "            rolling_range = df.iloc[i-duration:i]\n",
        "            current_bar = df.iloc[i]\n",
        "\n",
        "            rolling_high = rolling_range['high'].max()\n",
        "            rolling_low = rolling_range['low'].min()\n",
        "            rolling_open = rolling_range.iloc[0]['open']\n",
        "            rolling_close = rolling_range.iloc[-1]['close']\n",
        "\n",
        "            if (current_bar['high'] <= rolling_high and\n",
        "                current_bar['low'] >= rolling_low):\n",
        "\n",
        "                domain_type = self._determine_domain_type(df.iloc[i]['row_num'])\n",
        "                forecast_bars = total_rows - i - 1\n",
        "\n",
        "                new_domain = Domain(\n",
        "                    domain_id=self.domain_counter,\n",
        "                    ticker=self.ticker,\n",
        "                    domain_rolling_range_duration=duration,\n",
        "                    domain_captive_date=str(current_bar['date']),\n",
        "                    domain_row=current_bar['row_num'],\n",
        "                    domain_forecast_bars=forecast_bars,\n",
        "                    domain_type=domain_type,\n",
        "                    domain_open=rolling_open,\n",
        "                    domain_high=rolling_high,\n",
        "                    domain_low=rolling_low,\n",
        "                    domain_close_original=rolling_close,\n",
        "                    domain_close_first_captive=current_bar['close'],\n",
        "                    domain_range=rolling_high - rolling_low,\n",
        "                    domain_percentr_original=(rolling_close - rolling_low) / (rolling_high - rolling_low),\n",
        "                    domain_bias_dir_original=1 if (rolling_close - rolling_low) / (rolling_high - rolling_low) >= 0.5 else 2,\n",
        "                )\n",
        "\n",
        "                self.domains.append(new_domain)\n",
        "                self.domain_counter += 1\n",
        "\n",
        "            self._update_open_domains(df, current_bar, i)\n",
        "\n",
        "    def _determine_domain_type(self, current_row: int) -> int:\n",
        "        \"\"\"Determine domain type (1=Primary, 2=Nested, 3=Inside).\"\"\"\n",
        "        relevant_domains = [d for d in self.domains\n",
        "                          if d.status == 'open' and\n",
        "                          current_row - d.domain_row <= self.domain_primary_check_duration]\n",
        "\n",
        "        if not relevant_domains:\n",
        "            return 1  # Primary\n",
        "\n",
        "        last_domain = relevant_domains[-1]\n",
        "        row_diff = current_row - last_domain.domain_row\n",
        "\n",
        "        if row_diff == 1:\n",
        "            return 3  # Inside\n",
        "\n",
        "        # Check if nested within any primary domain\n",
        "        primary_domains = [d for d in relevant_domains if d.domain_type == 1]\n",
        "        for domain in primary_domains:\n",
        "            if (domain.domain_high >= last_domain.domain_high and\n",
        "                domain.domain_low <= last_domain.domain_low):\n",
        "                return 2  # Nested\n",
        "\n",
        "        return 1  # Primary\n",
        "\n",
        "    def _update_open_domains(self, df: pd.DataFrame, current_bar: pd.Series,\n",
        "                           current_idx: int):\n",
        "        \"\"\"Update metrics for open domains and calculate expansions.\"\"\"\n",
        "        for domain in [d for d in self.domains if d.status == 'open']:\n",
        "            # Check if domain is expanded\n",
        "            if (current_bar['high'] > domain.domain_high or\n",
        "                current_bar['low'] < domain.domain_low):\n",
        "\n",
        "                domain.status = 'closed'\n",
        "                domain.domain_expansion_dir = 1 if current_bar['high'] > domain.domain_high else 2\n",
        "                domain.domain_bias_ftt = 1 if domain.domain_expansion_dir == domain.domain_bias_dir_original else 0\n",
        "\n",
        "                # Calculate expansion metrics if enough forecast bars available\n",
        "                if domain.domain_forecast_bars >= max(self.first_expansion_distance,\n",
        "                                                    self.second_expansion_distance):\n",
        "                    self._calculate_expansions(df, domain, current_idx)\n",
        "            else:\n",
        "                # Update captive metrics\n",
        "                domain.domain_captive_count += 1\n",
        "                domain.domain_captive_high = max(domain.domain_captive_high, current_bar['high'])\n",
        "                domain.domain_captive_low = min(domain.domain_captive_low, current_bar['low'])\n",
        "                domain.domain_close_last = current_bar['close']\n",
        "                domain.domain_percentr_active = ((current_bar['close'] - domain.domain_low) /\n",
        "                                               domain.domain_range)\n",
        "                domain.domain_bias_active = 1 if domain.domain_percentr_active >= 0.5 else 2\n",
        "\n",
        "    def _calculate_expansions(self, df: pd.DataFrame, domain: Domain, current_idx: int):\n",
        "        \"\"\"Calculate first and second expansion metrics.\"\"\"\n",
        "        # First expansion window\n",
        "        first_window = df.iloc[current_idx:current_idx + self.first_expansion_distance]\n",
        "        domain.first_expansion_reu = max(0, first_window['high'].max() - domain.domain_high)\n",
        "        domain.first_expansion_red = max(0, domain.domain_low - first_window['low'].min())\n",
        "\n",
        "        # Second expansion window\n",
        "        if domain.domain_forecast_bars >= self.second_expansion_distance:\n",
        "            second_window = df.iloc[current_idx:current_idx + self.second_expansion_distance]\n",
        "            domain.second_expansion_reu = max(0, second_window['high'].max() - domain.domain_high)\n",
        "            domain.second_expansion_red = max(0, domain.domain_low - second_window['low'].min())\n",
        "\n",
        "    def _reduce_overlapping_domains(self):\n",
        "        \"\"\"Identify true domains and update related fields.\"\"\"\n",
        "        domains_by_date = {}\n",
        "        for domain in self.domains:\n",
        "            if domain.domain_captive_date not in domains_by_date:\n",
        "                domains_by_date[domain.domain_captive_date] = []\n",
        "            domains_by_date[domain.domain_captive_date].append(domain)\n",
        "\n",
        "        for date_domains in domains_by_date.values():\n",
        "            for domain in date_domains:\n",
        "                domain.domain_true_flag = 1\n",
        "                domain.domain_true_duration = self.rrduration\n",
        "\n",
        "def process_input_directory(input_dir: str = INPUT_DIRECTORY,\n",
        "                          rrduration: int = RRDURATION,\n",
        "                          domain_primary_check_duration: int = DOMAIN_PRIMARY_CHECK_DURATION,\n",
        "                          first_expansion_distance: int = FIRST_EXPANSION_DISTANCE,\n",
        "                          second_expansion_distance: int = SECOND_EXPANSION_DISTANCE):\n",
        "    \"\"\"Process all files in the input directory.\"\"\"\n",
        "    try:\n",
        "        os.makedirs('domain_output', exist_ok=True)\n",
        "        os.makedirs('domain_summary', exist_ok=True)\n",
        "\n",
        "        for filename in os.listdir(input_dir):\n",
        "            if filename.endswith('.csv'):\n",
        "                logger.info(f\"Processing {filename}\")\n",
        "\n",
        "                processor = DomainProcessor(\n",
        "                    rrduration=rrduration,\n",
        "                    domain_primary_check_duration=domain_primary_check_duration,\n",
        "                    first_expansion_distance=first_expansion_distance,\n",
        "                    second_expansion_distance=second_expansion_distance\n",
        "                )\n",
        "\n",
        "                filepath = os.path.join(input_dir, filename)\n",
        "                domains_df = processor.process_file(filepath)\n",
        "\n",
        "                ticker, period = filename.replace('.csv', '').split('_')\n",
        "\n",
        "                # Validate period\n",
        "                if period not in VALID_PERIODS:\n",
        "                    logger.error(f\"Invalid period {period} in file {filename}. Must be one of {VALID_PERIODS}\")\n",
        "                    continue\n",
        "\n",
        "                detailed_output = f\"domain_output/{ticker}_Domains_{period}.csv\"\n",
        "                domains_df.to_csv(detailed_output, index=False)\n",
        "\n",
        "                summary_df = create_summary(domains_df)\n",
        "                summary_output = f\"domain_summary/{ticker}_DomainSum_{period}.csv\"\n",
        "                summary_df.to_csv(summary_output, index=False)\n",
        "\n",
        "                logger.info(f\"Completed processing {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in process_input_directory: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def create_summary(domains_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Create summary statistics for domains.\"\"\"\n",
        "    grouped = domains_df.groupby('domain_type')\n",
        "\n",
        "    summary_data = []\n",
        "    for domain_type, group in grouped:\n",
        "        total_count = len(group)\n",
        "        follow_thru_count = group['domain_bias_ftt'].sum()\n",
        "        follow_thru_pct = (follow_thru_count / total_count * 100) if total_count > 0 else 0\n",
        "\n",
        "        summary_data.append({\n",
        "            'rolling_range_duration': RRDURATION,\n",
        "            'domain_type': domain_type,\n",
        "            'count': total_count,\n",
        "            'edge_bias_follow_count': follow_thru_count,\n",
        "            'edge_bias_follow_pct': follow_thru_pct\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        process_input_directory()\n",
        "        logger.info(f\"Completed processing all files in {INPUT_DIRECTORY}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Program terminated with error: {str(e)}\")"
      ],
      "metadata": {
        "id": "W9coa3CNSvx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjjJNZZV9PRp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class Domain:\n",
        "    domain_id: int\n",
        "    domain_rolling_range_duration: int\n",
        "    domain_captive_date: str\n",
        "    domain_row: int\n",
        "    domain_type: int\n",
        "    domain_open: float\n",
        "    domain_high: float\n",
        "    domain_low: float\n",
        "    domain_close_original: float\n",
        "    domain_range: float\n",
        "    domain_percentr_original: float\n",
        "    domain_bias_dir_original: int\n",
        "    domain_expansion_dir: Optional[int] = None\n",
        "    domain_bias_ftt: Optional[int] = None\n",
        "    domain_captive_count: int = 1\n",
        "    domain_captive_high: float = None\n",
        "    domain_captive_low: float = None\n",
        "    domain_percentr_active: float = None\n",
        "    domain_bias_active: int = None\n",
        "    domain_close_last: float = None\n",
        "    domain_true_flag: int = None\n",
        "    domain_true_duration: Optional[int] = None\n",
        "    status: str = 'open'\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.domain_captive_high is None:\n",
        "            self.domain_captive_high = float('-inf')\n",
        "        if self.domain_captive_low is None:\n",
        "            self.domain_captive_low = float('inf')\n",
        "\n",
        "class DomainProcessor:\n",
        "    def __init__(self, domain_depth: int = 12, domain_primary_check_duration: int = 20):\n",
        "        self.domain_depth = domain_depth\n",
        "        self.domain_primary_check_duration = domain_primary_check_duration\n",
        "        self.domain_counter = 100000\n",
        "        self.domains: List[Domain] = []\n",
        "\n",
        "    def process_file(self, filepath: str) -> pd.DataFrame:\n",
        "        \"\"\"Process a single input file and return domains DataFrame.\"\"\"\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "            required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "            if not all(col in df.columns for col in required_cols):\n",
        "                raise ValueError(f\"Missing required columns. Required: {required_cols}\")\n",
        "\n",
        "            # Standardize column names\n",
        "            df.columns = df.columns.str.lower()\n",
        "\n",
        "            # Add row numbers\n",
        "            df['row_num'] = range(1, len(df) + 1)\n",
        "\n",
        "            # Process each rolling range duration\n",
        "            for duration in range(1, self.domain_depth + 1):\n",
        "                self._process_rolling_range(df, duration)\n",
        "\n",
        "            # Reduce overlapping domains\n",
        "            self._reduce_overlapping_domains()\n",
        "\n",
        "            # Convert domains to DataFrame\n",
        "            domains_df = pd.DataFrame([vars(d) for d in self.domains])\n",
        "            return domains_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _process_rolling_range(self, df: pd.DataFrame, duration: int):\n",
        "        \"\"\"Process a single rolling range duration.\"\"\"\n",
        "        for i in range(duration, len(df)):\n",
        "            rolling_range = df.iloc[i-duration:i]\n",
        "            current_bar = df.iloc[i]\n",
        "\n",
        "            # Calculate rolling range metrics\n",
        "            rolling_high = rolling_range['high'].max()\n",
        "            rolling_low = rolling_range['low'].min()\n",
        "            rolling_open = rolling_range.iloc[0]['open']\n",
        "            rolling_close = rolling_range.iloc[-1]['close']\n",
        "\n",
        "            # Check if current bar is inside the rolling range\n",
        "            if (current_bar['high'] <= rolling_high and\n",
        "                current_bar['low'] >= rolling_low):\n",
        "                # Create new domain\n",
        "                domain_type = self._determine_domain_type(df.iloc[i]['row_num'], duration)\n",
        "\n",
        "                new_domain = Domain(\n",
        "                    domain_id=self.domain_counter,\n",
        "                    domain_rolling_range_duration=duration,\n",
        "                    domain_captive_date=str(current_bar['date']),\n",
        "                    domain_row=current_bar['row_num'],\n",
        "                    domain_type=domain_type,\n",
        "                    domain_open=rolling_open,\n",
        "                    domain_high=rolling_high,\n",
        "                    domain_low=rolling_low,\n",
        "                    domain_close_original=rolling_close,\n",
        "                    domain_range=rolling_high - rolling_low,\n",
        "                    domain_percentr_original=(rolling_close - rolling_low) / (rolling_high - rolling_low),\n",
        "                    domain_bias_dir_original=1 if (rolling_close - rolling_low) / (rolling_high - rolling_low) >= 0.5 else 0,\n",
        "                )\n",
        "\n",
        "                self.domains.append(new_domain)\n",
        "                self.domain_counter += 1\n",
        "\n",
        "            # Update existing open domains\n",
        "            self._update_open_domains(current_bar, duration)\n",
        "\n",
        "    def _determine_domain_type(self, current_row: int, duration: int) -> int:\n",
        "        \"\"\"Determine domain type (1=Primary, 2=Nested, 3=Inside).\"\"\"\n",
        "        relevant_domains = [d for d in self.domains\n",
        "                          if d.status == 'open' and\n",
        "                          d.domain_rolling_range_duration == duration and\n",
        "                          current_row - d.domain_row <= self.domain_primary_check_duration]\n",
        "\n",
        "        if not relevant_domains:\n",
        "            return 1  # Primary\n",
        "\n",
        "        last_domain = relevant_domains[-1]\n",
        "        row_diff = current_row - last_domain.domain_row\n",
        "\n",
        "        if row_diff == 1:\n",
        "            return 3  # Inside\n",
        "\n",
        "        # Check if nested within any primary domain\n",
        "        primary_domains = [d for d in relevant_domains if d.domain_type == 1]\n",
        "        for domain in primary_domains:\n",
        "            if (domain.domain_high >= last_domain.domain_high and\n",
        "                domain.domain_low <= last_domain.domain_low):\n",
        "                return 2  # Nested\n",
        "\n",
        "        return 1  # Primary\n",
        "\n",
        "    def _update_open_domains(self, current_bar: pd.Series, duration: int):\n",
        "        \"\"\"Update metrics for open domains.\"\"\"\n",
        "        for domain in [d for d in self.domains if d.status == 'open' and\n",
        "                      d.domain_rolling_range_duration == duration]:\n",
        "            # Check if domain is expanded\n",
        "            if (current_bar['high'] > domain.domain_high or\n",
        "                current_bar['low'] < domain.domain_low):\n",
        "                # Close domain and update expansion metrics\n",
        "                domain.status = 'closed'\n",
        "                domain.domain_expansion_dir = 1 if current_bar['high'] > domain.domain_high else 0\n",
        "                domain.domain_bias_ftt = 1 if domain.domain_expansion_dir == domain.domain_bias_dir_original else 0\n",
        "            else:\n",
        "                # Update captive metrics\n",
        "                domain.domain_captive_count += 1\n",
        "                domain.domain_captive_high = max(domain.domain_captive_high, current_bar['high'])\n",
        "                domain.domain_captive_low = min(domain.domain_captive_low, current_bar['low'])\n",
        "                domain.domain_close_last = current_bar['close']\n",
        "                domain.domain_percentr_active = ((current_bar['close'] - domain.domain_low) /\n",
        "                                               domain.domain_range)\n",
        "                domain.domain_bias_active = 1 if domain.domain_percentr_active >= 0.5 else 0\n",
        "\n",
        "    def _reduce_overlapping_domains(self):\n",
        "        \"\"\"Identify true domains and update related fields.\"\"\"\n",
        "        # Group domains by captive date\n",
        "        domains_by_date = {}\n",
        "        for domain in self.domains:\n",
        "            if domain.domain_captive_date not in domains_by_date:\n",
        "                domains_by_date[domain.domain_captive_date] = []\n",
        "            domains_by_date[domain.domain_captive_date].append(domain)\n",
        "\n",
        "        # Process each date group\n",
        "        for date, date_domains in domains_by_date.items():\n",
        "            # Sort by rolling range duration\n",
        "            date_domains.sort(key=lambda x: x.domain_rolling_range_duration)\n",
        "\n",
        "            current_high = None\n",
        "            current_low = None\n",
        "            current_true_duration = None\n",
        "\n",
        "            for domain in date_domains:\n",
        "                if current_high is None or current_low is None:\n",
        "                    # First domain in group\n",
        "                    current_high = domain.domain_high\n",
        "                    current_low = domain.domain_low\n",
        "                    current_true_duration = domain.domain_rolling_range_duration\n",
        "                    domain.domain_true_flag = 1\n",
        "                elif domain.domain_high == current_high and domain.domain_low == current_low:\n",
        "                    # Same range as previous true domain\n",
        "                    domain.domain_true_flag = 0\n",
        "                    domain.domain_true_duration = current_true_duration\n",
        "                else:\n",
        "                    # New range\n",
        "                    current_high = domain.domain_high\n",
        "                    current_low = domain.domain_low\n",
        "                    current_true_duration = domain.domain_rolling_range_duration\n",
        "                    domain.domain_true_flag = 1\n",
        "\n",
        "def process_input_directory(input_dir: str = '/content/input',\n",
        "                          domain_depth: int = 12,\n",
        "                          domain_primary_check_duration: int = 20):\n",
        "    \"\"\"Process all files in the input directory.\"\"\"\n",
        "    try:\n",
        "        # Create output directories\n",
        "        os.makedirs('domain_output', exist_ok=True)\n",
        "        os.makedirs('domain_summary', exist_ok=True)\n",
        "\n",
        "        # Process each file\n",
        "        for filename in os.listdir(input_dir):\n",
        "            if filename.endswith('.csv'):\n",
        "                logger.info(f\"Processing {filename}\")\n",
        "\n",
        "                # Initialize processor\n",
        "                processor = DomainProcessor(domain_depth, domain_primary_check_duration)\n",
        "\n",
        "                # Process file\n",
        "                filepath = os.path.join(input_dir, filename)\n",
        "                domains_df = processor.process_file(filepath)\n",
        "\n",
        "                # Extract ticker and temporal period from filename\n",
        "                ticker, temporal = filename.replace('.csv', '').split('_')\n",
        "\n",
        "                # Save detailed domain file\n",
        "                detailed_output = f\"domain_output/{ticker}_Domains_{temporal}.csv\"\n",
        "                domains_df.to_csv(detailed_output, index=False)\n",
        "\n",
        "                # Create and save summary\n",
        "                summary_df = create_summary(domains_df)\n",
        "                summary_output = f\"domain_summary/{ticker}_DomainSum_{temporal}.csv\"\n",
        "                summary_df.to_csv(summary_output, index=False)\n",
        "\n",
        "                logger.info(f\"Completed processing {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in process_input_directory: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def create_summary(domains_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Create summary statistics for domains.\"\"\"\n",
        "    # Group by rolling range duration and type\n",
        "    grouped = domains_df.groupby(['domain_rolling_range_duration', 'domain_type'])\n",
        "\n",
        "    summary_data = []\n",
        "    for (duration, domain_type), group in grouped:\n",
        "        total_count = len(group)\n",
        "        follow_thru_count = group['domain_bias_ftt'].sum()\n",
        "        follow_thru_pct = (follow_thru_count / total_count * 100) if total_count > 0 else 0\n",
        "\n",
        "        summary_data.append({\n",
        "            'rolling_range_duration': duration,\n",
        "            'domain_type': domain_type,\n",
        "            'count': total_count,\n",
        "            'edge_bias_follow_count': follow_thru_count,\n",
        "            'edge_bias_follow_pct': follow_thru_pct\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        process_input_directory()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Program terminated with error: {str(e)}\")"
      ]
    }
  ]
}