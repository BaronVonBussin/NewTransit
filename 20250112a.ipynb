{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtmIImfYNnqRrppBcsUk/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/20250112a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo0HqJbLi8D5",
        "outputId": "a1dbc631-1119-43ea-80fa-32f112c6034c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1_Flag    E1  NoE1        %E1      %NoE1\n",
            "Bias EPC                                 \n",
            "D    1    653   219  74.885321  25.114679\n",
            "     2    481   212  69.408369  30.591631\n",
            "     3    449   269  62.534819  37.465181\n",
            "     4    410   292  58.404558  41.595442\n",
            "     5    383   340  52.973721  47.026279\n",
            "U    1    853   245  77.686703  22.313297\n",
            "     2    575   230  71.428571  28.571429\n",
            "     3    485   275  63.815789  36.184211\n",
            "     4    410   302  57.584270  42.415730\n",
            "     5    367   331  52.578797  47.421203\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Load data\n",
        "file_path = '/content/input/market_data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Initialize prior bar variables\n",
        "data['PBH'] = data['high'].shift(1)\n",
        "data['PBL'] = data['low'].shift(1)\n",
        "data['PBC'] = data['close'].shift(1)\n",
        "\n",
        "data['Range'] = data['high'] - data['low']\n",
        "data['%R'] = (data['close'] - data['low']) / data['Range']\n",
        "\n",
        "# CE is now based on the PRIOR BAR %R\n",
        "data['Prior_%R'] = data['%R'].shift(1)\n",
        "data = data.dropna(subset=['PBH', 'PBL', 'PBC', 'Prior_%R'])  # Remove rows without prior bar data\n",
        "\n",
        "data['CE'] = np.where(data['Prior_%R'] >= 0.5, 1 - data['Prior_%R'], data['Prior_%R'])\n",
        "\n",
        "def calculate_epc(ce):\n",
        "    if ce == 0:\n",
        "        return 1\n",
        "    return min(max(math.ceil(ce / 0.1), 1), 5)\n",
        "\n",
        "data['EPC'] = data['CE'].apply(calculate_epc)\n",
        "\n",
        "data['Bias'] = np.where(data['CE'] == data['Prior_%R'], 'D', 'U')\n",
        "\n",
        "data['REU'] = np.where(data['high'] > data['PBH'], data['PBH'] - data['high'], 0)\n",
        "data['RED'] = np.where(data['low'] < data['PBL'], abs(data['PBL'] - data['low']), 0)\n",
        "\n",
        "data['REU_Flag'] = np.where(data['REU'] == 0, 'NoRE', 'REU')\n",
        "data['RED_Flag'] = np.where(data['RED'] == 0, 'NoRE', 'RED')\n",
        "\n",
        "data['E1'] = np.where(data['Bias'] == 'U', data['REU'], data['RED'])\n",
        "data['E2'] = np.where(data['Bias'] == 'U', data['RED'], data['REU'])\n",
        "\n",
        "data['E1_Flag'] = np.where(data['E1'] == 0, 'NoE1', 'E1')\n",
        "data['E2_Flag'] = np.where(data['E2'] == 0, 'NoE2', 'E2')\n",
        "\n",
        "# Summary statistics\n",
        "grouped = data.groupby(['Bias', 'EPC', 'E1_Flag']).size().unstack(fill_value=0)\n",
        "grouped['%E1'] = grouped['E1'] / (grouped['E1'] + grouped['NoE1']) * 100\n",
        "grouped['%NoE1'] = grouped['NoE1'] / (grouped['E1'] + grouped['NoE1']) * 100\n",
        "\n",
        "print(grouped)\n",
        "\n",
        "# Optional: Save summary to a CSV\n",
        "grouped.to_csv('/content/output/summary_stats.csv')\n"
      ]
    }
  ]
}