{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkPJmBHWgPrOgBHIhMZUYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/voodoo_gelset_20250222.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### formally fivestarstunna\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime\n",
        "from typing import Dict, Tuple, Optional, List, Any\n",
        "\n",
        "# Constants for configuration\n",
        "VALID_CHILD_PERIODS = ['D', 'W', 'M', 'Q']\n",
        "VALID_PARENT_PERIODS = ['W', 'M', 'Q', 'Y']\n",
        "DEFAULT_JOBNAME = 'gelset_20250107'\n",
        "\n",
        "class GelSetProcessor:\n",
        "    def __init__(self, input_dir=\"/content/input\",\n",
        "                 output_child_dir=\"/content/output_child\",\n",
        "                 output_parent_dir=\"/content/output_parent\",\n",
        "                 child_period=\"D\",\n",
        "                 parent_period=\"M\",\n",
        "                 jobname=\"gelset_20250107\"):\n",
        "\n",
        "        self.input_dir = input_dir\n",
        "        self.output_child_dir = output_child_dir\n",
        "        self.output_parent_dir = output_parent_dir\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "\n",
        "        # Create output directories if they don't exist\n",
        "        os.makedirs(output_child_dir, exist_ok=True)\n",
        "        os.makedirs(output_parent_dir, exist_ok=True)\n",
        "\n",
        "    def validate_input_data(self, df):\n",
        "        \"\"\"Validate input data according to spec requirements\"\"\"\n",
        "        conditions = [\n",
        "            (df['open'] > 0, \"open must be greater than 0\"),\n",
        "            (df['high'] > 0, \"high must be greater than 0\"),\n",
        "            (df['low'] > 0, \"low must be greater than 0\"),\n",
        "            (df['close'] > 0, \"close must be greater than 0\"),\n",
        "            (df['low'] <= df['close'], \"low must be less than or equal to close\"),\n",
        "            (df['close'] <= df['high'], \"close must be less than or equal to high\"),\n",
        "            (df['low'] <= df['open'], \"low must be less than or equal to open\"),\n",
        "            (df['open'] <= df['high'], \"open must be less than or equal to high\"),\n",
        "            ((df['high'] - df['low']) != 0, \"high minus low cannot be zero\")\n",
        "        ]\n",
        "\n",
        "        for condition, message in conditions:\n",
        "            if not condition.all():\n",
        "                raise ValueError(f\"Data validation failed: {message}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def process_round_one(self, data):\n",
        "        \"\"\"First Round - Establish intra-group values\"\"\"\n",
        "        # Initialize output data list\n",
        "        output_data = []\n",
        "\n",
        "        # Initialize group state tracker\n",
        "        group_state = {\n",
        "            \"current_group\": None,\n",
        "            \"intra_group_h\": None,\n",
        "            \"intra_group_l\": None,\n",
        "            \"prior_gelc\": None,\n",
        "            \"prior_gelh\": None,\n",
        "            \"prior_gell\": None,\n",
        "        }\n",
        "\n",
        "        # Process each row\n",
        "        for index, row in data.iterrows():\n",
        "            if row[\"parent\"] != group_state[\"current_group\"]:\n",
        "                # Reset group state for new group\n",
        "                group_state[\"current_group\"] = row[\"parent\"]\n",
        "                group_state[\"intra_group_h\"] = row[\"high\"]\n",
        "                group_state[\"intra_group_l\"] = row[\"low\"]\n",
        "                group_state[\"prior_gelc\"] = None\n",
        "                group_state[\"prior_gelh\"] = None\n",
        "                group_state[\"prior_gell\"] = None\n",
        "\n",
        "                range_expansion_up = 0\n",
        "                range_expansion_down = 0\n",
        "                prior_percent_r = None\n",
        "            else:\n",
        "                # Calculate range expansions\n",
        "                if row[\"high\"] > group_state[\"intra_group_h\"]:\n",
        "                    range_expansion_up = row[\"high\"] - group_state[\"intra_group_h\"]\n",
        "                else:\n",
        "                    range_expansion_up = 0\n",
        "\n",
        "                if row[\"low\"] < group_state[\"intra_group_l\"]:\n",
        "                    range_expansion_down = group_state[\"intra_group_l\"] - row[\"low\"]\n",
        "                else:\n",
        "                    range_expansion_down = 0\n",
        "\n",
        "                # Calculate prior_percent_r\n",
        "                if group_state[\"prior_gelc\"] is not None:\n",
        "                    prior_percent_r = (group_state[\"prior_gelc\"] - group_state[\"prior_gell\"]) / (\n",
        "                        group_state[\"prior_gelh\"] - group_state[\"prior_gell\"]\n",
        "                    ) if (group_state[\"prior_gelh\"] - group_state[\"prior_gell\"]) != 0 else None\n",
        "                else:\n",
        "                    prior_percent_r = None\n",
        "\n",
        "            # Update intra-group high and low\n",
        "            group_state[\"intra_group_h\"] = max(group_state[\"intra_group_h\"], row[\"high\"])\n",
        "            group_state[\"intra_group_l\"] = min(group_state[\"intra_group_l\"], row[\"low\"])\n",
        "\n",
        "            # Save current row values as prior for next row\n",
        "            group_state[\"prior_gelc\"] = row[\"close\"]\n",
        "            group_state[\"prior_gelh\"] = group_state[\"intra_group_h\"]\n",
        "            group_state[\"prior_gell\"] = group_state[\"intra_group_l\"]\n",
        "\n",
        "            # Create processed row\n",
        "            processed_row = row.to_dict()\n",
        "            processed_row.update({\n",
        "                \"gel_h\": group_state[\"intra_group_h\"],\n",
        "                \"gel_l\": group_state[\"intra_group_l\"],\n",
        "                \"reu_value\": range_expansion_up,\n",
        "                \"red_value\": range_expansion_down,\n",
        "                \"prior_percent_r\": prior_percent_r\n",
        "            })\n",
        "            output_data.append(processed_row)\n",
        "\n",
        "        return pd.DataFrame(output_data)\n",
        "\n",
        "    def process_round_two(self, data):\n",
        "        \"\"\"Second Round - Range Expansion\"\"\"\n",
        "        # Apply all the transformations from round 2\n",
        "        data[\"reu_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"reu_value\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"red_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"red_value\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"ce_percent\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (1 - row[\"prior_percent_r\"] if row[\"prior_percent_r\"] >= 0.5 else row[\"prior_percent_r\"]),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"epc\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (math.ceil((1 - row[\"prior_percent_r\"]) / 0.1) if row[\"prior_percent_r\"] >= 0.5\n",
        "                 else math.ceil(row[\"prior_percent_r\"] / 0.1)),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"epc_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (\"U\" if row[\"prior_percent_r\"] >= 0.5 else \"D\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"e1_value\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (row[\"reu_value\"] if row[\"prior_percent_r\"] >= 0.5 else row[\"red_value\"]),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"e2_value\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (row[\"reu_value\"] if row[\"prior_percent_r\"] < 0.5 else row[\"red_value\"]),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"re_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (True if row[\"reu_value\"] + row[\"red_value\"] != 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"twoway\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                ((True if row[\"red_flag\"] == True else False) if row[\"reu_flag\"] == True else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"twoway_fre_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (row[\"epc_dir\"] if row[\"twoway\"] == True else \"N\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"oneway_fre_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                ((\"D\" if row[\"red_flag\"] == True else \"N\") if row[\"reu_flag\"] == False else \"U\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"last_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (\"D\" if row[\"twoway\"] and row[\"twoway_fre_dir\"] == \"U\" else\n",
        "                 \"U\" if row[\"twoway\"] and row[\"twoway_fre_dir\"] == \"D\" else\n",
        "                 \"U\" if row[\"reu_flag\"] else\n",
        "                 \"D\" if row[\"red_flag\"] else\n",
        "                 \"N\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        return data\n",
        "\n",
        "    def process_round_three(self, data):\n",
        "        \"\"\"Third Round - RPC States\"\"\"\n",
        "        state_tracker = {\n",
        "            \"prior_dir_state\": None,\n",
        "            \"prior_last_dir\": None,\n",
        "            \"prior_gel_rpc_total\": 0,\n",
        "        }\n",
        "\n",
        "        for index, row in data.iterrows():\n",
        "            sequence = row[\"sequence\"]\n",
        "            last_dir = row[\"last_dir\"]\n",
        "            twoway = row[\"twoway\"]\n",
        "\n",
        "            if sequence == 1:\n",
        "                dir_state = None\n",
        "                gel_rpc = None\n",
        "                gel_rpc_total = None\n",
        "            else:\n",
        "                # Calculate dir_state\n",
        "                if last_dir != \"N\":\n",
        "                    dir_state = last_dir\n",
        "                else:\n",
        "                    dir_state = state_tracker[\"prior_dir_state\"]\n",
        "\n",
        "                # Calculate gel_rpc\n",
        "                if sequence == 2 and twoway:\n",
        "                    gel_rpc = 2\n",
        "                elif last_dir == \"N\":\n",
        "                    gel_rpc = 0\n",
        "                elif last_dir == state_tracker[\"prior_last_dir\"] and twoway:\n",
        "                    gel_rpc = 2\n",
        "                elif last_dir != state_tracker[\"prior_dir_state\"] and last_dir != \"N\":\n",
        "                    gel_rpc = 1\n",
        "                else:\n",
        "                    gel_rpc = 0\n",
        "\n",
        "                # Calculate gel_rpc_total\n",
        "                gel_rpc_total = (gel_rpc or 0) + (state_tracker[\"prior_gel_rpc_total\"] or 0)\n",
        "\n",
        "            # Update state tracker\n",
        "            state_tracker[\"prior_dir_state\"] = dir_state\n",
        "            state_tracker[\"prior_last_dir\"] = last_dir\n",
        "            state_tracker[\"prior_gel_rpc_total\"] = gel_rpc_total\n",
        "\n",
        "            # Update DataFrame\n",
        "            data.loc[index, \"dir_state\"] = dir_state\n",
        "            data.loc[index, \"gel_rpc\"] = gel_rpc\n",
        "            data.loc[index, \"gel_rpc_total\"] = gel_rpc_total\n",
        "\n",
        "        return data\n",
        "\n",
        "    def generate_summary(self, data, ticker):\n",
        "        \"\"\"Generate summary data for parent periods\"\"\"\n",
        "        summary_data = []\n",
        "\n",
        "        for parent, group in data.groupby(\"parent\"):\n",
        "            lookup_date = group[\"parent\"].iloc[0]\n",
        "            duration = len(group)\n",
        "            parent_high = group[\"gel_h\"].max()\n",
        "            parent_low = group[\"gel_l\"].min()\n",
        "            bar_of_h = group.loc[group[\"gel_h\"].idxmax(), \"sequence\"]\n",
        "            bar_of_l = group.loc[group[\"gel_l\"].idxmin(), \"sequence\"]\n",
        "            reu_count = group[\"reu_flag\"].sum()\n",
        "            red_count = group[\"red_flag\"].sum()\n",
        "\n",
        "            reu_first = group.loc[group[\"reu_flag\"] == True, \"sequence\"].min() if reu_count > 0 else None\n",
        "            reu_last = group.loc[group[\"reu_flag\"] == True, \"sequence\"].max() if reu_count > 0 else None\n",
        "            red_first = group.loc[group[\"red_flag\"] == True, \"sequence\"].min() if red_count > 0 else None\n",
        "            red_last = group.loc[group[\"red_flag\"] == True, \"sequence\"].max() if red_count > 0 else None\n",
        "\n",
        "            rpc_total = group[\"gel_rpc\"].sum()\n",
        "\n",
        "            summary_data.append({\n",
        "                \"ticker\": ticker,\n",
        "                \"parent\": lookup_date,\n",
        "                \"duration\": duration,\n",
        "                \"child_period\": self.child_period,\n",
        "                \"parent_period\": self.parent_period,\n",
        "                \"parent_high\": parent_high,\n",
        "                \"parent_low\": parent_low,\n",
        "                \"bar_of_h\": bar_of_h,\n",
        "                \"bar_of_l\": bar_of_l,\n",
        "                \"reu_count\": reu_count,\n",
        "                \"red_count\": red_count,\n",
        "                \"reu_first\": reu_first,\n",
        "                \"reu_last\": reu_last,\n",
        "                \"red_first\": red_first,\n",
        "                \"red_last\": red_last,\n",
        "                \"rpc_total\": rpc_total,\n",
        "                \"create_date\": datetime.now().date(),\n",
        "                \"create_time\": datetime.now().time(),\n",
        "                \"jobname\": self.jobname\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(summary_data)\n",
        "\n",
        "    def process_file(self, filename):\n",
        "        \"\"\"Process a single input file through all rounds\"\"\"\n",
        "        # Extract ticker from filename\n",
        "        ticker = filename.split('_')[0]\n",
        "\n",
        "        # Read input file\n",
        "        input_path = os.path.join(self.input_dir, filename)\n",
        "        data = pd.read_csv(input_path)\n",
        "\n",
        "        # Validate input data\n",
        "        self.validate_input_data(data)\n",
        "\n",
        "        # Add required columns\n",
        "        data['child_period'] = self.child_period\n",
        "        data['parent_period'] = self.parent_period\n",
        "        data['jobname'] = self.jobname\n",
        "\n",
        "        # Process through all rounds\n",
        "        data = self.process_round_one(data)\n",
        "        data = self.process_round_two(data)\n",
        "        data = self.process_round_three(data)\n",
        "\n",
        "        # Generate summary\n",
        "        summary_df = self.generate_summary(data, ticker)\n",
        "\n",
        "        # Export child data\n",
        "        child_filename = f\"{ticker}_{self.child_period}_gel.csv\"\n",
        "        child_path = os.path.join(self.output_child_dir, child_filename)\n",
        "        data.to_csv(child_path, index=False)\n",
        "\n",
        "        # Export summary data\n",
        "        summary_filename = f\"{ticker}_{self.parent_period}_gel.csv\"\n",
        "        summary_path = os.path.join(self.output_parent_dir, summary_filename)\n",
        "        summary_df.to_csv(summary_path, index=False)\n",
        "\n",
        "        return data, summary_df\n",
        "\n",
        "    def process_all_files(self):\n",
        "        \"\"\"Process all eligible files in the input directory\"\"\"\n",
        "        if not os.path.exists(self.input_dir):\n",
        "            raise FileNotFoundError(f\"Input directory {self.input_dir} does not exist\")\n",
        "\n",
        "        results = {}\n",
        "        processed_files = 0\n",
        "        errors = []\n",
        "\n",
        "        # Get list of all eligible files first\n",
        "        eligible_files = [f for f in os.listdir(self.input_dir)\n",
        "                         if f.endswith(f\"_{self.child_period}.csv\")]\n",
        "\n",
        "        if not eligible_files:\n",
        "            print(f\"No eligible files found with pattern *_{self.child_period}.csv\")\n",
        "            return results\n",
        "\n",
        "        print(f\"Found {len(eligible_files)} files to process\")\n",
        "\n",
        "        # Process each eligible file\n",
        "        for filename in eligible_files:\n",
        "            ticker = filename.split('_')[0]\n",
        "            try:\n",
        "                print(f\"Processing {filename}...\")\n",
        "\n",
        "                # Process the file\n",
        "                child_df, summary_df = self.process_file(filename)\n",
        "\n",
        "                # Store results\n",
        "                results[filename] = {\n",
        "                    'child_df': child_df,\n",
        "                    'summary_df': summary_df,\n",
        "                    'status': 'success',\n",
        "                    'error': None\n",
        "                }\n",
        "\n",
        "                processed_files += 1\n",
        "                print(f\"Successfully processed {filename}\")\n",
        "                print(f\"Generated {len(summary_df)} parent-level summaries for {ticker}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"Error processing {filename}: {str(e)}\"\n",
        "                print(error_msg)\n",
        "                errors.append(error_msg)\n",
        "\n",
        "                # Store error in results\n",
        "                results[filename] = {\n",
        "                    'child_df': None,\n",
        "                    'summary_df': None,\n",
        "                    'status': 'error',\n",
        "                    'error': str(e)\n",
        "                }\n",
        "\n",
        "        # Print final summary\n",
        "        print(\"\\nProcessing Complete:\")\n",
        "        print(f\"Successfully processed: {processed_files}/{len(eligible_files)} files\")\n",
        "\n",
        "        if errors:\n",
        "            print(\"\\nErrors encountered:\")\n",
        "            for error in errors:\n",
        "                print(f\"- {error}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "def validate_periods(child_period: str, parent_period: str) -> bool:\n",
        "\n",
        "    #Validate the child and parent period combinations.\n",
        "    #Args:\n",
        "    #    child_period (str): The child period code (D, W, M, Q)\n",
        "    #    parent_period (str): The parent period code (W, M, Q, Y)\n",
        "    #Returns:\n",
        "    #    bool: True if valid, raises ValueError if invalid\n",
        "    #Raises:\n",
        "    #    ValueError: If period combination is invalid\n",
        "\n",
        "    if child_period not in VALID_CHILD_PERIODS:\n",
        "        raise ValueError(f\"Invalid child_period: {child_period}. Must be one of {VALID_CHILD_PERIODS}\")\n",
        "\n",
        "    if parent_period not in VALID_PARENT_PERIODS:\n",
        "        raise ValueError(f\"Invalid parent_period: {parent_period}. Must be one of {VALID_PARENT_PERIODS}\")\n",
        "\n",
        "    # Check valid combinations\n",
        "    period_order = ['D', 'W', 'M', 'Q', 'Y']\n",
        "    child_idx = period_order.index(child_period)\n",
        "    parent_idx = period_order.index(parent_period)\n",
        "\n",
        "    if child_idx >= parent_idx:\n",
        "        raise ValueError(f\"Invalid period combination: {child_period} -> {parent_period}. Child period must be smaller than parent period.\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def setup_logging(log_dir: str = \"logs\") -> None:\n",
        "    \"\"\"Set up logging configuration.\"\"\"\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    log_file = os.path.join(log_dir, f\"gelset_processing_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "\n",
        "    # Configure logging (basic setup - can be enhanced as needed)\n",
        "    import logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file),\n",
        "            logging.StreamHandler(sys.stdout)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def process_gelset_data(\n",
        "    input_dir: str = '/content/input',\n",
        "    output_child_dir: str = '/content/output_child',\n",
        "    output_parent_dir: str = '/content/output_parent',\n",
        "    child_period: str = 'D',\n",
        "    parent_period: str = 'M',\n",
        "    jobname: str = DEFAULT_JOBNAME\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Process GelSet data with the given parameters.\n",
        "\n",
        "    Args:\n",
        "        input_dir: Directory containing input CSV files\n",
        "        output_child_dir: Directory for child output files\n",
        "        output_parent_dir: Directory for parent summary files\n",
        "        child_period: Child period code (D, W, M, Q)\n",
        "        parent_period: Parent period code (W, M, Q, Y)\n",
        "        jobname: Job name for tracking\n",
        "\n",
        "    Returns:\n",
        "        Dict containing processing results\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Validate period combination\n",
        "        validate_periods(child_period, parent_period)\n",
        "\n",
        "        # Initialize processor\n",
        "        processor = GelSetProcessor(\n",
        "            input_dir=input_dir,\n",
        "            output_child_dir=output_child_dir,\n",
        "            output_parent_dir=output_parent_dir,\n",
        "            child_period=child_period,\n",
        "            parent_period=parent_period,\n",
        "            jobname=jobname\n",
        "        )\n",
        "\n",
        "        # Process files\n",
        "        results = processor.process_all_files()\n",
        "\n",
        "        # Report results\n",
        "        success_count = sum(1 for r in results.values() if r['status'] == 'success')\n",
        "        print(f\"\\nProcessing complete. Successfully processed {success_count}/{len(results)} files.\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during processing: {str(e)}\")\n",
        "        return {'error': str(e)}\n",
        "\n",
        "# Example usage in Jupyter/Colab:\n",
        "if __name__ == \"__main__\":\n",
        "    # For notebooks, just run with default parameters\n",
        "    results = process_gelset_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eel4olAKWD9",
        "outputId": "0cb33a41-0e9f-4303-d050-dabdda2c3baf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11 files to process\n",
            "Processing C_D.csv...\n",
            "Successfully processed C_D.csv\n",
            "Generated 371 parent-level summaries for C\n",
            "Processing CAT_D.csv...\n",
            "Successfully processed CAT_D.csv\n",
            "Generated 371 parent-level summaries for CAT\n",
            "Processing BAC_D.csv...\n",
            "Successfully processed BAC_D.csv\n",
            "Generated 371 parent-level summaries for BAC\n",
            "Processing BA_D.csv...\n",
            "Successfully processed BA_D.csv\n",
            "Generated 371 parent-level summaries for BA\n",
            "Processing BABA_D.csv...\n",
            "Successfully processed BABA_D.csv\n",
            "Generated 123 parent-level summaries for BABA\n",
            "Processing AMZN_D.csv...\n",
            "Successfully processed AMZN_D.csv\n",
            "Generated 331 parent-level summaries for AMZN\n",
            "Processing BMY_D.csv...\n",
            "Successfully processed BMY_D.csv\n",
            "Generated 371 parent-level summaries for BMY\n",
            "Processing BIIB_D.csv...\n",
            "Successfully processed BIIB_D.csv\n",
            "Generated 371 parent-level summaries for BIIB\n",
            "Processing AXP_D.csv...\n",
            "Successfully processed AXP_D.csv\n",
            "Generated 371 parent-level summaries for AXP\n",
            "Processing BK_D.csv...\n",
            "Successfully processed BK_D.csv\n",
            "Generated 371 parent-level summaries for BK\n",
            "Processing BLK_D.csv...\n",
            "Successfully processed BLK_D.csv\n",
            "Generated 302 parent-level summaries for BLK\n",
            "\n",
            "Processing Complete:\n",
            "Successfully processed: 11/11 files\n",
            "\n",
            "Processing complete. Successfully processed 11/11 files.\n"
          ]
        }
      ]
    }
  ]
}