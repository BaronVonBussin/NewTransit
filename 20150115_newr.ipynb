{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyg/lBJBWaCUAiNlsYRI9t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/20150115_newr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AGIacQu-DxZ",
        "outputId": "1f2a1f91-5750-44ab-a8aa-0411e3cc0e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting GelSetProcessor...\n",
            "üìÅ Checked/Created directory: /content/output_child\n",
            "üìÅ Checked/Created directory: /content/output_parent\n",
            "üìÅ Checked/Created directory: /content/test\n",
            "üìÇ Eligible Files: ['BAC_D.csv']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüöÄ Processing Files:   0%|          | 0/1 [00:00<?, ?file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file: BAC_D.csv\n",
            "‚úÖ Data validation passed\n",
            "üîç Columns at start of Round 1: ['date', 'open', 'high', 'low', 'close', 'parent', 'sequence', 'pph', 'ppl', 'ppc', 'volume', 'child_period', 'parent_period', 'jobname']\n",
            "‚úÖ Completed Round 1\n",
            "üîé After Round 1 - Data shape: (7782, 41)\n",
            "üîç Columns at start of Round 2: ['date', 'open', 'high', 'low', 'close', 'parent', 'sequence', 'pph', 'ppl', 'ppc', 'volume', 'child_period', 'parent_period', 'jobname', 'gel_o', 'gel_h', 'gel_l', 'gel_reu_value', 'gel_red_value', 'icph', 'icpl', 'refh', 'refl', 'pp_reu', 'pp_red', 'gel_pripr', 'gel_prirange', 'bpb_reu_value', 'bpb_red_value', 'pbh', 'pbl', 'pbc', 'bpb_pripr', 'range', 'chg_h', 'chg_l', 'chg_h_percent', 'chg_l_percent', 'body', 'gap', 'island_gap']\n",
            "‚úÖ Completed Round 2\n",
            "üîé After Round 2 - Data shape: (7782, 75)\n",
            "‚úÖ Completed Round 3ip\n",
            "‚úÖ Completed Round 3pp\n",
            "üîé After Round 3bb - Data shape: (7782, 83)\n",
            "üîç Columns at start of Round 1: ['date', 'open', 'high', 'low', 'close', 'parent', 'sequence', 'pph', 'ppl', 'ppc', 'volume', 'child_period', 'parent_period', 'jobname', 'gel_o', 'gel_h', 'gel_l', 'gel_reu_value', 'gel_red_value', 'icph', 'icpl', 'refh', 'refl', 'pp_reu', 'pp_red', 'gel_pripr', 'gel_prirange', 'bpb_reu_value', 'bpb_red_value', 'pbh', 'pbl', 'pbc', 'bpb_pripr', 'range', 'chg_h', 'chg_l', 'chg_h_percent', 'chg_l_percent', 'body', 'gap', 'island_gap', 'bpb_ce_percent', 'bpb_epc', 'bpb_epc_dir', 'bpb_e1_value', 'bpb_e2_value', 'bpb_red_flag', 'bpb_reu_flag', 'bpb_re_flag', 'bpb_twoway_flag', 'gel_reu_flag', 'gel_red_flag', 'ip_ce_percent', 'ip_epc', 'ip_epc_dir', 'ip_e1_value', 'ip_e2_value', 'ip_re_flag', 'ip_twoway_flag', 'ip_twoway_fre_dir', 'ip_oneway_fre_dir', 'ip_last_dir', 'pp_reu_flag', 'pp_red_flag', 'pp_pri_percentr', 'pp_ce_percent', 'pp_epc', 'pp_epc_dir', 'pp_e1_value', 'pp_e2_value', 'pp_re_flag', 'pp_twoway_flag', 'pp_twoway_fre_dir', 'pp_oneway_fre_dir', 'pp_last_dir', 'ip_state_dir', 'ip_rpc_this_row', 'ip_rpc_total', 'ip_state_id', 'pp_state_dir', 'pp_rpc_this_row', 'pp_rpc_total', 'pp_state_id']\n",
            "üîç Columns at start of Round 2: ['date', 'open', 'high', 'low', 'close', 'parent', 'sequence', 'pph', 'ppl', 'ppc', 'volume', 'child_period', 'parent_period', 'jobname', 'gel_o', 'gel_h', 'gel_l', 'gel_reu_value', 'gel_red_value', 'icph', 'icpl', 'refh', 'refl', 'pp_reu', 'pp_red', 'gel_pripr', 'gel_prirange', 'bpb_reu_value', 'bpb_red_value', 'pbh', 'pbl', 'pbc', 'bpb_pripr', 'range', 'chg_h', 'chg_l', 'chg_h_percent', 'chg_l_percent', 'body', 'gap', 'island_gap', 'bpb_ce_percent', 'bpb_epc', 'bpb_epc_dir', 'bpb_e1_value', 'bpb_e2_value', 'bpb_red_flag', 'bpb_reu_flag', 'bpb_re_flag', 'bpb_twoway_flag', 'gel_reu_flag', 'gel_red_flag', 'ip_ce_percent', 'ip_epc', 'ip_epc_dir', 'ip_e1_value', 'ip_e2_value', 'ip_re_flag', 'ip_twoway_flag', 'ip_twoway_fre_dir', 'ip_oneway_fre_dir', 'ip_last_dir', 'pp_reu_flag', 'pp_red_flag', 'pp_pri_percentr', 'pp_ce_percent', 'pp_epc', 'pp_epc_dir', 'pp_e1_value', 'pp_e2_value', 'pp_re_flag', 'pp_twoway_flag', 'pp_twoway_fre_dir', 'pp_oneway_fre_dir', 'pp_last_dir', 'ip_state_dir', 'ip_rpc_this_row', 'ip_rpc_total', 'ip_state_id', 'pp_state_dir', 'pp_rpc_this_row', 'pp_rpc_total', 'pp_state_id']\n",
            "Attempting to export test file for BAC\n",
            "Data has 7782 rows. Proceeding with export.\n",
            "Exported test file to: /content/test/BAC_test_20250115_154752.csv\n",
            "Attempting to export test file for BAC\n",
            "Data has 7782 rows. Proceeding with export.\n",
            "Exported test file to: /content/test/BAC_test_20250115_154753.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üöÄ Processing Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:34<00:00, 34.55s/file]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, Tuple, Optional, List, Any\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Constants for configuration\n",
        "VALID_CHILD_PERIODS = ['D', 'W', 'M', 'Q']\n",
        "VALID_PARENT_PERIODS = ['W', 'M', 'Q', 'Y']\n",
        "DEFAULT_JOBNAME = 'gelset_20250107'\n",
        "\n",
        "class GelSetProcessor:\n",
        "    def __init__(self,\n",
        "                 input_dir=\"/content/input\",\n",
        "                 output_child_dir=\"/content/output_child\",\n",
        "                 output_parent_dir=\"/content/output_parent\",\n",
        "                 test_dir=\"/content/test\",\n",
        "                 child_period=\"D\",\n",
        "                 parent_period=\"M\",\n",
        "                 jobname=\"gelset_20250107\"):\n",
        "        self.input_dir = input_dir\n",
        "        self.output_child_dir = output_child_dir\n",
        "        self.output_parent_dir = output_parent_dir\n",
        "        self.test_dir = test_dir\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "\n",
        "        #print(\"‚úÖ GelSetProcessor initialized!\")\n",
        "        #print(f\"üìÇ Input Directory: {self.input_dir}\")\n",
        "        #print(f\"üìÇ Output Child Directory: {self.output_child_dir}\")\n",
        "        #print(f\"üìÇ Output Parent Directory: {self.output_parent_dir}\")\n",
        "        #print(f\"üìÇ Test Directory: {self.test_dir}\")\n",
        "\n",
        "        self.export_columns = [\n",
        "            # Input fields\n",
        "            'ticker', 'date', 'parent', 'sequence', 'open', 'high', 'low', 'close', 'volume',\n",
        "\n",
        "            # Prior Child (PC) fields\n",
        "            'bpb_reu_value', 'bpb_red_value', 'bpb_reu_flag', 'bpb_red_flag',\n",
        "            'bpb_re_flag', 'bpb_twoway_flag',\n",
        "            'bpb_pripr', 'bpb_ce_percent',\n",
        "            'bpb_epc', 'bpb_epc_dir',\n",
        "            'bpb_e1_value', 'bpb_e2_value',\n",
        "\n",
        "             # Intra-Parent (IP) fields\n",
        "            'gel_o', 'gel_h', 'gel_l',\n",
        "            'gel_reu_value', 'gel_red_value', 'gel_reu_flag', 'gel_red_flag',\n",
        "            'ip_re_flag', 'ip_twoway_flag', 'ip_rpc_this_row',\n",
        "            'gel_pripr', 'ip_ce_percent',\n",
        "            'ip_epc', 'ip_epc_dir',\n",
        "            'ip_e1_value', 'ip_e2_value',\n",
        "            'ip_last_dir',\n",
        "\n",
        "            # Round two fields\n",
        "            'pph', 'ppl',\n",
        "            'icph', 'icpl',\n",
        "            'refh', 'refl',\n",
        "            'pp_reu', 'pp_red',\n",
        "            'pp_reu_flag', 'pp_red_flag',\n",
        "            'pp_last_dir',\n",
        "        ]\n",
        "\n",
        "        for directory in [self.output_child_dir, self.output_parent_dir, self.test_dir]:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "            print(f\"üìÅ Checked/Created directory: {directory}\")\n",
        "\n",
        "        for directory in [self.output_child_dir, self.output_parent_dir, self.test_dir]:\n",
        "            try:\n",
        "                os.makedirs(directory, exist_ok=True)\n",
        "                logging.info(f\"‚úÖ Verified or created directory: {directory}\")\n",
        "\n",
        "                # Check write permissions\n",
        "                if not os.access(directory, os.W_OK):\n",
        "                    raise PermissionError(f\"‚ùå No write access to: {directory}\")\n",
        "            except Exception as e:\n",
        "                logging.error(f\"‚ùå Failed to create/access directory {directory}: {e}\")\n",
        "                raise\n",
        "\n",
        "        # Log directory paths\n",
        "        #logging.info(f\"üìÇ Input Directory: {self.input_dir}\")\n",
        "        #logging.info(f\"üìÇ Output Child Directory: {self.output_child_dir}\")\n",
        "        #logging.info(f\"üìÇ Output Parent Directory: {self.output_parent_dir}\")\n",
        "        #logging.info(f\"üìÇ Test Directory: {self.test_dir}\")\n",
        "\n",
        "        # Ensure directories exist\n",
        "        for directory in [self.output_child_dir, self.output_parent_dir, self.test_dir]:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "            logging.info(f\"‚úÖ Verified or created directory: {directory}\")\n",
        "\n",
        "        for directory in [self.output_child_dir, self.output_parent_dir, self.test_dir]:\n",
        "            if not os.access(directory, os.W_OK):\n",
        "                raise PermissionError(f\"‚ùå No write access to: {directory}\")\n",
        "\n",
        "        # All validation for input data--maybe ensure parsed child_period matches setting.\n",
        "    def validate_input_data(self, df):\n",
        "        \"\"\"Validate input data according to spec requirements\"\"\"\n",
        "        #if df.empty:\n",
        "        #    logging.error(\"‚ùó Input data is empty\")\n",
        "        #raise ValueError(\"Input data is empty\")\n",
        "\n",
        "        required_columns = ['open', 'high', 'low', 'close', 'pph', 'ppl', 'ppc']\n",
        "        missing_cols = [col for col in required_columns if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            logging.error(f\"‚ùå Missing required columns: {missing_cols}\")\n",
        "            raise ValueError(f\"Missing columns in input data: {missing_cols}\")\n",
        "\n",
        "        # Check if 'high' and other price fields are numeric\n",
        "        for col in ['open', 'high', 'low', 'close', 'pph', 'ppl', 'ppc']:\n",
        "            if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "                logging.error(f\"‚ùå Column '{col}' contains non-numeric data.\")\n",
        "                raise TypeError(f\"Column '{col}' must contain numeric data.\")\n",
        "\n",
        "        conditions = [\n",
        "            (df['open'] > 0, \"open must be greater than 0\"),\n",
        "            (df['high'] > 0, \"high must be greater than 0\"),\n",
        "            (df['low'] > 0, \"low must be greater than 0\"),\n",
        "            (df['close'] > 0, \"close must be greater than 0\"),\n",
        "            (df['low'] <= df['close'], \"low must be less than or equal to close\"),\n",
        "            (df['close'] <= df['high'], \"close must be less than or equal to high\"),\n",
        "            (df['low'] <= df['open'], \"low must be less than or equal to open\"),\n",
        "            (df['open'] <= df['high'], \"open must be less than or equal to high\"),\n",
        "            ((df['high'] - df['low']) != 0, \"high minus low cannot be zero\"),\n",
        "\n",
        "            # Prior Parent Fields Validation\n",
        "            (df['pph'] > 0, \"prior parent high must be greater than 0\"),\n",
        "            (df['ppl'] > 0, \"prior parent low must be greater than 0\"),\n",
        "            (df['ppc'] > 0, \"close must be greater than 0\"),\n",
        "            (df['ppl'] <= df['ppc'], \"low must be less than or equal to close\"),\n",
        "            (df['ppc'] <= df['pph'], \"close must be less than or equal to high\"),\n",
        "        ]\n",
        "\n",
        "        for condition, message in conditions:\n",
        "            if not condition.all():\n",
        "                logging.error(f\"‚ùå Data validation failed: {message}\")\n",
        "                raise ValueError(f\"Data validation failed: {message}\")\n",
        "\n",
        "        logging.info(\"‚úÖ Input data passed all validation checks.\")\n",
        "        return True\n",
        "\n",
        "    def safe_max(self, a, b):\n",
        "        \"\"\"Safely computes max while handling None values\"\"\"\n",
        "        if a is None:\n",
        "            return b\n",
        "        if b is None:\n",
        "            return a\n",
        "        return max(a, b)\n",
        "\n",
        "    def safe_min(self, a, b):\n",
        "        \"\"\"Safely computes min while handling None values\"\"\"\n",
        "        if a is None:\n",
        "            return b\n",
        "        if b is None:\n",
        "            return a\n",
        "        return min(a, b)\n",
        "\n",
        "    def safe_compare(self, a, b, op='gt'):\n",
        "        \"\"\"Safe comparison handling None values\"\"\"\n",
        "        if a is None or b is None:\n",
        "            return False\n",
        "        if op == 'gt':\n",
        "            return a > b\n",
        "        elif op == 'lt':\n",
        "            return a < b\n",
        "        return a == b\n",
        "\n",
        "    def safe_subtract(self, a, b):\n",
        "        \"\"\"Safe subtraction handling None values\"\"\"\n",
        "        try:\n",
        "            if a is None or b is None:\n",
        "                return 0\n",
        "            return a - b\n",
        "        except Exception as e:\n",
        "            logging.error(f\"‚ùó Error during subtraction: {e}\")\n",
        "            return 0\n",
        "\n",
        "    def process_round_one(self, data):\n",
        "\n",
        "        \"\"\"\n",
        "        First Round - Establish intra-group values and prior parent expansions.\n",
        "        Implements the relationship between intra-parent (IP) values, prior parent (PP) bounds, and prior child (PC) values.\n",
        "        \"\"\"\n",
        "        print(\"üîç Columns at start of Round 1:\", data.columns.tolist())\n",
        "\n",
        "        # Normalize column names to avoid issues with casing or whitespace\n",
        "        data.columns = data.columns.str.strip().str.lower()\n",
        "\n",
        "        # Check if 'high' column exists\n",
        "        if 'high' not in data.columns:\n",
        "            raise KeyError(\"‚ùó Column 'high' is missing in the input data.\")\n",
        "\n",
        "        # Check for empty DataFrame\n",
        "        if data.empty:\n",
        "            raise ValueError(\"‚ùó Input data is empty before Round 1 processing.\")\n",
        "\n",
        "        output_data = []\n",
        "\n",
        "        # Initialize group state tracker with default values\n",
        "        group_state = {\n",
        "            \"current_group\": None,\n",
        "\n",
        "            \"current_group\": None,\n",
        "            \"intra_group_h\": None,\n",
        "            \"intra_group_l\": None,\n",
        "            \"prior_gelo\": None,\n",
        "            \"prior_gelc\": None,\n",
        "            \"prior_gelh\": None,\n",
        "            \"prior_gell\": None,\n",
        "            \"prior_icph\": None,  # Track previous row's icph\n",
        "            \"prior_icpl\": None,   # Track previous row's icpl\n",
        "            \"pbh\": None,  # Track previous row's high\n",
        "            \"pbl\": None,   # Track previous row's low\n",
        "            \"pbc\": None,   # Track previous row's close\n",
        "\n",
        "            # Intra-Parent State Tracking\n",
        "            \"ip_state_dir\": None,\n",
        "            \"ip_state_id\": None,\n",
        "            \"ip_rpc_total\": 0,\n",
        "\n",
        "            \"prior_ip_state_dir\": None,\n",
        "            \"prior_ip_state_id\": None,\n",
        "            \"prior_ip_rpc_total\": 0,\n",
        "            \"prior_pp_state_dir\": None,\n",
        "            \"prior_pp_state_id\": None,\n",
        "            \"prior_pp_rpc_total\": 0,\n",
        "\n",
        "        }\n",
        "\n",
        "        for index, row in data.iterrows():\n",
        "            if str(row[\"parent\"]) != str(group_state[\"current_group\"]):\n",
        "                group_state[\"current_group\"] = row[\"parent\"]\n",
        "                group_state[\"intra_group_h\"] = row[\"high\"]\n",
        "                group_state[\"intra_group_l\"] = row[\"low\"]\n",
        "                group_state[\"gel_o\"] = row[\"open\"]\n",
        "                group_state[\"prior_gelc\"] = None\n",
        "                group_state[\"prior_gelh\"] = None\n",
        "                group_state[\"prior_gell\"] = None\n",
        "                group_state[\"prior_icph\"] = row[\"pph\"]  # For sequence 1, use pph\n",
        "                group_state[\"prior_icpl\"] = row[\"ppl\"]  # For sequence 1, use ppl\n",
        "                group_state[\"pbc\"] = None  # Add this line to initialize pbc\n",
        "\n",
        "                # Initialize Prior Child with current row values\n",
        "                #group_state[\"prior_open\"] = row[\"open\"]\n",
        "                #group_state[\"prior_high\"] = row[\"high\"]\n",
        "                #group_state[\"prior_low\"] = row[\"low\"]\n",
        "                #group_state[\"prior_close\"] = row[\"close\"]\n",
        "\n",
        "                # Initialize Prior Intra-Parent to None for new month\n",
        "                #group_state[\"pip_open\"] = None\n",
        "                #group_state[\"pip_high\"] = None\n",
        "                #group_state[\"pip_low\"] = None\n",
        "                #group_state[\"pip_close\"] = None\n",
        "\n",
        "                # Initialize Intra-Parent with current row values\n",
        "                #group_state[\"ip_open\"] = row[\"open\"]\n",
        "                #group_state[\"ip_high\"] = row[\"high\"]\n",
        "                #group_state[\"ip_low\"] = row[\"low\"]\n",
        "                #group_state[\"ip_close\"] = row[\"close\"]\n",
        "\n",
        "                # Reset state tracking for new month\n",
        "                group_state[\"prior_ip_state_dir\"] = None\n",
        "                group_state[\"prior_ip_state_id\"] = None\n",
        "                group_state[\"prior_ip_rpc_total\"] = None\n",
        "\n",
        "                group_state[\"prior_pp_state_dir\"] = None\n",
        "                group_state[\"prior_pp_state_id\"] = None\n",
        "                group_state[\"prior_pp_rpc_total\"] = None\n",
        "\n",
        "                range_expansion_up = 0\n",
        "                range_expansion_down = 0\n",
        "                prior_percent_r = None\n",
        "            else:\n",
        "                # Calculate regular range expansions\n",
        "                if (row[\"high\"] > group_state[\"intra_group_h\"]):\n",
        "                    range_expansion_up = row[\"high\"] - group_state[\"intra_group_h\"]\n",
        "                else:\n",
        "                    range_expansion_up = 0\n",
        "\n",
        "                if (row[\"low\"] < group_state[\"intra_group_l\"]):\n",
        "                    range_expansion_down = group_state[\"intra_group_l\"] - row[\"low\"]\n",
        "                else:\n",
        "                    range_expansion_down = 0\n",
        "\n",
        "            range = row[\"high\"] - row[\"low\"]\n",
        "            chg_h = row[\"high\"] - row[\"open\"]\n",
        "            chg_l = row[\"open\"] - row[\"low\"]\n",
        "            chg_h_percent = ((row[\"high\"] - row[\"open\"]) / row[\"open\"]) if row[\"open\"] != 0 else 0\n",
        "            chg_l_percent = ((row[\"open\"] - row[\"low\"]) / row[\"open\"]) if row[\"open\"] != 0 else 0\n",
        "            body = max(row[\"open\"], row[\"close\"]) - min(row[\"open\"], row[\"close\"])\n",
        "            gap = abs(row[\"open\"] - group_state[\"pbc\"]) if group_state[\"pbc\"] is not None else None\n",
        "            if group_state[\"pbh\"] is not None and group_state[\"pbl\"] is not None:\n",
        "                if row[\"open\"] > group_state[\"pbh\"]:\n",
        "                    island_gap = row[\"open\"] - group_state[\"pbh\"]\n",
        "                elif row[\"open\"] < group_state[\"pbl\"]:\n",
        "                   island_gap = row[\"low\"] - row[\"open\"]\n",
        "                else:\n",
        "                    island_gap = 0\n",
        "            else:\n",
        "               island_gap = 0\n",
        "\n",
        "            # Update intra-group high and low: END OF ROW HIGH/LOW OF GEL\n",
        "            group_state[\"intra_group_h\"] = max(group_state[\"intra_group_h\"], row[\"high\"])\n",
        "            group_state[\"intra_group_l\"] = min(group_state[\"intra_group_l\"], row[\"low\"])\n",
        "\n",
        "            # Calculate icph/icpl (using gel values AT OPEN against parent bounds)\n",
        "            icph = max(group_state[\"intra_group_h\"], row[\"pph\"])\n",
        "            icpl = min(group_state[\"intra_group_l\"], row[\"ppl\"])\n",
        "\n",
        "            # Get refh/refl from prior state\n",
        "            refh = group_state[\"prior_icph\"]\n",
        "            refl = group_state[\"prior_icpl\"]\n",
        "\n",
        "            # Calculate prior parent range expansions\n",
        "            pp_reu = max(group_state[\"intra_group_h\"] - refh, 0) if refh is not None else 0\n",
        "            pp_red = max(refl - group_state[\"intra_group_l\"], 0) if refl is not None else 0\n",
        "\n",
        "            # Calculate prior parent range expansions\n",
        "            bpb_reu = max(row[\"high\"] - group_state[\"pbh\"], 0) if group_state[\"pbh\"] is not None else 0\n",
        "            bpb_red = max(group_state[\"pbl\"] - row[\"low\"], 0) if group_state[\"pbl\"] is not None else 0\n",
        "\n",
        "            # Calculate prior_percent_r\n",
        "            if group_state[\"prior_gelc\"] is not None and (group_state[\"prior_gelh\"] - group_state[\"prior_gell\"]) != 0:\n",
        "                prior_percent_r = (group_state[\"prior_gelc\"] - group_state[\"prior_gell\"]) / (\n",
        "                    group_state[\"prior_gelh\"] - group_state[\"prior_gell\"]\n",
        "                )\n",
        "            else:\n",
        "                prior_percent_r = None\n",
        "\n",
        "            if group_state[\"prior_gelc\"] is not None and group_state[\"prior_gelh\"] - group_state[\"prior_gell\"] != 0:\n",
        "                gel_prior_range = group_state[\"prior_gelh\"] - group_state[\"prior_gell\"]\n",
        "            else:\n",
        "                gel_prior_range = None\n",
        "\n",
        "            if group_state[\"pbc\"] is not None and (group_state[\"pbh\"] - group_state[\"pbl\"]) != 0:\n",
        "                bpb_pripr = (group_state[\"pbc\"] - group_state[\"pbl\"]) / (\n",
        "                    group_state[\"pbh\"] - group_state[\"pbl\"]\n",
        "                )\n",
        "            else:\n",
        "                bpb_pripr = None\n",
        "            # Update prior values for next row\n",
        "            #group_state[\"prior_gelo\"] = row[\"gelo\"]\n",
        "            group_state[\"prior_gelc\"] = row[\"close\"]\n",
        "            group_state[\"prior_gelh\"] = group_state[\"intra_group_h\"]\n",
        "            group_state[\"prior_gell\"] = group_state[\"intra_group_l\"]\n",
        "            group_state[\"prior_icph\"] = icph\n",
        "            group_state[\"prior_icpl\"] = icpl\n",
        "            group_state[\"pbc\"] = row[\"close\"]\n",
        "\n",
        "            # Create processed row\n",
        "            processed_row = row.to_dict()\n",
        "            processed_row.update({\n",
        "                \"gel_o\": group_state[\"gel_o\"],\n",
        "                \"gel_h\": group_state[\"intra_group_h\"],\n",
        "                \"gel_l\": group_state[\"intra_group_l\"],\n",
        "                \"gel_reu_value\": range_expansion_up,\n",
        "                \"gel_red_value\": range_expansion_down,\n",
        "                \"icph\": icph,\n",
        "                \"icpl\": icpl,\n",
        "                \"refh\": refh,\n",
        "                \"refl\": refl,\n",
        "                \"pp_reu\": pp_reu,\n",
        "                \"pp_red\": pp_red,\n",
        "                \"gel_pripr\": prior_percent_r,\n",
        "                \"gel_prirange\": gel_prior_range,\n",
        "                \"bpb_reu_value\": bpb_reu,\n",
        "                \"bpb_red_value\": bpb_red,\n",
        "                \"pbh\": group_state[\"pbh\"],\n",
        "                \"pbl\": group_state[\"pbl\"],\n",
        "                \"pbc\": group_state[\"pbc\"],\n",
        "                \"bpb_pripr\": bpb_pripr,\n",
        "                \"range\": range,\n",
        "                \"chg_h\": chg_h,\n",
        "                \"chg_l\": chg_l,\n",
        "                \"chg_h_percent\": chg_h_percent,\n",
        "                \"chg_l_percent\": chg_l_percent,\n",
        "                \"body\": body,\n",
        "                \"gap\": gap,\n",
        "                \"island_gap\": island_gap\n",
        "            })\n",
        "            output_data.append(processed_row)\n",
        "\n",
        "            group_state[\"pbh\"] = row[\"high\"]\n",
        "            group_state[\"pbl\"] = row[\"low\"]\n",
        "            group_state[\"pbc\"] = row[\"close\"]\n",
        "\n",
        "        return pd.DataFrame(output_data)\n",
        "\n",
        "    def process_round_two(self, data):\n",
        "        \"\"\"\n",
        "        Second Round - Range Expansion with Prior Child, Intra-Parent, and Prior Parent Relationships\n",
        "        \"\"\"\n",
        "        print(\"üîç Columns at start of Round 2:\", data.columns.tolist())\n",
        "        required_columns = [\"high\", \"low\", \"close\", \"sequence\", \"pph\", \"ppl\"]\n",
        "        missing_cols = [col for col in required_columns if col not in data.columns]\n",
        "        if missing_cols:\n",
        "            raise KeyError(f\"‚ùó Missing columns: {missing_cols}\")\n",
        "        # --- Prior Child (PC) Calculations ---\n",
        "\n",
        "        #data[\"bpb_reu_value\"] = data.apply(\n",
        "        #   lambda row: self.safe_subtract(row[\"high\"], row[\"prior_high\"]) if self.safe_compare(row[\"high\"], row[\"prior_high\"], 'gt') else 0,\n",
        "        #   axis=1\n",
        "        #)\n",
        "        #data[\"bpb_red_value\"] = data.apply(\n",
        "        #    lambda row: ((row[\"close\"] - row[\"low\"]) / (row[\"high\"] - row[\"low\"])) if (row[\"high\"] - row[\"low\"]) != 0 else 0\n",
        "        #)\n",
        "        #data[\"bpb_pri_percentr\"] = data.apply(\n",
        "        #    lambda row: ((row[\"prior_close\"] - row[\"prior_low\"]) / (row[\"prior_high\"] - row[\"prior_low\"]))\n",
        "        #    if (row[\"prior_high\"] - row[\"prior_low\"]) != 0 and None not in (row[\"prior_close\"], row[\"prior_low\"], row[\"prior_high\"]) else 0,\n",
        "        #    axis=1\n",
        "        #)\n",
        "        #data[\"bpb_pri_percentr\"] = data.apply(\n",
        "        #    lambda row: ((row[\"close\"] - row[\"low\"]) / (row[\"high\"] - row[\"low\"])) if (row[\"high\"] - row[\"low\"]) != 0 else 0\n",
        "        #)\n",
        "        data[\"bpb_ce_percent\"] = data.apply(\n",
        "            lambda row: None if pd.isna(row[\"bpb_pripr\"]) else\n",
        "                (1 - row[\"bpb_pripr\"] if row[\"bpb_pripr\"] >= 0.5 else row[\"bpb_pripr\"]),\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"bpb_epc\"] = data[\"bpb_ce_percent\"].apply(\n",
        "        lambda x: None if pd.isna(x) else max(1, min(5, math.ceil(x / 0.1)))\n",
        "        )\n",
        "        data[\"bpb_epc_dir\"] = np.where(\n",
        "            data[\"sequence\"] == 1,\n",
        "            None,\n",
        "            np.where(data[\"bpb_pripr\"] >= 0.5, \"U\", \"D\")\n",
        "        )\n",
        "        data[\"bpb_e1_value\"] = data.apply(\n",
        "            lambda row: row[\"bpb_reu_value\"] if row[\"bpb_pripr\"] >= 0.5 else row[\"bpb_red_value\"],\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"bpb_e2_value\"] = data.apply(\n",
        "            lambda row: row[\"bpb_reu_value\"] if row[\"bpb_pripr\"] < 0.5 else row[\"bpb_red_value\"],\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"bpb_red_flag\"] = data[\"bpb_red_value\"] > 0\n",
        "        data[\"bpb_reu_flag\"] = data[\"bpb_reu_value\"] > 0\n",
        "        data[\"bpb_re_flag\"] = data[\"bpb_reu_flag\"] | data[\"bpb_red_flag\"]\n",
        "        data[\"bpb_twoway_flag\"] = data[\"bpb_reu_flag\"] & data[\"bpb_red_flag\"]\n",
        "\n",
        "        # --- Intra-Parent (IP) Calculations ---\n",
        "        #data[\"ip_reu_value\"] = data.apply(\n",
        "        #    lambda row: ((row[\"close\"] - row[\"low\"]) / (row[\"high\"] - row[\"low\"])) if (row[\"high\"] - row[\"low\"]) != 0 else 0\n",
        "        #)\n",
        "        #data[\"ip_red_value\"] = data.apply(\n",
        "        #    lambda row: ((row[\"close\"] - row[\"low\"]) / (row[\"high\"] - row[\"low\"])) if (row[\"high\"] - row[\"low\"]) != 0 else 0\n",
        "        #)\n",
        "        data[\"gel_reu_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"gel_reu_value\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_red_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"gel_red_value\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        #data[\"ip_pri_percentr\"] = data.apply(\n",
        "        #    lambda row: ((row[\"pip_close\"] - row[\"pip_low\"]) / (row[\"pip_high\"] - row[\"pip_low\"]))\n",
        "        #    if (row[\"pip_high\"] - row[\"pip_low\"]) != 0 else 0,\n",
        "        #    axis=1\n",
        "        #)\n",
        "        #data[\"ip_pri_percentr\"] = data.apply(\n",
        "        #    lambda row: 0 if pd.isna(row[\"high\"]) or pd.isna(row[\"low\"]) or (row[\"high\"] - row[\"low\"]) == 0\n",
        "        #    else (row[\"close\"] - row[\"low\"]) / (row[\"high\"] - row[\"low\"]),\n",
        "        #)\n",
        "        data[\"ip_ce_percent\"] = data.apply(\n",
        "            lambda row: row[\"gel_pripr\"] if row[\"gel_pripr\"] < 0.5 else row[\"gel_pripr\"],\n",
        "            axis = 1\n",
        "        )\n",
        "        data[\"ip_epc\"] = data[\"ip_ce_percent\"].apply(\n",
        "            lambda x: None if pd.isna(x) else max(1, min(5, math.ceil(x / 0.1)))\n",
        "\n",
        "        )\n",
        "        data[\"ip_epc_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (\"U\" if row[\"gel_pripr\"] >= 0.5 else \"D\"),\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"ip_e1_value\"] = data.apply(\n",
        "            lambda row: row[\"gel_reu_value\"] if row[\"gel_pripr\"] >= 0.5 else row[\"gel_red_value\"],\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"ip_e2_value\"] = data.apply(\n",
        "            lambda row: row[\"gel_reu_value\"] if row[\"gel_pripr\"] < 0.5 else row[\"gel_red_value\"],\n",
        "            axis=1\n",
        "        )\n",
        "        if 'high' not in data.columns:\n",
        "            raise KeyError(\"‚ùó 'high' column is missing in process_round_two\")\n",
        "        #data[\"gel_reu_flag\"] = data[\"gel_reu_value\"] > 0\n",
        "        #data[\"gel_red_flag\"] = data[\"gel_red_value\"] > 0\n",
        "        data[\"ip_re_flag\"] = data[\"gel_reu_flag\"] | data[\"gel_red_flag\"]\n",
        "        data[\"ip_twoway_flag\"] = data[\"gel_reu_flag\"] & data[\"gel_red_flag\"]\n",
        "        data[\"ip_twoway_fre_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (row[\"ip_epc_dir\"] if row[\"ip_twoway_flag\"] == True else \"N\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"ip_oneway_fre_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                ((\"D\" if row[\"gel_red_flag\"] == True else \"N\") if row[\"gel_reu_flag\"] == False else \"U\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"ip_last_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (\"D\" if bool(row[\"ip_twoway_flag\"]) and row[\"ip_twoway_fre_dir\"] == \"U\" else\n",
        "               \"U\" if bool(row[\"ip_twoway_flag\"]) and row[\"ip_twoway_fre_dir\"] == \"D\" else\n",
        "               \"U\" if bool(row[\"gel_reu_flag\"]) else\n",
        "               \"D\" if bool(row[\"gel_red_flag\"]) else\n",
        "               \"N\"),\n",
        "            axis=1\n",
        "        )\n",
        "        # Prior parent range expansions\n",
        "        data[\"pp_reu_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"pp_reu\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"pp_red_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"pp_red\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"pp_pri_percentr\"] = data.apply(\n",
        "            lambda row: None if pd.isna(row[\"ppc\"]) or (row[\"pph\"] - row[\"ppl\"]) == 0\n",
        "            else (row[\"ppc\"] - row[\"ppl\"]) / (row[\"pph\"] - row[\"ppl\"]),\n",
        "            axis = 1\n",
        "        )\n",
        "        data[\"pp_ce_percent\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (1 - row[\"pp_pri_percentr\"] if row[\"pp_pri_percentr\"] >= 0.5 else row[\"pp_pri_percentr\"]),\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"pp_epc\"] = data[\"pp_ce_percent\"].apply(\n",
        "            lambda x: None if pd.isna(x) else max(1, min(5, math.ceil(x / 0.1)))\n",
        "        )\n",
        "        data[\"pp_epc_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (\"U\" if row[\"pp_pri_percentr\"] >= 0.5 else \"D\"),\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"pp_e1_value\"] = data.apply(\n",
        "            lambda row: row[\"pp_reu\"] if row[\"pp_pri_percentr\"] >= 0.5 else row[\"pp_red\"],\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"pp_e2_value\"] = data.apply(\n",
        "            lambda row: row[\"pp_reu\"] if row[\"pp_pri_percentr\"] < 0.5 else row[\"pp_red\"],\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"pp_re_flag\"] = data[\"pp_reu_flag\"] | data[\"pp_red_flag\"]\n",
        "        data[\"pp_twoway_flag\"] = data[\"pp_reu_flag\"] & data[\"pp_red_flag\"]\n",
        "        data[\"pp_twoway_fre_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (row[\"pp_epc_dir\"] if row[\"pp_twoway_flag\"] == True else \"N\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"pp_oneway_fre_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                ((\"D\" if row[\"pp_red_flag\"] == True else \"N\") if row[\"pp_reu_flag\"] == False else \"U\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"pp_last_dir\"] = data.apply(\n",
        "            lambda row:\n",
        "                (\"D\" if row[\"pp_twoway_flag\"] and row[\"pp_twoway_fre_dir\"] == \"U\" else\n",
        "                 \"U\" if row[\"pp_twoway_flag\"] and row[\"pp_twoway_fre_dir\"] == \"D\" else\n",
        "                 \"U\" if row[\"pp_reu_flag\"] else\n",
        "                 \"D\" if row[\"pp_red_flag\"] else\n",
        "                 \"N\"),\n",
        "            axis=1\n",
        "        )\n",
        "        #data[\"pp_co_flag\"] = data.apply(\n",
        "        #    lambda row: None if row[\"sequence\"] == 1 else\n",
        "        #        (False if row[\"low\"] > row[\"pph\"] else False if row[\"high\"] < row[\"ppl\"] else True),\n",
        "        #    axis=1\n",
        "        #)\n",
        "        #data[\"pp_noco_dir\"] = data.apply(\n",
        "        #    lambda row: None if row[\"sequence\"] == 1 else\n",
        "        #        (None if row[\"pp_co_flag\"] == True else \"A\" if row[\"low\"] > row[\"pph\"] else \"B\"),\n",
        "        #    axis=1\n",
        "        #)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def process_round_three_ip(self, data):\n",
        "        \"\"\"Third Round - RPC States\"\"\"\n",
        "        state_tracker = {\n",
        "            \"prior_ip_state_dir\": None,\n",
        "            \"prior_ip_last_dir\": None,\n",
        "            \"prior_ip_rpc_total\": 0,\n",
        "        }\n",
        "\n",
        "        for index, row in data.iterrows():\n",
        "            try:\n",
        "                sequence = row[\"sequence\"]\n",
        "                ip_last_dir = row[\"ip_last_dir\"]\n",
        "                ip_twoway_flag = row[\"ip_twoway_flag\"]\n",
        "\n",
        "                if sequence == 1:\n",
        "                    ip_state_dir = \"N\"\n",
        "                    ip_rpc_this_row = 0\n",
        "                    ip_rpc_total = 0\n",
        "                    ip_state_id = f\"{row['parent']}_{sequence}_N\"\n",
        "                else:\n",
        "                    # Calculate gel_dir_state\n",
        "                    ip_dir_state = ip_last_dir if ip_last_dir != \"N\" else state_tracker[\"prior_ip_state_dir\"]\n",
        "\n",
        "                    # Calculate gel_rpc\n",
        "                    if sequence == 2 and ip_twoway_flag:\n",
        "                        ip_rpc_this_row = 2\n",
        "                    elif ip_last_dir == \"N\":\n",
        "                        ip_rpc_this_row = 0\n",
        "                    elif ip_last_dir == state_tracker[\"prior_ip_last_dir\"] and ip_twoway_flag:\n",
        "                        ip_rpc_this_row = 2\n",
        "                    elif ip_last_dir != state_tracker[\"prior_ip_state_dir\"] and ip_last_dir != \"N\":\n",
        "                        ip_rpc_this_row = 1\n",
        "                    else:\n",
        "                        ip_rpc_this_row = 0\n",
        "\n",
        "                    # Calculate ip_rpc_total safely\n",
        "                    ip_rpc_total = state_tracker[\"prior_ip_rpc_total\"] + ip_rpc_this_row if state_tracker[\"prior_ip_rpc_total\"] is not None else ip_rpc_this_row\n",
        "\n",
        "                    # Generate ip_state_id if new rpc occurs\n",
        "                    ip_state_id = f\"{row['parent']}_{sequence}_{ip_last_dir}\" if ip_rpc_this_row == 1 else state_tracker[\"prior_ip_state_dir\"]\n",
        "\n",
        "                # Update DataFrame\n",
        "                data.loc[index, \"ip_state_dir\"] = ip_state_dir\n",
        "                data.loc[index, \"ip_rpc_this_row\"] = ip_rpc_this_row\n",
        "                data.loc[index, \"ip_rpc_total\"] = ip_rpc_total\n",
        "                data.loc[index, \"ip_state_id\"] = ip_state_id\n",
        "\n",
        "\n",
        "                # Update state tracker\n",
        "                state_tracker.update({\n",
        "                    \"prior_ip_state_dir\": ip_state_dir,\n",
        "                    \"prior_ip_last_dir\": ip_last_dir,\n",
        "                    \"prior_ip_rpc_total\": ip_rpc_total,\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing row {index} in round three ip: {e}\")\n",
        "                print(f\"Error details - state_tracker: {state_tracker}\")\n",
        "                raise\n",
        "\n",
        "        return data\n",
        "\n",
        "    def process_round_three_pp(self, data):\n",
        "        \"\"\"Third Round - RPC States for Child/Prior Parent (PP)\"\"\"\n",
        "        state_tracker = {\n",
        "            \"prior_pp_state_dir\": None,\n",
        "            \"prior_pp_last_dir\": None,\n",
        "            \"prior_pp_rpc_total\": 0,\n",
        "        }\n",
        "\n",
        "        for index, row in data.iterrows():\n",
        "            sequence = row[\"sequence\"]\n",
        "            pp_last_dir = row[\"pp_last_dir\"]\n",
        "            pp_twoway_flag = row[\"pp_twoway_flag\"]\n",
        "\n",
        "            if sequence == 1:\n",
        "                pp_state_dir = \"N\"\n",
        "                pp_rpc_this_row = 0  # Represents RPC state change for this specific row\n",
        "                pp_rpc_total = 0\n",
        "                pp_state_id = f\"{row['parent']}_{sequence}_N\"\n",
        "            else:\n",
        "                # Calculate pp_dir_state\n",
        "                pp_dir_state = pp_last_dir if pp_last_dir != \"N\" else state_tracker[\"prior_pp_state_dir\"]\n",
        "\n",
        "                # Calculate pp_rpc_this_row\n",
        "                if sequence == 2 and pp_twoway_flag:\n",
        "                    pp_rpc_this_row = 2\n",
        "                elif pp_last_dir == \"N\":\n",
        "                    pp_rpc_this_row = 0\n",
        "                elif pp_last_dir == state_tracker[\"prior_pp_last_dir\"] and pp_twoway_flag:\n",
        "                    pp_rpc_this_row = 2\n",
        "                elif pp_last_dir != state_tracker[\"prior_pp_state_dir\"] and pp_last_dir != \"N\":\n",
        "                    pp_rpc_this_row = 1\n",
        "                else:\n",
        "                    pp_rpc_this_row = 0\n",
        "\n",
        "                # Calculate pp_rpc_total\n",
        "                pp_rpc_total = state_tracker[\"prior_pp_rpc_total\"] + pp_rpc_this_row\n",
        "\n",
        "                # Generate pp_state_id if new rpc occurs\n",
        "                if pp_rpc_this_row == 1:\n",
        "                    pp_state_id = f\"{row['parent']}_{sequence}_{pp_last_dir}\"\n",
        "                else:\n",
        "                    pp_state_id = state_tracker[\"prior_pp_state_dir\"]\n",
        "\n",
        "            # Update state tracker\n",
        "            state_tracker.update({\n",
        "                \"prior_pp_state_dir\": pp_state_dir,\n",
        "                \"prior_pp_last_dir\": pp_last_dir,\n",
        "                \"prior_pp_rpc_total\": pp_rpc_total\n",
        "            })\n",
        "\n",
        "            # Update DataFrame\n",
        "            data.at[index, \"pp_state_dir\"] = pp_state_dir\n",
        "            data.at[index, \"pp_rpc_this_row\"] = pp_rpc_this_row\n",
        "            data.at[index, \"pp_rpc_total\"] = pp_rpc_total\n",
        "            data.at[index, \"pp_state_id\"] = pp_state_id\n",
        "\n",
        "        return data\n",
        "\n",
        "    def generate_summary(self, data, ticker):\n",
        "        \"\"\"Generate summary data for parent periods\"\"\"\n",
        "        summary_data = []\n",
        "\n",
        "        for parent, group in data.groupby(\"parent\"):\n",
        "            lookup_date = group[\"parent\"].iloc[0]\n",
        "            duration = len(group)\n",
        "            parent_high = group[\"gel_h\"].max()\n",
        "            parent_low = group[\"gel_l\"].min()\n",
        "            bar_of_h = group.loc[group[\"gel_h\"].idxmax(), \"sequence\"]\n",
        "            bar_of_l = group.loc[group[\"gel_l\"].idxmin(), \"sequence\"]\n",
        "            bpb_reu_count = group[\"bpb_reu_flag\"].sum()\n",
        "            bpb_red_count = group[\"bpb_red_flag\"].sum()\n",
        "            bpb_reu_max = group[\"bpb_reu_value\"].max()\n",
        "            bpb_red_max = group[\"bpb_red_value\"].max()\n",
        "            bpb_re_count = group[\"bpb_re_flag\"].sum()\n",
        "            bpb_no_re_count = duration - group[\"bpb_re_flag\"].sum()\n",
        "            bpb_twoway_count = group[\"bpb_twoway_flag\"].sum()\n",
        "            range_max = group[\"range\"].max()\n",
        "            range_avg = group[\"range\"].mean()\n",
        "            bpb_re_count = group[\"bpb_re_flag\"].sum()\n",
        "            bpb_no_re_count = duration - group[\"bpb_re_flag\"].sum()\n",
        "            #bpb_twoway_count = group[\"bpb_twoway_flag\"].sum()\n",
        "            A1 = min(bar_of_h, bar_of_l)\n",
        "            A2 = max(bar_of_h, bar_of_l)\n",
        "            gel_reu_count = group[\"gel_reu_flag\"].sum()\n",
        "            gel_red_count = group[\"gel_red_flag\"].sum()\n",
        "            gel_reu_first = group.loc[group[\"gel_reu_flag\"] == True, \"sequence\"].min() if gel_reu_count > 0 else None\n",
        "            gel_reu_last = group.loc[group[\"gel_reu_flag\"] == True, \"sequence\"].max() if gel_reu_count > 0 else None\n",
        "            gel_red_first = group.loc[group[\"gel_red_flag\"] == True, \"sequence\"].min() if gel_red_count > 0 else None\n",
        "            gel_red_last = group.loc[group[\"gel_red_flag\"] == True, \"sequence\"].max() if gel_red_count > 0 else None\n",
        "\n",
        "            #gel_rpc_total = group[\"gel_rpc\"].sum()\n",
        "\n",
        "            #pp_reu_count = group[\"pp_reu_flag\"].sum()\n",
        "            #pp_red_count = group[\"pp_red_flag\"].sum()\n",
        "            #pp_reu_first = group.loc[group[\"pp_reu_flag\"] == True, \"sequence\"].min() if pp_reu_count > 0 else None\n",
        "            #pp_reu_last = group.loc[group[\"pp_reu_flag\"] == True, \"sequence\"].max() if pp_reu_count > 0 else None\n",
        "            #pp_red_first = group.loc[group[\"pp_red_flag\"] == True, \"sequence\"].min() if pp_red_count > 0 else None\n",
        "            #pp_red_last = group.loc[group[\"pp_red_flag\"] == True, \"sequence\"].max() if pp_red_count > 0 else None\n",
        "\n",
        "            summary_data.append({\n",
        "                \"ticker\": ticker,\n",
        "                \"parent\": lookup_date,\n",
        "                \"duration\": duration,\n",
        "                \"child_period\": self.child_period,\n",
        "                \"parent_period\": self.parent_period,\n",
        "                \"range_max\": range_max,\n",
        "                \"range_avg\": range_avg,\n",
        "                \"bpb_reu_count\": bpb_reu_count,\n",
        "                \"bpb_red_count\": bpb_red_count,\n",
        "                \"bpb_reu_max\": bpb_reu_max,\n",
        "                \"bpb_red_max\": bpb_red_max,\n",
        "                \"bpb_re_count\": bpb_re_count,\n",
        "                \"bpb_no_re_count\": bpb_no_re_count,\n",
        "                \"bpb_twoway_count\": bpb_twoway_count,\n",
        "                \"parent_high\": parent_high,\n",
        "                \"parent_low\": parent_low,\n",
        "                \"bar_of_h\": bar_of_h,\n",
        "                \"bar_of_l\": bar_of_l,\n",
        "                \"A1\": min(bar_of_h, bar_of_l),\n",
        "                \"A2\": max(bar_of_h, bar_of_l),\n",
        "                \"gel_reu_count\": gel_reu_count,\n",
        "                \"gel_red_count\": gel_red_count,\n",
        "                \"gel_reu_first\": gel_reu_first,\n",
        "                \"gel_reu_last\": gel_reu_last,\n",
        "                \"gel_red_first\": gel_red_first,\n",
        "                \"gel_red_last\": gel_red_last,\n",
        "                #\"pp_reu_count\": pp_reu_count,\n",
        "                #\"pp_red_count\": pp_red_count,\n",
        "                #\"pp_reu_first\": pp_reu_first,\n",
        "                #\"pp_reu_last\": pp_reu_last,\n",
        "                #\"pp_red_first\": pp_red_first,\n",
        "                #\"pp_red_last\": pp_red_last,\n",
        "                #\"gel_rpc_total\": gel_rpc_total,\n",
        "                \"create_date\": datetime.now().date(),\n",
        "                \"create_time\": datetime.now().time(),\n",
        "                \"jobname\": self.jobname\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(summary_data)\n",
        "\n",
        "    def export_test_file(self, data, ticker):\n",
        "        \"\"\"Export all fields after round three processing to a test file\"\"\"\n",
        "        # Assign ticker to the data\n",
        "        # ‚úÖ Add this to verify the export process\n",
        "        print(f\"Attempting to export test file for {ticker}\")\n",
        "\n",
        "        # ‚ö†Ô∏è Check if DataFrame is empty\n",
        "        if data.empty:\n",
        "            print(\"‚ö†Ô∏è Data is empty, nothing to export.\")\n",
        "            return data  # Stop here if data is empty\n",
        "        else:\n",
        "            print(f\"Data has {len(data)} rows. Proceeding with export.\")\n",
        "\n",
        "        data['ticker'] = ticker\n",
        "\n",
        "        # Updated field list to reflect the latest spec\n",
        "        columns = [\n",
        "            # Original input fields\n",
        "            'ticker', 'date', 'parent', 'sequence', 'open', 'high', 'low', 'close', 'range',\n",
        "            'chg_h', 'chg_l', 'chg_h_percent', 'chg_l_percent',\n",
        "\n",
        "            # Prior Child (PC) Fields\n",
        "            'bpb_red_value', 'bpb_red_flag',\n",
        "            'bpb_pripr', 'bpb_ce_percent', 'bpb_epc', 'bpb_epc_dir',\n",
        "\n",
        "            # Intra-Parent (IP) Fields\n",
        "            'gel_o', 'gel_h', 'gel_l', 'close',\n",
        "            'gel_reu_value', 'gel_red_value', 'gel_reu_flag', 'gel_red_flag',\n",
        "            'gel_pripr', 'ip_ce_percent', 'ip_epc', 'ip_epc_dir',\n",
        "            'ip_e1_value', 'ip_e2_value', 'ip_re_flag', 'ip_twoway_flag',\n",
        "            'ip_state_dir', 'ip_rpc_this_row', 'ip_rpc_total', 'ip_state_id',\n",
        "\n",
        "        ]\n",
        "\n",
        "        # ‚úÖ Ensure test directory exists\n",
        "        if not os.path.exists(self.test_dir):\n",
        "            try:\n",
        "                os.makedirs(self.test_dir, exist_ok=True)\n",
        "                print(f\"üìÇ Created missing test directory: {self.test_dir}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to create test directory {self.test_dir}: {str(e)}\")\n",
        "                return data\n",
        "\n",
        "       # ‚úÖ Check if the directory is writable\n",
        "        if not os.access(self.test_dir, os.W_OK):\n",
        "            print(f\"‚ùå No write access to: {self.test_dir}\")\n",
        "            return data\n",
        "\n",
        "        # ‚úÖ Ensure all columns exist in the DataFrame\n",
        "        missing_columns = [col for col in columns if col not in data.columns]\n",
        "        if missing_columns:\n",
        "            print(f\"‚ö†Ô∏è Missing columns in data, cannot export: {missing_columns}\")\n",
        "            return data\n",
        "\n",
        "        # Create filename with timestamp for uniqueness\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        output_file = os.path.join(self.test_dir, f\"{ticker}_test_{timestamp}.csv\")\n",
        "\n",
        "        # Export to CSV with error handling\n",
        "        try:\n",
        "            data.to_csv(output_file, columns=columns, index=False)\n",
        "            print(f\"Exported test file to: {output_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to export test file for {ticker}: {str(e)}\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    def process_file(self, filename):\n",
        "        \"\"\"Process a single input file through all rounds.\"\"\"\n",
        "        try:\n",
        "            # --- Validate Filename Format ---\n",
        "            if not filename.endswith(f\"_{self.child_period}.csv\"):\n",
        "                raise ValueError(f\"Invalid filename format: {filename}. Expected format: {{TICKER}}_{self.child_period}.csv\")\n",
        "\n",
        "            # --- Extract Ticker ---\n",
        "            ticker = filename.split('_')[0]\n",
        "\n",
        "            logging.info(f\"üì• Reading file: {filename}\")\n",
        "\n",
        "            print(f\"Reading file: {filename}\")\n",
        "            # --- Read Input File ---\n",
        "            input_path = os.path.join(self.input_dir, filename)\n",
        "            try:\n",
        "                data = pd.read_csv(input_path)\n",
        "                logging.info(f\"‚úÖ Successfully loaded input file: {input_path}\")\n",
        "            except FileNotFoundError:\n",
        "                logging.error(f\"‚ùå File not found: {input_path}\")\n",
        "                raise FileNotFoundError(f\"Input file not found: {input_path}\")\n",
        "            except pd.errors.EmptyDataError:\n",
        "                logging.error(f\"‚ùó File is empty: {input_path}\")\n",
        "                raise ValueError(f\"Input file is empty: {input_path}\")\n",
        "            except pd.errors.ParserError as e:\n",
        "                logging.error(f\"‚ùó Error parsing file {input_path}: {e}\")\n",
        "                raise ValueError(f\"Error parsing file: {input_path}\")\n",
        "            except Exception as e:\n",
        "                logging.error(f\"‚ùó Unexpected error reading file {input_path}: {e}\")\n",
        "                raise\n",
        "\n",
        "            # --- Validate Input Data ---\n",
        "            self.validate_input_data(data)\n",
        "            print(\"‚úÖ Data validation passed\")\n",
        "\n",
        "            # --- Add Required Metadata Columns ---\n",
        "            data['child_period'] = self.child_period\n",
        "            data['parent_period'] = self.parent_period\n",
        "            data['jobname'] = self.jobname\n",
        "\n",
        "            # --- Process Through All Rounds ---\n",
        "            data = self.process_round_one(data)\n",
        "            print(\"‚úÖ Completed Round 1\")\n",
        "            print(f\"üîé After Round 1 - Data shape: {data.shape}\")\n",
        "            data = self.process_round_two(data)\n",
        "            print(\"‚úÖ Completed Round 2\")\n",
        "            print(f\"üîé After Round 2 - Data shape: {data.shape}\")\n",
        "            data = self.process_round_three_ip(data)\n",
        "            print(\"‚úÖ Completed Round 3ip\")\n",
        "            data = self.process_round_three_pp(data)\n",
        "            print(\"‚úÖ Completed Round 3pp\")\n",
        "            print(f\"üîé After Round 3bb - Data shape: {data.shape}\")\n",
        "\n",
        "            # --- Generate Summary ---\n",
        "            self.validate_input_data(data)\n",
        "            logging.info(\"‚úÖ Data validation passed\")\n",
        "\n",
        "            # --- Add Required Metadata Columns ---\n",
        "            data['child_period'] = self.child_period\n",
        "            data['parent_period'] = self.parent_period\n",
        "            data['jobname'] = self.jobname\n",
        "\n",
        "            # --- Process Through All Rounds ---\n",
        "            data = self.process_round_one(data)\n",
        "            logging.info(\"‚úÖ Completed Round 1\")\n",
        "\n",
        "            data = self.process_round_two(data)\n",
        "            logging.info(\"‚úÖ Completed Round 2\")\n",
        "\n",
        "            data = self.process_round_three_ip(data)\n",
        "            logging.info(\"‚úÖ Completed Round 3\")\n",
        "\n",
        "            data = self.process_round_three_pp(data)\n",
        "            logging.info(\"‚úÖ Completed Round 3\")\n",
        "\n",
        "            # --- Export Test File ---\n",
        "            self.export_test_file(data, ticker)\n",
        "            logging.info(\"‚úÖ Exported test file\")\n",
        "\n",
        "            # --- Generate Summary ---\n",
        "            summary_df = self.generate_summary(data, ticker)\n",
        "            logging.info(\"‚úÖ Generated summary data\")\n",
        "\n",
        "            # --- Export Test File ---\n",
        "            self.export_test_file(data, ticker)\n",
        "            logging.info(\"‚úÖ Exported test file\")\n",
        "\n",
        "            # --- Export Child Data ---\n",
        "            child_filename = f\"{ticker}_{self.child_period}_processed.csv\"\n",
        "            child_path = os.path.join(self.output_child_dir, child_filename)\n",
        "\n",
        "            # Check write permission\n",
        "            if not os.access(self.output_child_dir, os.W_OK):\n",
        "                logging.error(f\"‚ùå No write access to: {self.output_child_dir}\")\n",
        "                return None, None\n",
        "\n",
        "            data.to_csv(child_path, columns=self.export_columns, index=False)\n",
        "            logging.info(f\"‚úÖ Exported child data to: {child_path}\")\n",
        "\n",
        "            # --- Export Summary Data ---\n",
        "            summary_filename = f\"{ticker}_{self.parent_period}_summary.csv\"\n",
        "            summary_path = os.path.join(self.output_parent_dir, summary_filename)\n",
        "\n",
        "            if not os.access(self.output_parent_dir, os.W_OK):\n",
        "                logging.error(f\"‚ùå No write access to: {self.output_parent_dir}\")\n",
        "                return None, None\n",
        "\n",
        "            summary_df.to_csv(summary_path, index=False)\n",
        "            logging.info(f\"‚úÖ Exported parent summary to: {summary_path}\")\n",
        "\n",
        "            return data, summary_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"‚ùó Error processing {filename}: {str(e)}\")\n",
        "            return None, None\n",
        "\n",
        "    def process_all_files(self):\n",
        "        \"\"\"Process all eligible files in the input directory with progress tracking and robust error handling.\"\"\"\n",
        "\n",
        "        # --- Validate Input Directory ---\n",
        "        if not os.path.exists(self.input_dir):\n",
        "            raise FileNotFoundError(f\"‚ùå Input directory {self.input_dir} does not exist.\")\n",
        "\n",
        "        # --- Check Write Permissions for Output Directories ---\n",
        "        for directory in [self.output_child_dir, self.output_parent_dir, self.test_dir]:\n",
        "            if not os.access(directory, os.W_OK):\n",
        "                raise PermissionError(f\"‚ùå No write access to: {directory}\")\n",
        "\n",
        "        results = {}\n",
        "        processed_files = 0\n",
        "        errors = []\n",
        "\n",
        "        # --- List Eligible Files ---\n",
        "        eligible_files = [f for f in os.listdir(self.input_dir) if f.endswith(f\"_{self.child_period}.csv\")]\n",
        "        print(f\"üìÇ Eligible Files: {eligible_files}\")  # Debug print\n",
        "\n",
        "        if not eligible_files:\n",
        "            logging.warning(f\"‚ö†Ô∏è No eligible files found with pattern *_{self.child_period}.csv\")\n",
        "            return results\n",
        "\n",
        "        logging.info(f\"üìà Found {len(eligible_files)} files to process.\\n\")\n",
        "\n",
        "        # --- Track Total Processing Time ---\n",
        "        total_start_time = time.time()\n",
        "\n",
        "        # --- Process Each File with Progress Bar ---\n",
        "        for idx, filename in enumerate(tqdm(eligible_files, desc=\"üöÄ Processing Files\", unit=\"file\"), start=1):\n",
        "            file_start_time = time.time()\n",
        "            try:\n",
        "                logging.info(f\"\\nüìÑ [{idx}/{len(eligible_files)}] Processing {filename}...\")\n",
        "\n",
        "                # --- Process the file ---\n",
        "                data, summary_df = self.process_file(filename)\n",
        "\n",
        "                if data is None or data.empty:\n",
        "                    logging.warning(f\"‚ö†Ô∏è Skipping {filename}: No data to process.\")\n",
        "                    continue\n",
        "\n",
        "                # --- Store Results ---\n",
        "                results[filename] = {\n",
        "                    'status': 'success',\n",
        "                    'data': data,\n",
        "                    'summary': summary_df,\n",
        "                    'error': None,\n",
        "                    'processing_time_sec': round(time.time() - file_start_time, 2)\n",
        "                }\n",
        "\n",
        "                processed_files += 1\n",
        "                logging.info(f\"‚úÖ Successfully processed {filename} in {results[filename]['processing_time_sec']} seconds.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"‚ùó Error processing {filename}: {str(e)}\"\n",
        "                logging.error(error_msg)\n",
        "                errors.append(error_msg)\n",
        "                results[filename] = {\n",
        "                    'status': 'error',\n",
        "                    'data': None,\n",
        "                    'summary': None,\n",
        "                    'error': str(e)\n",
        "                }\n",
        "\n",
        "        # --- Final Processing Summary ---\n",
        "        total_elapsed_time = round(time.time() - total_start_time, 2)\n",
        "        logging.info(f\"\\nüéâ Processing Complete: {processed_files}/{len(eligible_files)} files successfully processed in {total_elapsed_time} seconds.\")\n",
        "\n",
        "        if errors:\n",
        "            logging.warning(\"\\n‚ö†Ô∏è Errors encountered during processing:\")\n",
        "            for error in errors:\n",
        "                logging.warning(f\"- {error}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "# üî• Main Execution Block (PLACE THIS AT THE END)\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Starting GelSetProcessor...\")\n",
        "\n",
        "    # Initialize the processor\n",
        "    processor = GelSetProcessor()\n",
        "\n",
        "    # Start processing all files\n",
        "    results = processor.process_all_files()\n",
        "\n",
        "    logging.info(\"‚úÖ Processing complete!\")"
      ]
    }
  ]
}