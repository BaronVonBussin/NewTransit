{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG1aizQjhm072m95WJ2vI8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/gel_set_test_20250105.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuI4z_rZ3gcq",
        "outputId": "91727ea7-2888-4cdb-c7b9-0a11c123c4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the DataFrame before normalization:\n",
            "'date' (length: 4)\n",
            "'open' (length: 4)\n",
            "'high' (length: 4)\n",
            "'low' (length: 3)\n",
            "'close' (length: 5)\n",
            "'month' (length: 5)\n",
            "'year' (length: 4)\n",
            "'week' (length: 4)\n",
            "'weekday' (length: 7)\n",
            "'lookup_month' (length: 12)\n",
            "'month_sequence' (length: 14)\n",
            "'week_sequence' (length: 13)\n",
            "'lookup_week' (length: 11)\n",
            "Columns after renaming: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month', 'month_sequence', 'week_sequence', 'lookup_week']\n",
            "Columns after merge: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month_child', 'month_sequence', 'week_sequence', 'lookup_week', 'lookup_month_parent', 'dur', 'open', 'high', 'low', 'close', 'serial_id', 'row_number', 'ticker', 'parent_lookup_date', 'trading_bop', 'create_date', 'create_time', 'jobname']\n",
            "Columns after initialization: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month_child', 'month_sequence', 'week_sequence', 'lookup_week', 'lookup_month_parent', 'dur', 'open', 'high', 'low', 'close', 'serial_id', 'row_number', 'ticker', 'parent_lookup_date', 'trading_bop', 'create_date', 'create_time', 'jobname', 'gel_reu_value', 'gel_red_value', 'gel_reu_flag', 'gel_red_flag', 'gel_re_flag', 'gel_twoway', 'gel_new_rpc', 'gel_total_rpc', 'gel_dir_state', 'gel_eob_dir', 'gel_fre_dir', 'gel_epc_dir']\n",
            "Sample gel_total_rpc values: 0    1\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "Name: gel_total_rpc, dtype: int64\n",
            "Columns in the DataFrame before normalization:\n",
            "'date' (length: 4)\n",
            "'open' (length: 4)\n",
            "'high' (length: 4)\n",
            "'low' (length: 3)\n",
            "'close' (length: 5)\n",
            "'month' (length: 5)\n",
            "'year' (length: 4)\n",
            "'week' (length: 4)\n",
            "'weekday' (length: 7)\n",
            "'lookup_month' (length: 12)\n",
            "'month_sequence' (length: 14)\n",
            "'week_sequence' (length: 13)\n",
            "'lookup_week' (length: 11)\n",
            "Columns after renaming: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month', 'month_sequence', 'week_sequence', 'lookup_week']\n",
            "Columns after merge: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month_child', 'month_sequence', 'week_sequence', 'lookup_week', 'lookup_month_parent', 'dur', 'open', 'high', 'low', 'close', 'serial_id', 'row_number', 'ticker', 'parent_lookup_date', 'trading_bop', 'create_date', 'create_time', 'jobname']\n",
            "Columns after initialization: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month_child', 'month_sequence', 'week_sequence', 'lookup_week', 'lookup_month_parent', 'dur', 'open', 'high', 'low', 'close', 'serial_id', 'row_number', 'ticker', 'parent_lookup_date', 'trading_bop', 'create_date', 'create_time', 'jobname', 'gel_reu_value', 'gel_red_value', 'gel_reu_flag', 'gel_red_flag', 'gel_re_flag', 'gel_twoway', 'gel_new_rpc', 'gel_total_rpc', 'gel_dir_state', 'gel_eob_dir', 'gel_fre_dir', 'gel_epc_dir']\n",
            "Sample gel_total_rpc values: 0    1\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "Name: gel_total_rpc, dtype: int64\n",
            "Columns in the DataFrame before normalization:\n",
            "'date' (length: 4)\n",
            "'open' (length: 4)\n",
            "'high' (length: 4)\n",
            "'low' (length: 3)\n",
            "'close' (length: 5)\n",
            "'month' (length: 5)\n",
            "'year' (length: 4)\n",
            "'week' (length: 4)\n",
            "'weekday' (length: 7)\n",
            "'lookup_month' (length: 12)\n",
            "'month_sequence' (length: 14)\n",
            "'week_sequence' (length: 13)\n",
            "'lookup_week' (length: 11)\n",
            "Columns after renaming: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month', 'month_sequence', 'week_sequence', 'lookup_week']\n",
            "Columns after merge: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month_child', 'month_sequence', 'week_sequence', 'lookup_week', 'lookup_month_parent', 'dur', 'open', 'high', 'low', 'close', 'serial_id', 'row_number', 'ticker', 'parent_lookup_date', 'trading_bop', 'create_date', 'create_time', 'jobname']\n",
            "Columns after initialization: ['date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday', 'lookup_month_child', 'month_sequence', 'week_sequence', 'lookup_week', 'lookup_month_parent', 'dur', 'open', 'high', 'low', 'close', 'serial_id', 'row_number', 'ticker', 'parent_lookup_date', 'trading_bop', 'create_date', 'create_time', 'jobname', 'gel_reu_value', 'gel_red_value', 'gel_reu_flag', 'gel_red_flag', 'gel_re_flag', 'gel_twoway', 'gel_new_rpc', 'gel_total_rpc', 'gel_dir_state', 'gel_eob_dir', 'gel_fre_dir', 'gel_epc_dir']\n",
            "Sample gel_total_rpc values: 0    1\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "Name: gel_total_rpc, dtype: int64\n",
            "Processing complete. Child and Parent data have been exported.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Parameters\n",
        "child_period = \"D\"  # Default\n",
        "parent_period = \"M\"  # Default\n",
        "jobname = \"BPB_20250104\"\n",
        "input_folder_child = \"/content/input_child\"\n",
        "input_folder_parent = \"/content/input_parent\"\n",
        "output_folder_gel_child = \"output_gel_child\"\n",
        "output_folder_gel_parent = \"output_gel_parent\"\n",
        "\n",
        "# Utility functions\n",
        "def validate_child_row(row):\n",
        "    \"\"\"Validate child row data.\"\"\"\n",
        "    try:\n",
        "        assert row['low'] <= row['open'] <= row['high'], \"Invalid open value\"\n",
        "        assert row['low'] <= row['close'] <= row['high'], \"Invalid close value\"\n",
        "        assert (row['high'] - row['low']) > 0, \"High-Low <= 0\"\n",
        "        assert not pd.isna(row).any(), \"Row contains NaN values\"\n",
        "        return True\n",
        "    except AssertionError as e:\n",
        "        return False\n",
        "\n",
        "def validate_parent_row(row, parent_period):\n",
        "    \"\"\"Validate parent row data.\"\"\"\n",
        "    try:\n",
        "        assert row['low'] <= row['open'] <= row['high'], \"Invalid open value\"\n",
        "        assert row['low'] <= row['close'] <= row['high'], \"Invalid close value\"\n",
        "        assert (row['high'] - row['low']) > 0, \"High-Low <= 0\"\n",
        "        if parent_period == \"M\":\n",
        "            assert 'lookup_month' in row, \"Missing lookup_month for parent row\"\n",
        "        elif parent_period == \"W\":\n",
        "            assert 'lookup_week' in row, \"Missing lookup_week for parent row\"\n",
        "        return True\n",
        "    except AssertionError as e:\n",
        "        return False\n",
        "\n",
        "def fetch_files(folder, file_type):\n",
        "    \"\"\"Fetch all CSV files from the specified folder.\"\"\"\n",
        "    return [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv') and file_type in f]\n",
        "\n",
        "# Processing functions\n",
        "def process_parent_file(file_path):\n",
        "    \"\"\"Process parent file and return a DataFrame.\"\"\"\n",
        "    file_name = os.path.basename(file_path)\n",
        "    ticker, period = file_name.split('_')[:2]\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Validate rows\n",
        "    df = df[df.apply(lambda row: validate_parent_row(row, parent_period), axis=1)]\n",
        "\n",
        "    # Add reference fields\n",
        "    df['serial_id'] = [f\"{datetime.now().strftime('%Y%m%d%H%M%S')}{i}\" for i in range(len(df))]\n",
        "    df['row_number'] = range(1, len(df) + 1)\n",
        "    df['ticker'] = ticker\n",
        "    df['parent_lookup_date'] = df['lookup_month'] if parent_period == \"M\" else df['lookup_week']\n",
        "    df['trading_bop'] = df['dur']  # Assuming duration corresponds to trading_bop for parent\n",
        "    df['create_date'] = datetime.now().date()\n",
        "    df['create_time'] = datetime.now().time()\n",
        "    df['jobname'] = jobname\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_child_file(file_path, parent_df):\n",
        "    \"\"\"Process child file and return a DataFrame.\"\"\"\n",
        "    file_name = os.path.basename(file_path)\n",
        "    ticker, period = file_name.split('_')[:2]\n",
        "\n",
        "    # Read file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Debug column names\n",
        "    print(\"Columns in the DataFrame before normalization:\")\n",
        "    for col in df.columns:\n",
        "        print(f\"'{col}' (length: {len(col)})\")\n",
        "\n",
        "    # Normalize column names\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    # Rename columns to avoid conflicts\n",
        "    df.rename(columns={\n",
        "        'open': 'open_fixed',\n",
        "        'high': 'high_fixed',\n",
        "        'low': 'low_fixed',\n",
        "        'close': 'close_fixed'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Verify renamed columns\n",
        "    print(\"Columns after renaming:\", df.columns.tolist())\n",
        "\n",
        "    # Validate rows\n",
        "    df = df[\n",
        "        (df['low_fixed'] <= df['open_fixed']) &\n",
        "        (df['open_fixed'] <= df['high_fixed']) &\n",
        "        (df['low_fixed'] <= df['close_fixed']) &\n",
        "        (df['close_fixed'] <= df['high_fixed']) &\n",
        "        ((df['high_fixed'] - df['low_fixed']) > 0)\n",
        "    ]\n",
        "\n",
        "    # Align with parent file\n",
        "    parent_lookup_field = 'lookup_month' if parent_period == \"M\" else 'lookup_week'\n",
        "    df = df.merge(parent_df, left_on=parent_lookup_field, right_on='parent_lookup_date', suffixes=('_child', '_parent'))\n",
        "\n",
        "    # Debug columns after merge\n",
        "    print(\"Columns after merge:\", df.columns.tolist())\n",
        "\n",
        "    # Define all expected fields\n",
        "    expected_fields = [\n",
        "        'date', 'open_fixed', 'high_fixed', 'low_fixed', 'close_fixed', 'month', 'year', 'week', 'weekday',\n",
        "        'lookup_month_child', 'lookup_week', 'dur', 'open', 'high', 'low', 'close', 'serial_id',\n",
        "        'row_number', 'ticker', 'parent_lookup_date', 'trading_bop', 'create_date', 'create_time',\n",
        "        'jobname', 'gel_reu_value', 'gel_red_value', 'gel_reu_flag', 'gel_red_flag', 'gel_re_flag',\n",
        "        'gel_twoway', 'gel_new_rpc', 'gel_total_rpc', 'gel_dir_state', 'gel_eob_dir', 'gel_fre_dir',\n",
        "        'gel_epc_dir'\n",
        "    ]\n",
        "\n",
        "    # Initialize missing fields\n",
        "    for field in expected_fields:\n",
        "        if field not in df.columns:\n",
        "            if field.endswith('_flag'):  # Flags are boolean\n",
        "                df[field] = False\n",
        "            elif field.startswith('gel_'):  # Derived numeric fields\n",
        "                df[field] = np.nan\n",
        "            else:  # Other fields, initialize with empty or NaN\n",
        "                df[field] = np.nan\n",
        "\n",
        "    print(\"Columns after initialization:\", df.columns.tolist())\n",
        "\n",
        "    # Debug missing fields\n",
        "    missing_fields = [field for field in expected_fields if field not in df.columns]\n",
        "    if missing_fields:\n",
        "        raise KeyError(f\"Missing fields in DataFrame: {missing_fields}\")\n",
        "\n",
        "    # Compute derived fields\n",
        "    df['gel_reu_value'] = np.where(\n",
        "        df['high_fixed'] > df['high_fixed'].shift(1),\n",
        "        df['high_fixed'] - df['high_fixed'].shift(1),\n",
        "        0\n",
        "    )\n",
        "    df['gel_red_value'] = np.where(\n",
        "        df['low_fixed'] < df['low_fixed'].shift(1),\n",
        "        df['low_fixed'].shift(1) - df['low_fixed'],\n",
        "        0\n",
        "    )\n",
        "    df['gel_reu_flag'] = df['gel_reu_value'] > 0\n",
        "    df['gel_red_flag'] = df['gel_red_value'] > 0\n",
        "    df['gel_re_flag'] = df['gel_reu_flag'] | df['gel_red_flag']\n",
        "\n",
        "    # Compute gel_eob_dir\n",
        "    df['gel_eob_dir'] = np.where(\n",
        "        df['gel_twoway'],\n",
        "        np.where(df['gel_epc_dir'] == \"U\", \"D\", \"U\"),\n",
        "        df['gel_fre_dir']\n",
        "    )\n",
        "\n",
        "    # Compute gel_dir_state\n",
        "    df['gel_dir_state'] = np.where(\n",
        "        df['trading_bop'] == 1,\n",
        "        df['gel_eob_dir'],  # Reset state for the first bar in a parent\n",
        "        df['gel_dir_state'].ffill()  # Forward fill for subsequent bars\n",
        "    )\n",
        "\n",
        "    # Compute gel_new_rpc and gel_total_rpc\n",
        "    df['gel_new_rpc'] = np.where(\n",
        "        df['trading_bop'] == 1,\n",
        "        np.where(df['gel_re_flag'], np.where(df['gel_twoway'], 2, 1), 0),\n",
        "        np.where(df['gel_twoway'], np.where(df['gel_dir_state'] == df['gel_epc_dir'], 2, 1), 0)\n",
        "    )\n",
        "    df['gel_total_rpc'] = df.groupby('parent_lookup_date')['gel_new_rpc'].cumsum()\n",
        "\n",
        "    print(\"Sample gel_total_rpc values:\", df['gel_total_rpc'].head())\n",
        "\n",
        "    # Summarize parent-child data\n",
        "    summary = df.groupby('parent_lookup_date').agg(\n",
        "        start_date=('date', 'min'),\n",
        "        end_date=('date', 'max'),\n",
        "        child_count=('row_number', 'count'),\n",
        "        reu_count=('gel_reu_value', 'sum'),\n",
        "        red_count=('gel_red_value', 'sum'),\n",
        "        total_rpc=('gel_total_rpc', 'max')\n",
        "    ).reset_index()\n",
        "    summary['create_date'] = datetime.now().date()\n",
        "    summary['create_time'] = datetime.now().time()\n",
        "    summary['jobname'] = jobname\n",
        "\n",
        "    return df, summary\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Process parent files\n",
        "    parent_files = fetch_files(input_folder_parent, parent_period)\n",
        "    all_parent_data = pd.concat([process_parent_file(f) for f in parent_files], ignore_index=True)\n",
        "\n",
        "    # Process child files\n",
        "    child_files = fetch_files(input_folder_child, child_period)\n",
        "    all_child_data = []\n",
        "    all_summaries = []\n",
        "    for f in child_files:\n",
        "        child_data, summary = process_child_file(f, all_parent_data)\n",
        "        all_child_data.append(child_data)\n",
        "        all_summaries.append(summary)\n",
        "\n",
        "    all_child_data = pd.concat(all_child_data, ignore_index=True)\n",
        "    all_summaries = pd.concat(all_summaries, ignore_index=True)\n",
        "\n",
        "    # Export files\n",
        "    os.makedirs(output_folder_gel_child, exist_ok=True)\n",
        "    os.makedirs(output_folder_gel_parent, exist_ok=True)\n",
        "\n",
        "    all_child_data.to_csv(os.path.join(output_folder_gel_child, f\"all_child_data_{child_period}.csv\"), index=False)\n",
        "    all_summaries.to_csv(os.path.join(output_folder_gel_parent, f\"all_parent_summary_{parent_period}.csv\"), index=False)\n",
        "\n",
        "    print(\"Processing complete. Child and Parent data have been exported.\")\n",
        "\n",
        "# Run\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFK38od78PPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}