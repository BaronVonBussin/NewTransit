{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHWsMSTXi59T9DgLCfsbd9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/basic_model_20241228.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWGou8ORY0VA",
        "outputId": "76ddf4e2-5bb7-4d19-dc5a-b86330f01b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3ec77be3c51c>:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df = pd.read_csv(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing MMM_D...\n",
            "Data exported for MMM_D to output_basicmodel/MMM_D_basicmodel.csv\n",
            "Summary exported for MMM_D to summary_basicmodel/MMM_D_basicmodel_summary.csv\n",
            "Processing AAPL_D...\n",
            "Data exported for AAPL_D to output_basicmodel/AAPL_D_basicmodel.csv\n",
            "Summary exported for AAPL_D to summary_basicmodel/AAPL_D_basicmodel_summary.csv\n",
            "Processing AFL_D...\n",
            "Data exported for AFL_D to output_basicmodel/AFL_D_basicmodel.csv\n",
            "Summary exported for AFL_D to summary_basicmodel/AFL_D_basicmodel_summary.csv\n",
            "Processing WTI_D...\n",
            "Data exported for WTI_D to output_basicmodel/WTI_D_basicmodel.csv\n",
            "Summary exported for WTI_D to summary_basicmodel/WTI_D_basicmodel_summary.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "\n",
        "class BasicModel:\n",
        "    def __init__(self, rolling_range_duration=4):\n",
        "        self.rolling_range_duration = rolling_range_duration\n",
        "\n",
        "    def read_csv_files(self, input_folder):\n",
        "        \"\"\"\n",
        "        Reads all CSV files from the input folder. Assumes files are named\n",
        "        TICKER_{temporal_period}.csv and contain columns: date, open, high, low, close.\n",
        "        \"\"\"\n",
        "        data = {}\n",
        "        for file in os.listdir(input_folder):\n",
        "            if file.endswith(\".csv\"):\n",
        "                ticker = os.path.splitext(file)[0]\n",
        "                df = pd.read_csv(\n",
        "                    os.path.join(input_folder, file),\n",
        "                    parse_dates=[\"date\"]\n",
        "                )\n",
        "                data[ticker] = df\n",
        "        return data\n",
        "\n",
        "    def calculate_metrics(self, df):\n",
        "        \"\"\"\n",
        "        Calculate metrics based on the rolling range and reference fields.\n",
        "        \"\"\"\n",
        "        df = df.sort_values(by=\"date\").reset_index(drop=True)\n",
        "\n",
        "        # Reference Fields\n",
        "        df[\"ref_open\"] = df[\"open\"].shift(self.rolling_range_duration)\n",
        "        df[\"ref_high\"] = df[\"high\"].rolling(self.rolling_range_duration).max().shift(1)\n",
        "        df[\"ref_low\"] = df[\"low\"].rolling(self.rolling_range_duration).min().shift(1)\n",
        "        df[\"ref_close\"] = df[\"close\"].shift(1)\n",
        "        df[\"ref_range\"] = df[\"ref_high\"] - df[\"ref_low\"]\n",
        "\n",
        "        # Percentage Range and Derived Fields\n",
        "        df[\"ref_percentr\"] = (df[\"ref_close\"] - df[\"ref_low\"]) / df[\"ref_range\"]\n",
        "        df[\"ref_epc\"] = np.ceil(\n",
        "            np.minimum((1 - df[\"ref_percentr\"]), df[\"ref_percentr\"]) / 0.1\n",
        "        )\n",
        "        df[\"ref_epc_dir\"] = np.where(\n",
        "            df[\"ref_percentr\"] == np.minimum((1 - df[\"ref_percentr\"]), df[\"ref_percentr\"]),\n",
        "            1,\n",
        "            0,\n",
        "        )\n",
        "        df[\"ref_ce_percent\"] = np.minimum((1 - df[\"ref_percentr\"]), df[\"ref_percentr\"])\n",
        "        df[\"ref_ce_value\"] = np.where(\n",
        "            df[\"ref_epc_dir\"] == 1,\n",
        "            df[\"ref_high\"] - df[\"ref_close\"],\n",
        "            df[\"ref_close\"] - df[\"ref_low\"],\n",
        "        )\n",
        "        df[\"ref_hp_flag\"] = np.where(df[\"ref_ce_percent\"] <= 0.25, 1, 0)\n",
        "\n",
        "        # Range Expansions\n",
        "        df[\"reu_value\"] = np.where(df[\"high\"] > df[\"ref_high\"], df[\"high\"] - df[\"ref_high\"], 0)\n",
        "        df[\"red_value\"] = np.where(df[\"low\"] < df[\"ref_low\"], df[\"ref_low\"] - df[\"low\"], 0)\n",
        "        df[\"reu_flag\"] = np.where(df[\"reu_value\"] > 0, 1, 0)\n",
        "        df[\"red_flag\"] = np.where(df[\"red_value\"] > 0, 1, 0)\n",
        "        df[\"re_value\"] = df[\"reu_value\"] + df[\"red_value\"]\n",
        "        df[\"re_flag\"] = np.where(df[\"re_value\"] > 0, 1, 0)\n",
        "\n",
        "        # Directional Changes\n",
        "        df[\"re_number_dir\"] = np.where(\n",
        "            (df[\"reu_value\"] > 0) & (df[\"red_value\"] > 0),\n",
        "            1,\n",
        "            0,\n",
        "        )\n",
        "        df[\"ere_e1\"] = np.where(\n",
        "            df[\"ref_epc_dir\"] == 1,\n",
        "            np.where(df[\"red_value\"] > 0, 1, 0),\n",
        "            np.where(df[\"reu_value\"] > 0, 1, 0),\n",
        "        )\n",
        "        df[\"ere_e2\"] = np.where(\n",
        "            df[\"ref_epc_dir\"] == 0,\n",
        "            np.where(df[\"red_value\"] > 0, 1, 0),\n",
        "            np.where(df[\"reu_value\"] > 0, 1, 0),\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def export_data(self, df, ticker, output_folder):\n",
        "        \"\"\"\n",
        "        Export the processed data to the output folder.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(output_folder):\n",
        "            os.makedirs(output_folder)\n",
        "        output_file = os.path.join(output_folder, f\"{ticker}_basicmodel.csv\")\n",
        "        df.to_csv(output_file, index=False)\n",
        "        print(f\"Data exported for {ticker} to {output_file}\")\n",
        "\n",
        "    def generate_summary(self, df, ticker, summary_folder):\n",
        "        \"\"\"\n",
        "        Generate a summary by year with totals and percentage breakdowns.\n",
        "        \"\"\"\n",
        "        df[\"year\"] = pd.to_datetime(df[\"date\"]).dt.year\n",
        "        summary = df.groupby(\"year\").agg(\n",
        "            total_rows=(\"date\", \"count\"),\n",
        "            total_re_flag=(\"re_flag\", \"sum\"),\n",
        "            total_reu_flag=(\"reu_flag\", \"sum\"),\n",
        "            total_red_flag=(\"red_flag\", \"sum\"),\n",
        "            reu_percent=(\"reu_flag\", lambda x: np.mean(x) * 100),\n",
        "            red_percent=(\"red_flag\", lambda x: np.mean(x) * 100),\n",
        "        ).reset_index()\n",
        "\n",
        "        if not os.path.exists(summary_folder):\n",
        "            os.makedirs(summary_folder)\n",
        "        summary_file = os.path.join(summary_folder, f\"{ticker}_basicmodel_summary.csv\")\n",
        "        summary.to_csv(summary_file, index=False)\n",
        "        print(f\"Summary exported for {ticker} to {summary_file}\")\n",
        "\n",
        "    def process_folder(self, input_folder, output_folder, summary_folder):\n",
        "        \"\"\"\n",
        "        Process all CSV files in the input folder and generate output and summary files.\n",
        "        \"\"\"\n",
        "        data = self.read_csv_files(input_folder)\n",
        "        for ticker, df in data.items():\n",
        "            print(f\"Processing {ticker}...\")\n",
        "            processed_data = self.calculate_metrics(df)\n",
        "            self.export_data(processed_data, ticker, output_folder)\n",
        "            self.generate_summary(processed_data, ticker, summary_folder)\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "input_folder = \"/content/input_basicmodel\"\n",
        "output_folder = \"output_basicmodel\"\n",
        "summary_folder = \"summary_basicmodel\"\n",
        "\n",
        "model = BasicModel(rolling_range_duration=1)\n",
        "model.process_folder(input_folder, output_folder, summary_folder)\n"
      ]
    }
  ]
}