{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnaxwpO/05KWvZvY84c1rl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/romulus_20250108.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Romulus"
      ],
      "metadata": {
        "id": "nN_yZ3L0Lly0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fixjdZ_-wtVP",
        "outputId": "52e4929d-145b-40da-909a-ad31be661acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11 files to process\n",
            "Processing MMM_D.csv...\n",
            "Exported test file to: /content/test/MMM_test1.csv\n",
            "Successfully processed MMM_D.csv\n",
            "Processing JPM_D.csv...\n",
            "Exported test file to: /content/test/JPM_test1.csv\n",
            "Successfully processed JPM_D.csv\n",
            "Processing GOLD_D.csv...\n",
            "Exported test file to: /content/test/GOLD_test1.csv\n",
            "Successfully processed GOLD_D.csv\n",
            "Processing COST_D.csv...\n",
            "Exported test file to: /content/test/COST_test1.csv\n",
            "Successfully processed COST_D.csv\n",
            "Processing IBM_D.csv...\n",
            "Exported test file to: /content/test/IBM_test1.csv\n",
            "Successfully processed IBM_D.csv\n",
            "Processing BAC_D.csv...\n",
            "Exported test file to: /content/test/BAC_test1.csv\n",
            "Successfully processed BAC_D.csv\n",
            "Processing AXP_D.csv...\n",
            "Exported test file to: /content/test/AXP_test1.csv\n",
            "Successfully processed AXP_D.csv\n",
            "Processing JNJ_D.csv...\n",
            "Exported test file to: /content/test/JNJ_test1.csv\n",
            "Successfully processed JNJ_D.csv\n",
            "Processing BA_D.csv...\n",
            "Exported test file to: /content/test/BA_test1.csv\n",
            "Successfully processed BA_D.csv\n",
            "Processing FCX_D.csv...\n",
            "Exported test file to: /content/test/FCX_test1.csv\n",
            "Successfully processed FCX_D.csv\n",
            "Processing ADBE_D.csv...\n",
            "Exported test file to: /content/test/ADBE_test1.csv\n",
            "Successfully processed ADBE_D.csv\n",
            "\n",
            "Processing Complete: 11/11 files\n",
            "\n",
            "Processing complete. Successfully processed 11/11 files.\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "GelSet Data Processor with Prior Parent Range Expansion Logic\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime\n",
        "from typing import Dict, Tuple, Optional, List, Any\n",
        "\n",
        "# Constants for configuration\n",
        "VALID_CHILD_PERIODS = ['D', 'W', 'M', 'Q']\n",
        "VALID_PARENT_PERIODS = ['W', 'M', 'Q', 'Y']\n",
        "DEFAULT_JOBNAME = 'gelset_20250107'\n",
        "\n",
        "class GelSetProcessor:\n",
        "    def __init__(self, input_dir=\"/content/input\",\n",
        "                 output_child_dir=\"/content/output_child\",\n",
        "                 output_parent_dir=\"/content/output_parent\",\n",
        "                 test_dir=\"/content/test\",\n",
        "                 child_period=\"D\",\n",
        "                 parent_period=\"M\",\n",
        "                 jobname=\"gelset_20250107\"):\n",
        "\n",
        "        self.input_dir = input_dir\n",
        "        self.output_child_dir = output_child_dir\n",
        "        self.output_parent_dir = output_parent_dir\n",
        "        self.test_dir = test_dir\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "\n",
        "        self.export_columns = [\n",
        "            # Original input fields\n",
        "            'ticker', 'date', 'parent', 'sequence', 'open', 'high', 'low', 'close', 'range', 'chg_h', 'chg_l', 'chg_h_percent', 'chg_l_percent',\n",
        "            'gap', 'island_gap', 'bpb_reu', 'bpb_red', 'bpb_reu_flag', 'bpb_red_flag', 'bpb_pripr', 'bpb_ce_percent', 'bpb_epc', 'bpb_epc_dir',\n",
        "            'bpb_e1_value', 'bpb_e2_value', 'bpb_re_flag', 'bpb_twoway',\n",
        "\n",
        "            # Round one fields\n",
        "            'gel_o', 'gel_h', 'gel_l',\n",
        "            'gel_reu', 'gel_red',\n",
        "            'gel_reu_flag', 'gel_red_flag',\n",
        "            'gel_pripr', 'gel_ce_percent', 'gel_epc', 'gel_epc_dir', 'gel_prirange',\n",
        "            'gel_e1_value', 'gel_e2_value',\n",
        "            'gel_re_flag', 'gel_twoway',\n",
        "            'gel_twoway_fre_dir', 'gel_oneway_fre_dir',\n",
        "            'gel_last_dir',\n",
        "            'gel_oco_flag', 'gel_noco_dir',\n",
        "\n",
        "            # Round two fields\n",
        "            'pph', 'ppl',\n",
        "            'icph', 'icpl',\n",
        "            'refh', 'refl',\n",
        "            'pp_reu', 'pp_red',\n",
        "            'pp_reu_flag', 'pp_red_flag',\n",
        "            'pp_co_flag', 'pp_noco_dir',\n",
        "        ]\n",
        "\n",
        "        # Create output directories--one for child, one for parent, and one test (can remove eventually)\n",
        "        for directory in [output_child_dir, output_parent_dir, test_dir]:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # All validation for input data--maybe ensure parsed child_period matches setting.\n",
        "    def validate_input_data(self, df):\n",
        "        \"\"\"Validate input data according to spec requirements\"\"\"\n",
        "        conditions = [\n",
        "            (df['open'] > 0, \"open must be greater than 0\"),\n",
        "            (df['high'] > 0, \"high must be greater than 0\"),\n",
        "            (df['low'] > 0, \"low must be greater than 0\"),\n",
        "            (df['close'] > 0, \"close must be greater than 0\"),\n",
        "            (df['low'] <= df['close'], \"low must be less than or equal to close\"),\n",
        "            (df['close'] <= df['high'], \"close must be less than or equal to high\"),\n",
        "            (df['low'] <= df['open'], \"low must be less than or equal to open\"),\n",
        "            (df['open'] <= df['high'], \"open must be less than or equal to high\"),\n",
        "            ((df['high'] - df['low']) != 0, \"high minus low cannot be zero\"),\n",
        "            (df['pph'] > 0, \"prior parent high must be greater than 0\"),\n",
        "            (df['ppl'] > 0, \"prior parent low must be greater than 0\"),\n",
        "            (df['ppc'] > 0, \"close must be greater than 0\"),\n",
        "            (df['ppl'] <= df['ppc'], \"low must be less than or equal to close\"),\n",
        "            (df['ppc'] <= df['pph'], \"close must be less than or equal to high\"),\n",
        "        ]\n",
        "\n",
        "        for condition, message in conditions:\n",
        "            if not condition.all():\n",
        "                raise ValueError(f\"Data validation failed: {message}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def process_round_one(self, data):\n",
        "        \"\"\"\n",
        "        First Round - Establish intra-group values and prior parent expansions\n",
        "        Implements the relationship between gel values, prior parent bounds, and reference values\n",
        "        \"\"\"\n",
        "        # Initialize output data list\n",
        "        output_data = []\n",
        "\n",
        "        # Initialize group state tracker--these are memory fields, initiate with None.\n",
        "        group_state = {\n",
        "            \"current_group\": None,\n",
        "            \"intra_group_h\": None,\n",
        "            \"intra_group_l\": None,\n",
        "            \"prior_gelo\": None,\n",
        "            \"prior_gelc\": None,\n",
        "            \"prior_gelh\": None,\n",
        "            \"prior_gell\": None,\n",
        "            \"prior_icph\": None,  # Track previous row's icph\n",
        "            \"prior_icpl\": None,   # Track previous row's icpl\n",
        "            \"pbh\": None,  # Track previous row's high\n",
        "            \"pbl\": None,   # Track previous row's low\n",
        "            \"pbc\": None,   # Track previous row's close\n",
        "        }\n",
        "\n",
        "        # Process each row\n",
        "        for index, row in data.iterrows():\n",
        "            # identify new parent group\n",
        "            if row[\"parent\"] != group_state[\"current_group\"]:\n",
        "                # Reset group state for new group\n",
        "                group_state[\"current_group\"] = row[\"parent\"]\n",
        "                group_state[\"intra_group_h\"] = row[\"high\"]\n",
        "                group_state[\"intra_group_l\"] = row[\"low\"]\n",
        "                group_state[\"gel_o\"] = row[\"open\"]\n",
        "                group_state[\"prior_gelc\"] = None\n",
        "                group_state[\"prior_gelh\"] = None\n",
        "                group_state[\"prior_gell\"] = None\n",
        "                group_state[\"prior_icph\"] = row[\"pph\"]  # For sequence 1, use pph\n",
        "                group_state[\"prior_icpl\"] = row[\"ppl\"]  # For sequence 1, use ppl\n",
        "                group_state[\"pbc\"] = None  # Add this line to initialize pbc\n",
        "\n",
        "                range_expansion_up = 0\n",
        "                range_expansion_down = 0\n",
        "                prior_percent_r = None\n",
        "            else:\n",
        "                # Calculate regular range expansions\n",
        "                if row[\"high\"] > group_state[\"intra_group_h\"]:\n",
        "                    range_expansion_up = row[\"high\"] - group_state[\"intra_group_h\"]\n",
        "                else:\n",
        "                    range_expansion_up = 0\n",
        "\n",
        "                if row[\"low\"] < group_state[\"intra_group_l\"]:\n",
        "                    range_expansion_down = group_state[\"intra_group_l\"] - row[\"low\"]\n",
        "                else:\n",
        "                    range_expansion_down = 0\n",
        "\n",
        "            range = row[\"high\"] - row[\"low\"]\n",
        "            chg_h = row[\"high\"] - row[\"open\"]\n",
        "            chg_l = row[\"open\"] - row[\"low\"]\n",
        "            chg_h_percent = (row[\"high\"] - row[\"open\"])/row[\"open\"]\n",
        "            chg_l_percent = (row[\"open\"] - row[\"low\"])/row[\"open\"]\n",
        "            body = max(row[\"open\"], row[\"close\"]) - min(row[\"open\"], row[\"close\"])\n",
        "            gap = abs(row[\"open\"] - group_state[\"pbc\"]) if group_state[\"pbc\"] is not None else None\n",
        "            island_gap = (\n",
        "                0 if group_state[\"pbh\"] is None or group_state[\"pbl\"] is None\n",
        "                else (row[\"open\"] - group_state[\"pbh\"]) if row[\"open\"] > group_state[\"pbh\"]\n",
        "                else (row[\"low\"] - row[\"open\"]) if row[\"open\"] < group_state[\"pbl\"]\n",
        "                else 0\n",
        "            )\n",
        "\n",
        "            # Update intra-group high and low: END OF ROW HIGH/LOW OF GEL\n",
        "            group_state[\"intra_group_h\"] = max(group_state[\"intra_group_h\"], row[\"high\"])\n",
        "            group_state[\"intra_group_l\"] = min(group_state[\"intra_group_l\"], row[\"low\"])\n",
        "\n",
        "            # Calculate icph/icpl (using gel values AT OPEN against parent bounds)\n",
        "            icph = max(group_state[\"intra_group_h\"], row[\"pph\"])\n",
        "            icpl = min(group_state[\"intra_group_l\"], row[\"ppl\"])\n",
        "\n",
        "            # Get refh/refl from prior state\n",
        "            refh = group_state[\"prior_icph\"]\n",
        "            refl = group_state[\"prior_icpl\"]\n",
        "\n",
        "            # Calculate prior parent range expansions\n",
        "            pp_reu = max(group_state[\"intra_group_h\"] - refh, 0) if refh is not None else 0\n",
        "            pp_red = max(refl - group_state[\"intra_group_l\"], 0) if refl is not None else 0\n",
        "\n",
        "            # Calculate prior parent range expansions\n",
        "            bpb_reu = max(row[\"high\"] - group_state[\"pbh\"], 0) if group_state[\"pbh\"] is not None else 0\n",
        "            bpb_red = max(group_state[\"pbl\"] - row[\"low\"], 0) if group_state[\"pbl\"] is not None else 0\n",
        "\n",
        "            # Calculate prior_percent_r\n",
        "            if group_state[\"prior_gelc\"] is not None and (group_state[\"prior_gelh\"] - group_state[\"prior_gell\"]) != 0:\n",
        "                prior_percent_r = (group_state[\"prior_gelc\"] - group_state[\"prior_gell\"]) / (\n",
        "                    group_state[\"prior_gelh\"] - group_state[\"prior_gell\"]\n",
        "                )\n",
        "            else:\n",
        "                prior_percent_r = None\n",
        "\n",
        "            if group_state[\"prior_gelc\"] is not None and group_state[\"prior_gelh\"] - group_state[\"prior_gell\"] != 0:\n",
        "                gel_prior_range = group_state[\"prior_gelh\"] - group_state[\"prior_gell\"]\n",
        "            else:\n",
        "                gel_prior_range = None\n",
        "\n",
        "            if group_state[\"pbc\"] is not None and (group_state[\"pbh\"] - group_state[\"pbl\"]) != 0:\n",
        "                bpb_pripr = (group_state[\"pbc\"] - group_state[\"pbl\"]) / (\n",
        "                    group_state[\"pbh\"] - group_state[\"pbl\"]\n",
        "                )\n",
        "            else:\n",
        "                bpb_pripr = None\n",
        "\n",
        "            # Update prior values for next row\n",
        "            #group_state[\"prior_gelo\"] = row[\"gelo\"]\n",
        "            group_state[\"prior_gelc\"] = row[\"close\"]\n",
        "            group_state[\"prior_gelh\"] = group_state[\"intra_group_h\"]\n",
        "            group_state[\"prior_gell\"] = group_state[\"intra_group_l\"]\n",
        "            group_state[\"prior_icph\"] = icph\n",
        "            group_state[\"prior_icpl\"] = icpl\n",
        "            group_state[\"pbc\"] = row[\"close\"]\n",
        "\n",
        "            # Create processed row\n",
        "            processed_row = row.to_dict()\n",
        "            processed_row.update({\n",
        "                \"gel_o\": group_state[\"gel_o\"],\n",
        "                \"gel_h\": group_state[\"intra_group_h\"],\n",
        "                \"gel_l\": group_state[\"intra_group_l\"],\n",
        "                \"gel_reu\": range_expansion_up,\n",
        "                \"gel_red\": range_expansion_down,\n",
        "                \"icph\": icph,\n",
        "                \"icpl\": icpl,\n",
        "                \"refh\": refh,\n",
        "                \"refl\": refl,\n",
        "                \"pp_reu\": pp_reu,\n",
        "                \"pp_red\": pp_red,\n",
        "                \"gel_pripr\": prior_percent_r,\n",
        "                \"gel_prirange\": gel_prior_range,\n",
        "                \"bpb_reu\": bpb_reu,\n",
        "                \"bpb_red\": bpb_red,\n",
        "                \"pbh\": group_state[\"pbh\"],\n",
        "                \"pbl\": group_state[\"pbl\"],\n",
        "                \"pbc\": group_state[\"pbc\"],\n",
        "                \"bpb_pripr\": bpb_pripr,\n",
        "                \"range\": range,\n",
        "                \"chg_h\": chg_h,\n",
        "                \"chg_l\": chg_l,\n",
        "                \"chg_h_percent\": chg_h_percent,\n",
        "                \"chg_l_percent\": chg_l_percent,\n",
        "                \"body\": body,\n",
        "                \"gap\": gap,\n",
        "                \"island_gap\": island_gap\n",
        "            })\n",
        "            output_data.append(processed_row)\n",
        "\n",
        "            group_state[\"pbh\"] = row[\"high\"]\n",
        "            group_state[\"pbl\"] = row[\"low\"]\n",
        "            group_state[\"pbc\"] = row[\"close\"]\n",
        "\n",
        "        return pd.DataFrame(output_data)\n",
        "\n",
        "    def process_round_two(self, data):\n",
        "        \"\"\"Second Round - Range Expansion\"\"\"\n",
        "        # Regular range expansions\n",
        "        data[\"bpb_reu_flag\"] = data.apply(\n",
        "            lambda row: True if row[\"bpb_reu\"] > 0 else False,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_red_flag\"] = data.apply(\n",
        "            lambda row: True if row[\"bpb_red\"] > 0 else False,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_ce_percent\"] = data.apply(\n",
        "            lambda row: None if pd.isna(row[\"bpb_pripr\"]) else\n",
        "                (1 - row[\"bpb_pripr\"] if row[\"bpb_pripr\"] >= 0.5 else row[\"bpb_pripr\"]),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_epc\"] = data.apply(\n",
        "            lambda row: None if pd.isna(row[\"bpb_ce_percent\"]) else\n",
        "                math.ceil(row[\"bpb_ce_percent\"] / 0.1),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_epc\"] = data.apply(\n",
        "            lambda row: None if pd.isna(row[\"bpb_ce_percent\"]) else\n",
        "                max(1, min(5, math.ceil(row[\"bpb_ce_percent\"] / 0.1))),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_epc_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (\"U\" if row[\"bpb_pripr\"] >= 0.5 else \"D\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_e1_value\"] = data.apply(\n",
        "            lambda row: row[\"bpb_reu\"] if row[\"bpb_pripr\"] >= 0.5 else row[\"bpb_red\"],\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_e2_value\"] = data.apply(\n",
        "            lambda row: row[\"bpb_reu\"] if row[\"bpb_pripr\"] < 0.5 else row[\"bpb_red\"],\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_re_flag\"] = data.apply(\n",
        "            lambda row: True if row[\"bpb_reu\"] + row[\"bpb_red\"] != 0 else False,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"bpb_twoway\"] = data.apply(\n",
        "            lambda row: (True if row[\"bpb_red_flag\"] == True else False) if row[\"bpb_reu_flag\"] == True else False,\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_reu_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"gel_reu\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_red_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"gel_red\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        # Prior parent range expansions\n",
        "        data[\"pp_reu_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"pp_reu\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"pp_red_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (True if row[\"pp_red\"] > 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_ce_percent\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (1 - row[\"gel_pripr\"] if row[\"gel_pripr\"] >= 0.5 else row[\"gel_pripr\"]),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_epc\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (math.ceil((1 - row[\"gel_pripr\"]) / 0.1) if row[\"gel_pripr\"] >= 0.5\n",
        "                 else math.ceil(row[\"gel_pripr\"] / 0.1)),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_epc_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else (\"U\" if row[\"gel_pripr\"] >= 0.5 else \"D\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_e1_value\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (row[\"gel_reu\"] if row[\"gel_pripr\"] >= 0.5 else row[\"gel_red\"]),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_e2_value\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (row[\"gel_reu\"] if row[\"gel_pripr\"] < 0.5 else row[\"gel_red\"]),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_re_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (True if row[\"gel_reu\"] + row[\"gel_red\"] != 0 else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_twoway\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                ((True if row[\"gel_red_flag\"] == True else False) if row[\"gel_reu_flag\"] == True else False),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_twoway_fre_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (row[\"gel_epc_dir\"] if row[\"gel_twoway\"] == True else \"N\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_oneway_fre_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                ((\"D\" if row[\"gel_red_flag\"] == True else \"N\") if row[\"gel_reu_flag\"] == False else \"U\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"gel_last_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (\"D\" if row[\"gel_twoway\"] and row[\"gel_twoway_fre_dir\"] == \"U\" else\n",
        "                 \"U\" if row[\"gel_twoway\"] and row[\"gel_twoway_fre_dir\"] == \"D\" else\n",
        "                 \"U\" if row[\"gel_reu_flag\"] else\n",
        "                 \"D\" if row[\"gel_red_flag\"] else\n",
        "                 \"N\"),\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"gel_oco_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (False if row[\"low\"] > row[\"gel_o\"] else False if row[\"high\"] < row[\"gel_o\"] else True),\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"gel_noco_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (None if row[\"gel_oco_flag\"] == True else \"A\" if row[\"low\"] > row[\"gel_o\"] else \"B\"),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        data[\"pp_co_flag\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (False if row[\"low\"] > row[\"pph\"] else False if row[\"high\"] < row[\"ppl\"] else True),\n",
        "            axis=1\n",
        "        )\n",
        "        data[\"pp_noco_dir\"] = data.apply(\n",
        "            lambda row: None if row[\"sequence\"] == 1 else\n",
        "                (None if row[\"pp_co_flag\"] == True else \"A\" if row[\"low\"] > row[\"pph\"] else \"B\"),\n",
        "            axis=1\n",
        "        )\n",
        "        return data\n",
        "\n",
        "    def process_round_three(self, data):\n",
        "        \"\"\"Third Round - RPC States\"\"\"\n",
        "        state_tracker = {\n",
        "            \"prior_gel_dir_state\": None,\n",
        "            \"prior_gel_last_dir\": None,\n",
        "            \"prior_gel_rpc_total\": 0,\n",
        "        }\n",
        "\n",
        "        for index, row in data.iterrows():\n",
        "            sequence = row[\"sequence\"]\n",
        "            gel_last_dir = row[\"gel_last_dir\"]\n",
        "            gel_twoway = row[\"gel_twoway\"]\n",
        "\n",
        "            if sequence == 1:\n",
        "                gel_dir_state = None\n",
        "                gel_rpc = None\n",
        "                gel_rpc_total = None\n",
        "            else:\n",
        "                # Calculate gel_dir_state\n",
        "                if gel_last_dir != \"N\":\n",
        "                    gel_dir_state = gel_last_dir\n",
        "                else:\n",
        "                    gel_dir_state = state_tracker[\"prior_gel_dir_state\"]\n",
        "\n",
        "                # Calculate gel_rpc\n",
        "                if sequence == 2 and gel_twoway:\n",
        "                    gel_rpc = 2\n",
        "                elif gel_last_dir == \"N\":\n",
        "                    gel_rpc = 0\n",
        "                elif gel_last_dir == state_tracker[\"prior_gel_last_dir\"] and gel_twoway:\n",
        "                    gel_rpc = 2\n",
        "                elif gel_last_dir != state_tracker[\"prior_gel_dir_state\"] and gel_last_dir != \"N\":\n",
        "                    gel_rpc = 1\n",
        "                else:\n",
        "                    gel_rpc = 0\n",
        "\n",
        "                # Calculate gel_rpc_total\n",
        "                gel_rpc_total = (gel_rpc or 0) + (state_tracker[\"prior_gel_rpc_total\"] or 0)\n",
        "\n",
        "            # Update state tracker\n",
        "            state_tracker[\"prior_gel_dir_state\"] = gel_dir_state\n",
        "            state_tracker[\"prior_gel_last_dir\"] = gel_last_dir\n",
        "            state_tracker[\"prior_gel_rpc_total\"] = gel_rpc_total\n",
        "\n",
        "            # Update DataFrame\n",
        "            data.loc[index, \"gel_dir_state\"] = gel_dir_state\n",
        "            data.loc[index, \"gel_rpc\"] = gel_rpc\n",
        "            #data.loc[index, \"gel_rpc_total\"] = gel_rpc_total\n",
        "\n",
        "        return data\n",
        "\n",
        "    def generate_summary(self, data, ticker):\n",
        "        \"\"\"Generate summary data for parent periods\"\"\"\n",
        "        summary_data = []\n",
        "\n",
        "        for parent, group in data.groupby(\"parent\"):\n",
        "            lookup_date = group[\"parent\"].iloc[0]\n",
        "            duration = len(group)\n",
        "            parent_high = group[\"gel_h\"].max()\n",
        "            parent_low = group[\"gel_l\"].min()\n",
        "            bar_of_h = group.loc[group[\"gel_h\"].idxmax(), \"sequence\"]\n",
        "            bar_of_l = group.loc[group[\"gel_l\"].idxmin(), \"sequence\"]\n",
        "            bpb_reu_count = group[\"bpb_reu_flag\"].sum()\n",
        "            bpb_red_count = group[\"bpb_red_flag\"].sum()\n",
        "            bpb_reu_max = group[\"bpb_reu\"].max()\n",
        "            bpb_red_max = group[\"bpb_red\"].max()\n",
        "            bpb_re_count = group[\"bpb_re_flag\"].sum()\n",
        "            bpb_no_re_count = duration - group[\"bpb_re_flag\"].sum()\n",
        "            bpb_twoway_count = group[\"bpb_twoway\"].sum()\n",
        "            range_max = group[\"range\"].max()\n",
        "            range_avg = group[\"range\"].mean()\n",
        "            bpb_re_count = group[\"bpb_re_flag\"].sum()\n",
        "            bpb_no_re_count = duration - group[\"bpb_re_flag\"].sum()\n",
        "            bpb_twoway_count = group[\"bpb_twoway\"].sum()\n",
        "            A1 = min(bar_of_h, bar_of_l)\n",
        "            A2 = max(bar_of_h, bar_of_l)\n",
        "            gel_reu_count = group[\"gel_reu_flag\"].sum()\n",
        "            gel_red_count = group[\"gel_red_flag\"].sum()\n",
        "            gel_reu_first = group.loc[group[\"gel_reu_flag\"] == True, \"sequence\"].min() if gel_reu_count > 0 else None\n",
        "            gel_reu_last = group.loc[group[\"gel_reu_flag\"] == True, \"sequence\"].max() if gel_reu_count > 0 else None\n",
        "            gel_red_first = group.loc[group[\"gel_red_flag\"] == True, \"sequence\"].min() if gel_red_count > 0 else None\n",
        "            gel_red_last = group.loc[group[\"gel_red_flag\"] == True, \"sequence\"].max() if gel_red_count > 0 else None\n",
        "\n",
        "            gel_rpc_total = group[\"gel_rpc\"].sum()\n",
        "\n",
        "            pp_reu_count = group[\"pp_reu_flag\"].sum()\n",
        "            pp_red_count = group[\"pp_red_flag\"].sum()\n",
        "            pp_reu_first = group.loc[group[\"pp_reu_flag\"] == True, \"sequence\"].min() if pp_reu_count > 0 else None\n",
        "            pp_reu_last = group.loc[group[\"pp_reu_flag\"] == True, \"sequence\"].max() if pp_reu_count > 0 else None\n",
        "            pp_red_first = group.loc[group[\"pp_red_flag\"] == True, \"sequence\"].min() if pp_red_count > 0 else None\n",
        "            pp_red_last = group.loc[group[\"pp_red_flag\"] == True, \"sequence\"].max() if pp_red_count > 0 else None\n",
        "\n",
        "            summary_data.append({\n",
        "                \"ticker\": ticker,\n",
        "                \"parent\": lookup_date,\n",
        "                \"duration\": duration,\n",
        "                \"child_period\": self.child_period,\n",
        "                \"parent_period\": self.parent_period,\n",
        "                \"range_max\": range_max,\n",
        "                \"range_avg\": range_avg,\n",
        "                \"bpb_reu_count\": bpb_reu_count,\n",
        "                \"bpb_red_count\": bpb_red_count,\n",
        "                \"bpb_reu_max\": bpb_reu_max,\n",
        "                \"bpb_red_max\": bpb_red_max,\n",
        "                \"bpb_re_count\": bpb_re_count,\n",
        "                \"bpb_no_re_count\": bpb_no_re_count,\n",
        "                \"bpb_twoway_count\": bpb_twoway_count,\n",
        "                \"parent_high\": parent_high,\n",
        "                \"parent_low\": parent_low,\n",
        "                \"bar_of_h\": bar_of_h,\n",
        "                \"bar_of_l\": bar_of_l,\n",
        "                \"A1\": min(bar_of_h, bar_of_l),\n",
        "                \"A2\": max(bar_of_h, bar_of_l),\n",
        "                \"gel_reu_count\": gel_reu_count,\n",
        "                \"gel_red_count\": gel_red_count,\n",
        "                \"gel_reu_first\": gel_reu_first,\n",
        "                \"gel_reu_last\": gel_reu_last,\n",
        "                \"gel_red_first\": gel_red_first,\n",
        "                \"gel_red_last\": gel_red_last,\n",
        "                \"pp_reu_count\": pp_reu_count,\n",
        "                \"pp_red_count\": pp_red_count,\n",
        "                \"pp_reu_first\": pp_reu_first,\n",
        "                \"pp_reu_last\": pp_reu_last,\n",
        "                \"pp_red_first\": pp_red_first,\n",
        "                \"pp_red_last\": pp_red_last,\n",
        "                \"gel_rpc_total\": gel_rpc_total,\n",
        "                \"create_date\": datetime.now().date(),\n",
        "                \"create_time\": datetime.now().time(),\n",
        "                \"jobname\": self.jobname\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(summary_data)\n",
        "\n",
        "    def export_test_file(self, data, ticker):\n",
        "        \"\"\"Export all fields after round two processing to a test file\"\"\"\n",
        "        # All fields present at this point\n",
        "        data['ticker'] = ticker\n",
        "        columns = [\n",
        "            # Original input fields\n",
        "            'ticker', 'date', 'parent', 'sequence', 'open', 'high', 'low', 'close', 'range', 'chg_h', 'chg_l', 'chg_h_percent', 'chg_l_percent',\n",
        "            'gap', 'island_gap', 'bpb_reu', 'bpb_red', 'bpb_reu_flag', 'bpb_red_flag', 'bpb_pripr', 'bpb_ce_percent', 'bpb_epc', 'bpb_epc_dir',\n",
        "            'bpb_e1_value', 'bpb_e2_value', 'bpb_re_flag', 'bpb_twoway',\n",
        "\n",
        "            # Round one fields\n",
        "            'gel_o', 'gel_h', 'gel_l',\n",
        "            'gel_reu', 'gel_red',\n",
        "            'gel_reu_flag', 'gel_red_flag',\n",
        "            'gel_pripr', 'gel_ce_percent', 'gel_epc', 'gel_epc_dir', 'gel_prirange',\n",
        "            'gel_e1_value', 'gel_e2_value',\n",
        "            'gel_re_flag', 'gel_twoway',\n",
        "            'gel_twoway_fre_dir', 'gel_oneway_fre_dir',\n",
        "            'gel_last_dir',\n",
        "            'gel_oco_flag', 'gel_noco_dir',\n",
        "\n",
        "            # Round two fields\n",
        "            'pph', 'ppl',\n",
        "            'icph', 'icpl',\n",
        "            'refh', 'refl',\n",
        "            'pp_reu', 'pp_red',\n",
        "            'pp_reu_flag', 'pp_red_flag',\n",
        "            'pp_co_flag', 'pp_noco_dir',\n",
        "        ]\n",
        "\n",
        "        # Export to CSV\n",
        "        output_file = os.path.join(self.test_dir, f\"{ticker}_test1.csv\")\n",
        "        data.to_csv(output_file, columns=self.export_columns, index=False)\n",
        "        print(f\"Exported test file to: {output_file}\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    def process_file(self, filename):\n",
        "        \"\"\"Process a single input file through all rounds\"\"\"\n",
        "        # Extract ticker from filename\n",
        "        ticker = filename.split('_')[0]\n",
        "\n",
        "        # Read input file\n",
        "        input_path = os.path.join(self.input_dir, filename)\n",
        "        data = pd.read_csv(input_path)\n",
        "\n",
        "        # Validate input data\n",
        "        self.validate_input_data(data)\n",
        "\n",
        "        # Add required columns\n",
        "        data['child_period'] = self.child_period\n",
        "        data['parent_period'] = self.parent_period\n",
        "        data['jobname'] = self.jobname\n",
        "\n",
        "        # Process through rounds\n",
        "        data = self.process_round_one(data)\n",
        "        data = self.process_round_two(data)\n",
        "        data = self.process_round_three(data)\n",
        "\n",
        "        # Generate summary\n",
        "        summary_df = self.generate_summary(data, ticker)\n",
        "\n",
        "        # Export test file after round two\n",
        "        data = self.export_test_file(data, ticker)\n",
        "\n",
        "        # Export child data\n",
        "        child_filename = f\"{ticker}_{self.child_period}_gel.csv\"\n",
        "        child_path = os.path.join(self.output_child_dir, child_filename)\n",
        "        data.to_csv(child_path, columns=self.export_columns, index=False)\n",
        "\n",
        "        # Export summary data\n",
        "        summary_filename = f\"{ticker}_{self.parent_period}_gel.csv\"\n",
        "        summary_path = os.path.join(self.output_parent_dir, summary_filename)\n",
        "        summary_df.to_csv(summary_path, index=False)\n",
        "\n",
        "        return data, summary_df\n",
        "\n",
        "    def process_all_files(self):\n",
        "        \"\"\"Process all eligible files in the input directory\"\"\"\n",
        "        if not os.path.exists(self.input_dir):\n",
        "            raise FileNotFoundError(f\"Input directory {self.input_dir} does not exist\")\n",
        "\n",
        "        results = {}\n",
        "        processed_files = 0\n",
        "        errors = []\n",
        "\n",
        "        # Get list of eligible files\n",
        "        eligible_files = [f for f in os.listdir(self.input_dir)\n",
        "                         if f.endswith(f\"_{self.child_period}.csv\")]\n",
        "\n",
        "        if not eligible_files:\n",
        "            print(f\"No eligible files found with pattern *_{self.child_period}.csv\")\n",
        "            return results\n",
        "\n",
        "        print(f\"Found {len(eligible_files)} files to process\")\n",
        "\n",
        "        for filename in eligible_files:\n",
        "            try:\n",
        "                print(f\"Processing {filename}...\")\n",
        "                data = self.process_file(filename)\n",
        "                results[filename] = {\n",
        "                    'status': 'success',\n",
        "                    'data': data,\n",
        "                    'error': None\n",
        "                }\n",
        "                processed_files += 1\n",
        "                print(f\"Successfully processed {filename}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"Error processing {filename}: {str(e)}\"\n",
        "                print(error_msg)\n",
        "                errors.append(error_msg)\n",
        "                results[filename] = {\n",
        "                    'status': 'error',\n",
        "                    'data': None,\n",
        "                    'error': str(e)\n",
        "                }\n",
        "\n",
        "        print(f\"\\nProcessing Complete: {processed_files}/{len(eligible_files)} files\")\n",
        "        if errors:\n",
        "            print(\"\\nErrors encountered:\")\n",
        "            for error in errors:\n",
        "                print(f\"- {error}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "def validate_periods(child_period: str, parent_period: str) -> bool:\n",
        "\n",
        "    #Validate the child and parent period combinations.\n",
        "    #Args:\n",
        "    #    child_period (str): The child period code (D, W, M, Q)\n",
        "    #    parent_period (str): The parent period code (W, M, Q, Y)\n",
        "    #Returns:\n",
        "    #    bool: True if valid, raises ValueError if invalid\n",
        "    #Raises:\n",
        "    #    ValueError: If period combination is invalid\n",
        "\n",
        "    if child_period not in VALID_CHILD_PERIODS:\n",
        "        raise ValueError(f\"Invalid child_period: {child_period}. Must be one of {VALID_CHILD_PERIODS}\")\n",
        "\n",
        "    if parent_period not in VALID_PARENT_PERIODS:\n",
        "        raise ValueError(f\"Invalid parent_period: {parent_period}. Must be one of {VALID_PARENT_PERIODS}\")\n",
        "\n",
        "    # Check valid combinations\n",
        "    period_order = ['D', 'W', 'M', 'Q', 'Y']\n",
        "    child_idx = period_order.index(child_period)\n",
        "    parent_idx = period_order.index(parent_period)\n",
        "\n",
        "    if child_idx >= parent_idx:\n",
        "        raise ValueError(f\"Invalid period combination: {child_period} -> {parent_period}. Child period must be smaller than parent period.\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def setup_logging(log_dir: str = \"logs\") -> None:\n",
        "    \"\"\"Set up logging configuration.\"\"\"\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    log_file = os.path.join(log_dir, f\"gelset_processing_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "\n",
        "    # Configure logging (basic setup - can be enhanced as needed)\n",
        "    import logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file),\n",
        "            logging.StreamHandler(sys.stdout)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def process_gelset_data(\n",
        "    input_dir: str = '/content/input',\n",
        "    output_child_dir: str = '/content/output_child',\n",
        "    output_parent_dir: str = '/content/output_parent',\n",
        "    child_period: str = 'D',\n",
        "    parent_period: str = 'M',\n",
        "    jobname: str = DEFAULT_JOBNAME\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Process GelSet data with the given parameters.\n",
        "\n",
        "    Args:\n",
        "        input_dir: Directory containing input CSV files\n",
        "        output_child_dir: Directory for child output files\n",
        "        output_parent_dir: Directory for parent summary files\n",
        "        child_period: Child period code (D, W, M, Q)\n",
        "        parent_period: Parent period code (W, M, Q, Y)\n",
        "        jobname: Job name for tracking\n",
        "\n",
        "    Returns:\n",
        "        Dict containing processing results\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Validate period combination\n",
        "        validate_periods(child_period, parent_period)\n",
        "\n",
        "        # Initialize processor\n",
        "        processor = GelSetProcessor(\n",
        "            input_dir=input_dir,\n",
        "            output_child_dir=output_child_dir,\n",
        "            output_parent_dir=output_parent_dir,\n",
        "            child_period=child_period,\n",
        "            parent_period=parent_period,\n",
        "            jobname=jobname\n",
        "        )\n",
        "\n",
        "        # Process files\n",
        "        results = processor.process_all_files()\n",
        "\n",
        "        # Report results\n",
        "        success_count = sum(1 for r in results.values() if r['status'] == 'success')\n",
        "        print(f\"\\nProcessing complete. Successfully processed {success_count}/{len(results)} files.\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during processing: {str(e)}\")\n",
        "        return {'error': str(e)}\n",
        "\n",
        "# Example usage in Jupyter/Colab:\n",
        "if __name__ == \"__main__\":\n",
        "    # For notebooks, just run with default parameters\n",
        "    results = process_gelset_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zip_and_download(source_dir, period):\n",
        "    # Count files\n",
        "    file_count = len([name for name in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, name))])\n",
        "    print(f\"Found {file_count} {period} files\")\n",
        "\n",
        "    # Create zip file\n",
        "    zip_filename = f'{period}_files.zip'\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for file in os.listdir(source_dir):\n",
        "            file_path = os.path.join(source_dir, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                zipf.write(file_path, arcname=file)\n",
        "\n",
        "    # Download zip file\n",
        "    files.download(zip_filename)\n",
        "    print(f\"Downloaded {zip_filename}\")\n",
        "\n",
        "# Create and download zips for each directory\n",
        "print(\"\\nCreating and downloading zip files...\\n\")\n",
        "zip_and_download('/content/output_child', 'child')\n",
        "zip_and_download('/content/output_parent', 'parent')\n",
        "#zip_and_download('/content/testone', 'test')"
      ],
      "metadata": {
        "id": "L0HcquBDBb0T",
        "outputId": "cfcff67d-0584-4ba3-aec7-bade9cd274cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating and downloading zip files...\n",
            "\n",
            "Found 73 child files\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ffbead9-d2c3-4346-844d-2a08f3f85ac8\", \"child_files.zip\", 163431513)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded child_files.zip\n",
            "Found 73 parent files\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_987fc984-5a7b-4c0f-8800-d306c92233d8\", \"parent_files.zip\", 1910813)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded parent_files.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Use same tickers as cell 1\n",
        "tickers = [\"SPY\", \"TQQQ\", \"QQQ\", \"SQQQ\", \"EEM\", \"XLF\", \"GLD\", \"XLE\", \"EFA\", \"GDX\", \"XLK\",\n",
        "           \"TLT\", \"XLV\", \"FXI\", \"XLY\",\n",
        "           \"XLI\", \"XLU\", \"XLP\", \"XLB\"]\n",
        "\n",
        "# Create export directories if they don't exist\n",
        "os.makedirs('/content/export_daily', exist_ok=True)\n",
        "os.makedirs('/content/export_weekly', exist_ok=True)\n",
        "os.makedirs('/content/export_monthly', exist_ok=True)\n",
        "\n",
        "def validate_data(df, ticker):\n",
        "    \"\"\"Validate OHLC data for errors\"\"\"\n",
        "    # Store original row count\n",
        "    original_count = len(df)\n",
        "\n",
        "    # Round all values to 4 decimal places\n",
        "    for col in ['Open', 'High', 'Low', 'Close']:\n",
        "        df[col] = df[col].round(4)\n",
        "\n",
        "    # Create mask for each condition\n",
        "    non_zero = (df['Open'] > 0) & (df['High'] > 0) & (df['Low'] > 0) & (df['Close'] > 0)\n",
        "    valid_low = (df['Low'] <= df['Close']) & (df['Low'] <= df['Open'])\n",
        "    valid_high = (df['High'] >= df['Close']) & (df['High'] >= df['Open'])\n",
        "    valid_range = (df['High'] - df['Low']) > 0\n",
        "\n",
        "    # Combine all conditions\n",
        "    valid_rows = non_zero & valid_low & valid_high & valid_range\n",
        "\n",
        "    # Filter data\n",
        "    df_clean = df[valid_rows].copy()\n",
        "\n",
        "    # Report removed rows\n",
        "    removed_count = original_count - len(df_clean)\n",
        "    if removed_count > 0:\n",
        "        print(f\"{ticker}: Removed {removed_count} invalid rows out of {original_count}\")\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "def load_data(ticker):\n",
        "    file_path = f'{ticker}_OHLC.csv'\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Ensure column order for daily data\n",
        "    column_order = ['Date', 'Open', 'High', 'Low', 'Close']\n",
        "    df = df[column_order]\n",
        "\n",
        "    # Validate and clean data before proceeding\n",
        "    df = validate_data(df, ticker)\n",
        "\n",
        "    return df\n",
        "\n",
        "def aggregate_data(df):\n",
        "    agg_rules = {\n",
        "        'Open': 'first',\n",
        "        'High': 'max',\n",
        "        'Low': 'min',\n",
        "        'Close': 'last'\n",
        "    }\n",
        "\n",
        "    weekly_data = df.set_index('Date').resample('W').agg(agg_rules).reset_index()\n",
        "    monthly_data = df.set_index('Date').resample('M').agg(agg_rules).reset_index()\n",
        "\n",
        "    column_order = ['Date', 'Open', 'High', 'Low', 'Close']\n",
        "    weekly_data = weekly_data[column_order]\n",
        "    monthly_data = monthly_data[column_order]\n",
        "\n",
        "    # Validate aggregated data\n",
        "    weekly_data = validate_data(weekly_data, f\"{df.name}_weekly\")\n",
        "    monthly_data = validate_data(monthly_data, f\"{df.name}_monthly\")\n",
        "\n",
        "    return weekly_data, monthly_data\n",
        "\n",
        "def save_to_csv(data, ticker, period):\n",
        "    if period == 'daily':\n",
        "        file_path = f'/content/export_daily/{ticker}_daily.csv'\n",
        "    elif period == 'weekly':\n",
        "        file_path = f'/content/export_weekly/{ticker}_weekly.csv'\n",
        "    else:\n",
        "        file_path = f'/content/export_monthly/{ticker}_monthly.csv'\n",
        "\n",
        "    data.to_csv(file_path, index=False)\n",
        "    print(f\"Saved {file_path}\")\n",
        "\n",
        "def process_ticker(ticker):\n",
        "    print(f\"Processing {ticker}...\")\n",
        "    try:\n",
        "        # Load and save daily data\n",
        "        df = load_data(ticker)\n",
        "        df.name = ticker  # Add name attribute for reference in aggregation\n",
        "\n",
        "        if len(df) > 0:  # Only proceed if we have valid data\n",
        "            save_to_csv(df, ticker, 'daily')\n",
        "\n",
        "            # Process and save weekly/monthly data\n",
        "            weekly_data, monthly_data = aggregate_data(df)\n",
        "\n",
        "            if len(weekly_data) > 0:\n",
        "                save_to_csv(weekly_data, ticker, 'weekly')\n",
        "            if len(monthly_data) > 0:\n",
        "                save_to_csv(monthly_data, ticker, 'monthly')\n",
        "\n",
        "            print(f\"Successfully processed {ticker}\")\n",
        "        else:\n",
        "            print(f\"No valid data for {ticker}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {ticker}: {str(e)}\")\n",
        "\n",
        "# Process all tickers\n",
        "for ticker in tickers:\n",
        "    process_ticker(ticker)"
      ],
      "metadata": {
        "id": "EqxRbHXrBJ1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Use same tickers as cell 1\n",
        "tickers = [\"SPY\", \"TQQQ\", \"QQQ\", \"SQQQ\", \"EEM\", \"XLF\", \"GLD\", \"XLE\", \"EFA\", \"GDX\", \"XLK\",\n",
        "           \"TLT\", \"XLV\", \"FXI\", \"XLY\",\n",
        "           \"XLI\", \"XLU\", \"XLP\", \"XLB\"]\n",
        "\n",
        "# Create export directories if they don't exist\n",
        "os.makedirs('/content/export_daily', exist_ok=True)\n",
        "os.makedirs('/content/export_weekly', exist_ok=True)\n",
        "os.makedirs('/content/export_monthly', exist_ok=True)\n",
        "\n",
        "def validate_data(df, ticker):\n",
        "    \"\"\"Validate OHLC data for errors\"\"\"\n",
        "    # Store original row count\n",
        "    original_count = len(df)\n",
        "\n",
        "    # Round all values to 4 decimal places\n",
        "    for col in ['Open', 'High', 'Low', 'Close']:\n",
        "        df[col] = df[col].round(4)\n",
        "\n",
        "    # Create mask for each condition\n",
        "    non_zero = (df['Open'] > 0) & (df['High'] > 0) & (df['Low'] > 0) & (df['Close'] > 0)\n",
        "    valid_low = (df['Low'] <= df['Close']) & (df['Low'] <= df['Open'])\n",
        "    valid_high = (df['High'] >= df['Close']) & (df['High'] >= df['Open'])\n",
        "    valid_range = (df['High'] - df['Low']) > 0\n",
        "\n",
        "    # Combine all conditions\n",
        "    valid_rows = non_zero & valid_low & valid_high & valid_range\n",
        "\n",
        "    # Filter data\n",
        "    df_clean = df[valid_rows].copy()\n",
        "\n",
        "    # Report removed rows\n",
        "    removed_count = original_count - len(df_clean)\n",
        "    if removed_count > 0:\n",
        "        print(f\"{ticker}: Removed {removed_count} invalid rows out of {original_count}\")\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "def load_data(ticker):\n",
        "    file_path = f'{ticker}_OHLC.csv'\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Ensure column order for daily data\n",
        "    column_order = ['Date', 'Open', 'High', 'Low', 'Close']\n",
        "    df = df[column_order]\n",
        "\n",
        "    # Validate and clean data before proceeding\n",
        "    df = validate_data(df, ticker)\n",
        "\n",
        "    return df\n",
        "\n",
        "def aggregate_data(df):\n",
        "    agg_rules = {\n",
        "        'Open': 'first',\n",
        "        'High': 'max',\n",
        "        'Low': 'min',\n",
        "        'Close': 'last'\n",
        "    }\n",
        "\n",
        "    weekly_data = df.set_index('Date').resample('W').agg(agg_rules).reset_index()\n",
        "    monthly_data = df.set_index('Date').resample('M').agg(agg_rules).reset_index()\n",
        "\n",
        "    column_order = ['Date', 'Open', 'High', 'Low', 'Close']\n",
        "    weekly_data = weekly_data[column_order]\n",
        "    monthly_data = monthly_data[column_order]\n",
        "\n",
        "    # Validate aggregated data\n",
        "    weekly_data = validate_data(weekly_data, f\"{df.name}_weekly\")\n",
        "    monthly_data = validate_data(monthly_data, f\"{df.name}_monthly\")\n",
        "\n",
        "    return weekly_data, monthly_data\n",
        "\n",
        "def save_to_csv(data, ticker, period):\n",
        "    if period == 'daily':\n",
        "        file_path = f'/content/export_daily/{ticker}_daily.csv'\n",
        "    elif period == 'weekly':\n",
        "        file_path = f'/content/export_weekly/{ticker}_weekly.csv'\n",
        "    else:\n",
        "        file_path = f'/content/export_monthly/{ticker}_monthly.csv'\n",
        "\n",
        "    data.to_csv(file_path, index=False)\n",
        "    print(f\"Saved {file_path}\")\n",
        "\n",
        "def process_ticker(ticker):\n",
        "    print(f\"Processing {ticker}...\")\n",
        "    try:\n",
        "        # Load and save daily data\n",
        "        df = load_data(ticker)\n",
        "        df.name = ticker  # Add name attribute for reference in aggregation\n",
        "\n",
        "        if len(df) > 0:  # Only proceed if we have valid data\n",
        "            save_to_csv(df, ticker, 'daily')\n",
        "\n",
        "            # Process and save weekly/monthly data\n",
        "            weekly_data, monthly_data = aggregate_data(df)\n",
        "\n",
        "            if len(weekly_data) > 0:\n",
        "                save_to_csv(weekly_data, ticker, 'weekly')\n",
        "            if len(monthly_data) > 0:\n",
        "                save_to_csv(monthly_data, ticker, 'monthly')\n",
        "\n",
        "            print(f\"Successfully processed {ticker}\")\n",
        "        else:\n",
        "            print(f\"No valid data for {ticker}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {ticker}: {str(e)}\")\n",
        "\n",
        "# Process all tickers\n",
        "for ticker in tickers:\n",
        "    process_ticker(ticker)"
      ],
      "metadata": {
        "id": "oXDUp_N1_TDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Function to download all files from a directory\n",
        "def download_directory_files(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        if os.path.isfile(filepath):\n",
        "            files.download(filepath)\n",
        "\n",
        "# Download files from each export directory\n",
        "print(\"Downloading child files...\")\n",
        "download_directory_files('/content/output_child')\n",
        "\n",
        "print(\"Downloading parent files...\")\n",
        "download_directory_files('/content/output_parent')\n",
        "\n",
        "print(\"Downloading test files...\")\n",
        "download_directory_files('/content/testone')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "dV-AVMXyFQkh",
        "outputId": "879ffc89-8797-4971-d6fe-fbe0a6d21500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading child files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23799fd7-de63-4904-bb23-d49af3f16fb0\", \"MMM_D_gel.csv\", 479578)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e2498d8a-ad1c-40fe-8f85-4aa0780a2fe0\", \"AAPL_D_gel.csv\", 545376)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f83ef5bc-4954-4fa7-9017-fd86915922d6\", \"AFL_D_gel.csv\", 542176)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading parent files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0d5b7407-5b86-4dd9-8581-ef897a4d01c3\", \"MMM_M_gel.csv\", 5899)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_354591fc-27b9-45fd-b119-793c1a41006d\", \"AAPL_M_gel.csv\", 6362)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_30008667-6a03-43b9-84e0-77346d75a969\", \"AFL_M_gel.csv\", 6339)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading test files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0188b0b8-8bac-48ad-88d3-a68b72052baf\", \"AFL_test1.csv\", 542176)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_788550fc-ec06-40a7-af5d-6dba2ae6bccf\", \"MMM_test1.csv\", 479578)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9c2e8e2d-3159-47a8-8fd1-7fa3df975c5a\", \"AAPL_test1.csv\", 545376)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}