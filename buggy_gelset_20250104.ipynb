{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVePETUmcMjxGanqv0IvWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaronVonBussin/NewTransit/blob/main/buggy_gelset_20250104.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "class GetSetsProcessor:\n",
        "    \"\"\"Main processor for Get Sets analysis\"\"\"\n",
        "\n",
        "    def __init__(self, child_period='D', parent_period='M', jobname='Gelset'):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "        self.setup_logging()\n",
        "\n",
        "        # Validate period combinations\n",
        "        self._validate_periods()\n",
        "\n",
        "        # Setup paths\n",
        "        self.setup_directories()\n",
        "\n",
        "    def _validate_periods(self):\n",
        "        \"\"\"Validate period combinations\"\"\"\n",
        "        valid_combinations = {\n",
        "            ('D', 'W'), ('D', 'M'),\n",
        "            ('M', 'Q'), ('M', 'Y'),\n",
        "            ('Q', 'Y'), ('D', 'Q')\n",
        "        }\n",
        "        if (self.child_period, self.parent_period) not in valid_combinations:\n",
        "            raise ValueError(f\"Invalid period combination: {self.child_period}/{self.parent_period}\")\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Initialize logging\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(f'getsets_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger('GetSets')\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create required output directories\"\"\"\n",
        "        directories = ['output_child', 'output_parent', 'output_gel_sum']\n",
        "        for dir_name in directories:\n",
        "            Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "    def process_file(self, filepath):\n",
        "        \"\"\"Process a single input file\"\"\"\n",
        "        try:\n",
        "            # Extract file information\n",
        "            ticker, temporal_period, rolling_range = self._parse_filename(filepath)\n",
        "\n",
        "            # Load and validate input data\n",
        "            df = self._load_input_file(filepath)\n",
        "\n",
        "            # Create parent file\n",
        "            parent_df = self._create_parent_file(df)\n",
        "\n",
        "            # Process child calculations\n",
        "            child_df = self._process_child_calculations(df, parent_df)\n",
        "\n",
        "            # Update parent with child data\n",
        "            parent_df = self._update_parent_with_child_data(parent_df, child_df)\n",
        "\n",
        "            # Generate summary statistics\n",
        "            self._generate_summary(parent_df, child_df, ticker)\n",
        "\n",
        "            # Export results\n",
        "            self._export_results(parent_df, child_df, ticker)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_filename(self, filepath):\n",
        "        \"\"\"Parse input filename for ticker and metadata\"\"\"\n",
        "        filename = Path(filepath).stem\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) != 3:\n",
        "            raise ValueError(f\"Invalid filename format: {filename}\")\n",
        "        return parts[0], parts[1], parts[2]\n",
        "\n",
        "    def _load_input_file(self, filepath):\n",
        "        \"\"\"Load and validate input file\"\"\"\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Validate OHLC relationships\n",
        "        valid_mask = (\n",
        "            (df['low'] <= df['open']) &\n",
        "            (df['low'] <= df['close']) &\n",
        "            (df['high'] >= df['open']) &\n",
        "            (df['high'] >= df['close']) &\n",
        "            (df['high'] - df['low'] > 0)\n",
        "        )\n",
        "\n",
        "        invalid_rows = df[~valid_mask]\n",
        "        if len(invalid_rows) > 0:\n",
        "            self.logger.warning(f\"Removing {len(invalid_rows)} invalid rows\")\n",
        "            df = df[valid_mask]\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _create_parent_file(self, df):\n",
        "        \"\"\"Create parent file from child data\"\"\"\n",
        "        parent_processor = ParentProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return parent_processor.create_parent_file(df)\n",
        "\n",
        "    def _process_child_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        child_processor = ChildProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return child_processor.process_calculations(df, parent_df)\n",
        "\n",
        "    def _update_parent_with_child_data(self, parent_df, child_df):\n",
        "        \"\"\"Update parent file with aggregated child data\"\"\"\n",
        "        updater = ParentUpdater(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return updater.update_parent(parent_df, child_df)\n",
        "\n",
        "    def _generate_summary(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate summary statistics\"\"\"\n",
        "        summary = SummaryGenerator()\n",
        "        return summary.generate(parent_df, child_df, ticker)\n",
        "\n",
        "    def _export_results(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Export results to CSV files\"\"\"\n",
        "        # Export child file\n",
        "        child_path = f'output_child/{ticker}_child_{self.child_period}.csv'\n",
        "        child_df.to_csv(child_path, index=False)\n",
        "\n",
        "        # Export parent file\n",
        "        parent_path = f'output_parent/{ticker}_parent_{self.parent_period}.csv'\n",
        "        parent_df.to_csv(parent_path, index=False)\n",
        "\n",
        "        self.logger.info(f\"Results exported: {child_path}, {parent_path}\")\n",
        "\n",
        "\n",
        "class ParentProcessor:\n",
        "    \"\"\"Handles creation and processing of parent file\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def create_parent_file(self, df):\n",
        "        \"\"\"Create parent file by aggregating child data\"\"\"\n",
        "        # Group by parent period\n",
        "        grouped = self._group_by_parent_period(df)\n",
        "\n",
        "        # Aggregate OHLC\n",
        "        parent_df = grouped.agg({\n",
        "            'open': 'first',\n",
        "            'high': 'max',\n",
        "            'low': 'min',\n",
        "            'close': 'last',\n",
        "            'volume': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Add reference fields\n",
        "        parent_df = self._add_reference_fields(parent_df)\n",
        "\n",
        "        # Calculate basic indicators\n",
        "        parent_df = self._calculate_basic_indicators(parent_df)\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "    def _group_by_parent_period(self, df):\n",
        "        \"\"\"Group data by parent period\"\"\"\n",
        "        if self.parent_period == 'W':\n",
        "            return df.groupby(pd.Grouper(key='date', freq='W'))\n",
        "        elif self.parent_period == 'M':\n",
        "            return df.groupby(pd.Grouper(key='date', freq='M'))\n",
        "        elif self.parent_period == 'Q':\n",
        "            return df.groupby(pd.Grouper(key='date', freq='Q'))\n",
        "        elif self.parent_period == 'Y':\n",
        "            return df.groupby(pd.Grouper(key='date', freq='Y'))\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid parent period: {self.parent_period}\")\n",
        "\n",
        "    def _add_reference_fields(self, df):\n",
        "        \"\"\"Add reference fields to parent dataframe\"\"\"\n",
        "        df['serial_id'] = self._generate_serial_ids(df)\n",
        "        df['model_type'] = 1  # bar/prior bar\n",
        "        df['child_period'] = self.child_period\n",
        "        df['parent_period'] = self.parent_period\n",
        "        df['create_date'] = datetime.now().strftime('%Y-%m-%d')\n",
        "        df['create_time'] = datetime.now().strftime('%H:%M:%S')\n",
        "        return df\n",
        "\n",
        "    def _generate_serial_ids(self, df):\n",
        "        \"\"\"Generate unique 13-digit serial IDs\"\"\"\n",
        "        base = int(datetime.now().strftime('%Y%m%d%H%M'))\n",
        "        return [f\"{base}{i:03d}\" for i in range(len(df))]\n",
        "\n",
        "    def _calculate_basic_indicators(self, df):\n",
        "        \"\"\"Calculate basic technical indicators\"\"\"\n",
        "        # Calculate range\n",
        "        df['range'] = df['high'] - df['low']\n",
        "\n",
        "        # Calculate percent_r\n",
        "        df['percent_r'] = (df['close'] - df['low']) / df['range']\n",
        "\n",
        "        # Add prior bar references\n",
        "        df['ro'] = df['open'].shift(1)\n",
        "        df['rh'] = df['high'].shift(1)\n",
        "        df['rl'] = df['low'].shift(1)\n",
        "        df['rc'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class ChildProcessor:\n",
        "    \"\"\"Handles child calculations including bar/prior bar and gel calculations\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def process_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        # Add trading_bop\n",
        "        df = self._add_trading_bop(df)\n",
        "\n",
        "        # Calculate bar/prior bar\n",
        "        df = self._calculate_bar_prior_bar(df)\n",
        "\n",
        "        # Calculate gel values\n",
        "        df = self._calculate_gel_values(df)\n",
        "\n",
        "        # Calculate prior parent values\n",
        "        df = self._calculate_prior_parent(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_trading_bop(self, df):\n",
        "        \"\"\"Add trading bar of parent field\"\"\"\n",
        "        # Group by parent period and assign sequential numbers\n",
        "        if self.parent_period == 'W':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='W')).cumcount() + 1\n",
        "        elif self.parent_period == 'M':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='M')).cumcount() + 1\n",
        "        elif self.parent_period == 'Q':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Q')).cumcount() + 1\n",
        "        elif self.parent_period == 'Y':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Y')).cumcount() + 1\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_bar_prior_bar(self, df):\n",
        "        \"\"\"Calculate bar/prior bar values\"\"\"\n",
        "        # REU/RED calculations\n",
        "        df['reu_value'] = df.apply(\n",
        "            lambda x: x['high'] - x['high'].shift(1) if x['high'] > x['high'].shift(1) else 0\n",
        "        )\n",
        "        df['red_value'] = df.apply(\n",
        "            lambda x: abs(x['low'] - x['low'].shift(1)) if x['low'] < x['low'].shift(1) else 0\n",
        "        )\n",
        "\n",
        "        # Flags\n",
        "        df['reu_flag'] = (df['reu_value'] > 0).astype(int)\n",
        "        df['red_flag'] = (df['red_value'] > 0).astype(int)\n",
        "        df['re_value'] = df['reu_value'] + df['red_value']\n",
        "        df['re_flag'] = ((df['reu_flag'] == 1) | (df['red_flag'] == 1)).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "class GelCalculator:\n",
        "    \"\"\"Handles Gel calculations including expansions and pattern recognition\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_gel_values(self, df):\n",
        "        \"\"\"Calculate all gel-related values\"\"\"\n",
        "        # Initialize gel OHLC\n",
        "        df = self._initialize_gel_ohlc(df)\n",
        "\n",
        "        # Calculate gel ranges and percentages\n",
        "        df = self._calculate_gel_ranges(df)\n",
        "\n",
        "        # Calculate gel expansions\n",
        "        df = self._calculate_gel_expansions(df)\n",
        "\n",
        "        # Calculate gel patterns\n",
        "        df = self._calculate_gel_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_gel_ohlc(self, df):\n",
        "        \"\"\"Initialize gel OHLC values\"\"\"\n",
        "        # First bar of parent sets initial values\n",
        "        df['gel_open'] = df.apply(\n",
        "            lambda x: x['open'] if x['trading_bop'] == 1\n",
        "            else x['gel_open'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        # Running high/low within parent\n",
        "        df['gel_high'] = df.apply(\n",
        "            lambda x: x['high'] if x['trading_bop'] == 1\n",
        "            else max(x['high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_low'] = df.apply(\n",
        "            lambda x: x['low'] if x['trading_bop'] == 1\n",
        "            else min(x['low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_close'] = df['close']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_ranges(self, df):\n",
        "        \"\"\"Calculate gel ranges and percentages\"\"\"\n",
        "        df['gel_range'] = df['gel_high'] - df['gel_low']\n",
        "        df['gel_percent_r'] = (df['gel_close'] - df['gel_low']) / df['gel_range']\n",
        "\n",
        "        # Calculate gel ce_percent\n",
        "        df['gel_ce_percent'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else 1 - x['gel_percent_r'].shift(1) if x['gel_percent_r'].shift(1) >= 0.5\n",
        "            else x['gel_percent_r'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_expansions(self, df):\n",
        "        \"\"\"Calculate gel expansion values\"\"\"\n",
        "        # Calculate REU/RED for gel\n",
        "        df['gel_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['gel_high'] - x['gel_high'].shift(1) if x['gel_high'] > x['gel_high'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['gel_low'] - x['gel_low'].shift(1)) if x['gel_low'] < x['gel_low'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gel_reu_flag'] = (df['gel_reu_value'] > 0).astype(int)\n",
        "        df['gel_red_flag'] = (df['gel_red_value'] > 0).astype(int)\n",
        "        df['gel_re_value'] = df['gel_reu_value'] + df['gel_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_patterns(self, df):\n",
        "        \"\"\"Calculate gel pattern indicators\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gel_epc'] = np.ceil(df['gel_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gel_epc_dir'] = (df['gel_percent_r'].shift(1) >= 0.5).astype(int)\n",
        "        df['gel_epc_hp'] = (df['gel_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate E1/E2 values\n",
        "        df['gel_e1_value'] = df.apply(\n",
        "            lambda x: x['gel_reu_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_red_value'], axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_e2_value'] = df.apply(\n",
        "            lambda x: x['gel_red_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_reu_value'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class PriorParentCalculator:\n",
        "    \"\"\"Handles calculations related to prior parent period relationships\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_prior_parent(self, df):\n",
        "        \"\"\"Calculate all prior parent related values\"\"\"\n",
        "        # Initialize parent reference values\n",
        "        df = self._initialize_parent_refs(df)\n",
        "\n",
        "        # Calculate ranges and percentages\n",
        "        df = self._calculate_parent_ranges(df)\n",
        "\n",
        "        # Calculate expansions against prior parent\n",
        "        df = self._calculate_parent_expansions(df)\n",
        "\n",
        "        # Calculate patterns and directions\n",
        "        df = self._calculate_parent_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_parent_refs(self, df):\n",
        "        \"\"\"Initialize references to parent values\"\"\"\n",
        "        df['gelp_open'] = df['parent_open']\n",
        "\n",
        "        # Running high/low against parent\n",
        "        df['gelp_high'] = df.apply(\n",
        "            lambda x: x['parent_high'] if x['trading_bop'] == 1\n",
        "            else max(x['parent_high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_low'] = df.apply(\n",
        "            lambda x: x['parent_low'] if x['trading_bop'] == 1\n",
        "            else min(x['parent_low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_close'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_ranges(self, df):\n",
        "        \"\"\"Calculate ranges and percentages against parent\"\"\"\n",
        "        df['gelp_range'] = df['gelp_high'] - df['gelp_low']\n",
        "        df['gelp_percent_r'] = (df['gelp_close'] - df['gelp_low']) / df['gelp_range']\n",
        "\n",
        "        df['gelp_ce_percent'] = df.apply(\n",
        "            lambda x: 1 - x['gelp_percent_r'] if x['gelp_percent_r'] >= 0.5\n",
        "            else x['gelp_percent_r'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_expansions(self, df):\n",
        "        \"\"\"Calculate expansions against parent values\"\"\"\n",
        "        # Calculate REU/RED against parent\n",
        "        df['gelp_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['high'] - x['gelp_high'] if x['high'] > x['gelp_high']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['low'] - x['gelp_low']) if x['low'] < x['gelp_low']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gelp_reu_flag'] = (df['gelp_reu_value'] > 0).astype(int)\n",
        "        df['gelp_red_flag'] = (df['gelp_red_value'] > 0).astype(int)\n",
        "        df['gelp_re_value'] = df['gelp_reu_value'] + df['gelp_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_patterns(self, df):\n",
        "        \"\"\"Calculate pattern indicators against parent\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gelp_epc'] = np.ceil(df['gelp_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gelp_epc_dir'] = (df['gelp_percent_r'] >= 0.5).astype(int)\n",
        "        df['gelp_epc_hp_flag'] = (df['gelp_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate direction and RPC\n",
        "        df['gelp_dir'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_dir'].shift(1) if x['gelp_re_flag'] == 0\n",
        "            else 0 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == 1\n",
        "            else 1 if x['gelp_reu_flag'] == 1\n",
        "            else x['gelp_dir'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_rpc'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_rpc'].shift(1) if x['gelp_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 2 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 1, axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class SummaryGenerator:\n",
        "    \"\"\"Generates summary statistics and analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate complete summary statistics\"\"\"\n",
        "        summary = {}\n",
        "\n",
        "        # Parent level statistics\n",
        "        summary.update(self._generate_parent_stats(parent_df))\n",
        "\n",
        "        # Child level statistics\n",
        "        summary.update(self._generate_child_stats(child_df))\n",
        "\n",
        "        # Pattern analysis\n",
        "        summary.update(self._analyze_patterns(parent_df, child_df))\n",
        "\n",
        "        # Export summary\n",
        "        self._export_summary(summary, ticker)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _generate_parent_stats(self, df):\n",
        "        \"\"\"Generate parent level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        # E1 FRE flag by EPC HP\n",
        "        e1_hp_stats = df[df['epc_hp'] == 1]['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_hp_counts'] = e1_hp_stats.to_dict()\n",
        "        stats['e1_fre_flag_hp_percentages'] = (e1_hp_stats / len(df[df['epc_hp'] == 1]) * 100).to_dict()\n",
        "\n",
        "        # Range histogram\n",
        "        stats['range_histogram'] = df['range'].describe().to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _generate_child_stats(self, df):\n",
        "        \"\"\"Generate child level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['child_e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['child_e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _analyze_patterns(self, parent_df, child_df):\n",
        "        \"\"\"Analyze patterns across parent and child data\"\"\"\n",
        "        patterns = {}\n",
        "\n",
        "        # Analyze expansion patterns\n",
        "        patterns['avg_expansion_by_period'] = child_df.groupby('trading_bop')['re_value'].mean().to_dict()\n",
        "\n",
        "        # Analyze direction persistence\n",
        "        patterns['direction_persistence'] = self._calculate_direction_persistence(child_df)\n",
        "\n",
        "        # Analyze high/low positioning\n",
        "        patterns['hl_position_stats'] = self._analyze_hl_positions(child_df)\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def _calculate_direction_persistence(self, df):\n",
        "        \"\"\"Calculate statistics about direction persistence\"\"\"\n",
        "        return {\n",
        "            'avg_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().mean(),\n",
        "            'max_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().max()\n",
        "        }\n",
        "\n",
        "    def _analyze_hl_positions(self, df):\n",
        "        \"\"\"Analyze high/low position patterns\"\"\"\n",
        "        return {\n",
        "            'early_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) & (df['trading_bop'] <= 2)]),\n",
        "            'middle_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                               (df['trading_bop'] > 2) & (df['trading_bop'] < df['parent_duration'] - 1)]),\n",
        "            'late_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                             (df['trading_bop'] >= df['parent_duration'] - 1)])\n",
        "        }\n",
        "\n",
        "    def _export_summary(self, summary, ticker):\n",
        "        \"\"\"Export summary statistics to CSV\"\"\"\n",
        "        # Convert nested dict to flat format for CSV\n",
        "        flat_summary = self._flatten_dict(summary)\n",
        "\n",
        "        # Create DataFrame and export\n",
        "        summary_df = pd.DataFrame([flat_summary])\n",
        "        summary_df.to_csv(f'output_gel_sum/{ticker}_summary.csv', index=False)\n",
        "\n",
        "    def _flatten_dict(self, d, parent_key='', sep='_'):\n",
        "        \"\"\"Flatten nested dictionary for CSV export\"\"\"\n",
        "        items = []\n",
        "        for k, v in d.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "            if isinstance(v, dict):\n",
        "                items.extend(self._flatten_dict(v, new_key, sep=sep).items())\n",
        "            else:\n",
        "                items.append((new_key, v))\n",
        "        return dict(items)"
      ],
      "metadata": {
        "id": "6P29K06WzRdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "class GetSetsProcessor:\n",
        "    \"\"\"Main processor for Get Sets analysis\"\"\"\n",
        "\n",
        "    def __init__(self, child_period='D', parent_period='M', jobname='Gelset'):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "        self.setup_logging()\n",
        "\n",
        "        # Validate period combinations\n",
        "        self._validate_periods()\n",
        "\n",
        "        # Setup paths\n",
        "        self.setup_directories()\n",
        "\n",
        "    def _validate_periods(self):\n",
        "        \"\"\"Validate period combinations\"\"\"\n",
        "        valid_combinations = {\n",
        "            ('D', 'W'), ('D', 'M'),\n",
        "            ('M', 'Q'), ('M', 'Y'),\n",
        "            ('Q', 'Y'), ('D', 'Q')\n",
        "        }\n",
        "        if (self.child_period, self.parent_period) not in valid_combinations:\n",
        "            raise ValueError(f\"Invalid period combination: {self.child_period}/{self.parent_period}\")\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Initialize logging\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(f'getsets_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger('GetSets')\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create required output directories\"\"\"\n",
        "        directories = ['output_child', 'output_parent', 'output_gel_sum']\n",
        "        for dir_name in directories:\n",
        "            Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "    def process_file(self, filepath):\n",
        "        \"\"\"Process a single input file\"\"\"\n",
        "        try:\n",
        "            # Extract file information\n",
        "            ticker, temporal_period, rolling_range = self._parse_filename(filepath)\n",
        "\n",
        "            # Load and validate input data\n",
        "            df = self._load_input_file(filepath)\n",
        "\n",
        "            # Create parent file\n",
        "            parent_df = self._create_parent_file(df)\n",
        "\n",
        "            # Process child calculations\n",
        "            child_df = self._process_child_calculations(df, parent_df)\n",
        "\n",
        "            # Update parent with child data\n",
        "            parent_df = self._update_parent_with_child_data(parent_df, child_df)\n",
        "\n",
        "            # Generate summary statistics\n",
        "            self._generate_summary(parent_df, child_df, ticker)\n",
        "\n",
        "            # Export results\n",
        "            self._export_results(parent_df, child_df, ticker)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_filename(self, filepath):\n",
        "        \"\"\"Parse input filename for ticker and metadata\"\"\"\n",
        "        filename = Path(filepath).stem\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) != 3:\n",
        "            raise ValueError(f\"Invalid filename format: {filename}\")\n",
        "        return parts[0], parts[1], parts[2]\n",
        "\n",
        "    def _load_input_file(self, filepath):\n",
        "        \"\"\"Load and validate input file\"\"\"\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Validate OHLC relationships\n",
        "        valid_mask = (\n",
        "            (df['low'] <= df['open']) &\n",
        "            (df['low'] <= df['close']) &\n",
        "            (df['high'] >= df['open']) &\n",
        "            (df['high'] >= df['close']) &\n",
        "            (df['high'] - df['low'] > 0)\n",
        "        )\n",
        "\n",
        "        invalid_rows = df[~valid_mask]\n",
        "        if len(invalid_rows) > 0:\n",
        "            self.logger.warning(f\"Removing {len(invalid_rows)} invalid rows\")\n",
        "            df = df[valid_mask]\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _create_parent_file(self, df):\n",
        "        \"\"\"Create parent file from child data\"\"\"\n",
        "        parent_processor = ParentProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return parent_processor.create_parent_file(df)\n",
        "\n",
        "    def _process_child_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        child_processor = ChildProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return child_processor.process_calculations(df, parent_df)\n",
        "\n",
        "    def _update_parent_with_child_data(self, parent_df, child_df):\n",
        "        \"\"\"Update parent file with aggregated child data\"\"\"\n",
        "        updater = ParentUpdater(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return updater.update_parent(parent_df, child_df)\n",
        "\n",
        "    def _generate_summary(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate summary statistics\"\"\"\n",
        "        summary = SummaryGenerator()\n",
        "        return summary.generate(parent_df, child_df, ticker)\n",
        "\n",
        "    def _export_results(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Export results to CSV files\"\"\"\n",
        "        # Export child file\n",
        "        child_path = f'output_child/{ticker}_child_{self.child_period}.csv'\n",
        "        child_df.to_csv(child_path, index=False)\n",
        "\n",
        "        # Export parent file\n",
        "        parent_path = f'output_parent/{ticker}_parent_{self.parent_period}.csv'\n",
        "        parent_df.to_csv(parent_path, index=False)\n",
        "\n",
        "        self.logger.info(f\"Results exported: {child_path}, {parent_path}\")\n",
        "\n",
        "\n",
        "class ParentProcessor:\n",
        "    \"\"\"Handles creation and processing of parent file\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def create_parent_file(self, df):\n",
        "        \"\"\"Create parent file by aggregating child data\"\"\"\n",
        "        # Group by parent period\n",
        "        grouped = self._group_by_parent_period(df)\n",
        "\n",
        "        # Aggregate OHLC\n",
        "        parent_df = grouped.agg({\n",
        "            'open': 'first',\n",
        "            'high': 'max',\n",
        "            'low': 'min',\n",
        "            'close': 'last',\n",
        "            'volume': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Add reference fields\n",
        "        parent_df = self._add_reference_fields(parent_df)\n",
        "\n",
        "        # Calculate basic indicators\n",
        "        parent_df = self._calculate_basic_indicators(parent_df)\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "    def _group_by_parent_period(self, df):\n",
        "        \"\"\"Group data by parent period\"\"\"\n",
        "        if self.parent_period == 'W':\n",
        "            return df.groupby(pd.Grouper(key='date', freq='W'))\n",
        "        elif self.parent_period == 'M':\n",
        "            return df.groupby(pd.Grouper(key='date', freq='M'))\n",
        "        elif self.parent_period == 'Q':\n",
        "            return df.groupby(pd.Grouper(key='date', freq='Q'))\n",
        "        elif self.parent_period == 'Y':\n",
        "            return df.groupby(pd.Grouper(key='date', freq='Y'))\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid parent period: {self.parent_period}\")\n",
        "\n",
        "    def _add_reference_fields(self, df):\n",
        "        \"\"\"Add reference fields to parent dataframe\"\"\"\n",
        "        df['serial_id'] = self._generate_serial_ids(df)\n",
        "        df['model_type'] = 1  # bar/prior bar\n",
        "        df['child_period'] = self.child_period\n",
        "        df['parent_period'] = self.parent_period\n",
        "        df['create_date'] = datetime.now().strftime('%Y-%m-%d')\n",
        "        df['create_time'] = datetime.now().strftime('%H:%M:%S')\n",
        "        return df\n",
        "\n",
        "    def _generate_serial_ids(self, df):\n",
        "        \"\"\"Generate unique 13-digit serial IDs\"\"\"\n",
        "        base = int(datetime.now().strftime('%Y%m%d%H%M'))\n",
        "        return [f\"{base}{i:03d}\" for i in range(len(df))]\n",
        "\n",
        "    def _calculate_basic_indicators(self, df):\n",
        "        \"\"\"Calculate basic technical indicators\"\"\"\n",
        "        # Calculate range\n",
        "        df['range'] = df['high'] - df['low']\n",
        "\n",
        "        # Calculate percent_r\n",
        "        df['percent_r'] = (df['close'] - df['low']) / df['range']\n",
        "\n",
        "        # Add prior bar references\n",
        "        df['ro'] = df['open'].shift(1)\n",
        "        df['rh'] = df['high'].shift(1)\n",
        "        df['rl'] = df['low'].shift(1)\n",
        "        df['rc'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class ChildProcessor:\n",
        "    \"\"\"Handles child calculations including bar/prior bar and gel calculations\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def process_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        # Add trading_bop\n",
        "        df = self._add_trading_bop(df)\n",
        "\n",
        "        # Calculate bar/prior bar\n",
        "        df = self._calculate_bar_prior_bar(df)\n",
        "\n",
        "        # Calculate gel values\n",
        "        df = self._calculate_gel_values(df)\n",
        "\n",
        "        # Calculate prior parent values\n",
        "        df = self._calculate_prior_parent(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_trading_bop(self, df):\n",
        "        \"\"\"Add trading bar of parent field\"\"\"\n",
        "        # Group by parent period and assign sequential numbers\n",
        "        if self.parent_period == 'W':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='W')).cumcount() + 1\n",
        "        elif self.parent_period == 'M':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='M')).cumcount() + 1\n",
        "        elif self.parent_period == 'Q':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Q')).cumcount() + 1\n",
        "        elif self.parent_period == 'Y':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Y')).cumcount() + 1\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_bar_prior_bar(self, df):\n",
        "        \"\"\"Calculate bar/prior bar values\"\"\"\n",
        "        # REU/RED calculations\n",
        "        df['reu_value'] = df.apply(\n",
        "            lambda x: x['high'] - x['high'].shift(1) if x['high'] > x['high'].shift(1) else 0\n",
        "        )\n",
        "        df['red_value'] = df.apply(\n",
        "            lambda x: abs(x['low'] - x['low'].shift(1)) if x['low'] < x['low'].shift(1) else 0\n",
        "        )\n",
        "\n",
        "        # Flags\n",
        "        df['reu_flag'] = (df['reu_value'] > 0).astype(int)\n",
        "        df['red_flag'] = (df['red_value'] > 0).astype(int)\n",
        "        df['re_value'] = df['reu_value'] + df['red_value']\n",
        "        df['re_flag'] = ((df['reu_flag'] == 1) | (df['red_flag'] == 1)).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "class GelCalculator:\n",
        "    \"\"\"Handles Gel calculations including expansions and pattern recognition\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_gel_values(self, df):\n",
        "        \"\"\"Calculate all gel-related values\"\"\"\n",
        "        # Initialize gel OHLC\n",
        "        df = self._initialize_gel_ohlc(df)\n",
        "\n",
        "        # Calculate gel ranges and percentages\n",
        "        df = self._calculate_gel_ranges(df)\n",
        "\n",
        "        # Calculate gel expansions\n",
        "        df = self._calculate_gel_expansions(df)\n",
        "\n",
        "        # Calculate gel patterns\n",
        "        df = self._calculate_gel_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_gel_ohlc(self, df):\n",
        "        \"\"\"Initialize gel OHLC values\"\"\"\n",
        "        # First bar of parent sets initial values\n",
        "        df['gel_open'] = df.apply(\n",
        "            lambda x: x['open'] if x['trading_bop'] == 1\n",
        "            else x['gel_open'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        # Running high/low within parent\n",
        "        df['gel_high'] = df.apply(\n",
        "            lambda x: x['high'] if x['trading_bop'] == 1\n",
        "            else max(x['high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_low'] = df.apply(\n",
        "            lambda x: x['low'] if x['trading_bop'] == 1\n",
        "            else min(x['low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_close'] = df['close']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_ranges(self, df):\n",
        "        \"\"\"Calculate gel ranges and percentages\"\"\"\n",
        "        df['gel_range'] = df['gel_high'] - df['gel_low']\n",
        "        df['gel_percent_r'] = (df['gel_close'] - df['gel_low']) / df['gel_range']\n",
        "\n",
        "        # Calculate gel ce_percent\n",
        "        df['gel_ce_percent'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else 1 - x['gel_percent_r'].shift(1) if x['gel_percent_r'].shift(1) >= 0.5\n",
        "            else x['gel_percent_r'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_expansions(self, df):\n",
        "        \"\"\"Calculate gel expansion values\"\"\"\n",
        "        # Calculate REU/RED for gel\n",
        "        df['gel_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['gel_high'] - x['gel_high'].shift(1) if x['gel_high'] > x['gel_high'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['gel_low'] - x['gel_low'].shift(1)) if x['gel_low'] < x['gel_low'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gel_reu_flag'] = (df['gel_reu_value'] > 0).astype(int)\n",
        "        df['gel_red_flag'] = (df['gel_red_value'] > 0).astype(int)\n",
        "        df['gel_re_value'] = df['gel_reu_value'] + df['gel_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_patterns(self, df):\n",
        "        \"\"\"Calculate gel pattern indicators\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gel_epc'] = np.ceil(df['gel_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gel_epc_dir'] = (df['gel_percent_r'].shift(1) >= 0.5).astype(int)\n",
        "        df['gel_epc_hp'] = (df['gel_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate E1/E2 values\n",
        "        df['gel_e1_value'] = df.apply(\n",
        "            lambda x: x['gel_reu_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_red_value'], axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_e2_value'] = df.apply(\n",
        "            lambda x: x['gel_red_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_reu_value'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class PriorParentCalculator:\n",
        "    \"\"\"Handles calculations related to prior parent period relationships\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_prior_parent(self, df):\n",
        "        \"\"\"Calculate all prior parent related values\"\"\"\n",
        "        # Initialize parent reference values\n",
        "        df = self._initialize_parent_refs(df)\n",
        "\n",
        "        # Calculate ranges and percentages\n",
        "        df = self._calculate_parent_ranges(df)\n",
        "\n",
        "        # Calculate expansions against prior parent\n",
        "        df = self._calculate_parent_expansions(df)\n",
        "\n",
        "        # Calculate patterns and directions\n",
        "        df = self._calculate_parent_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_parent_refs(self, df):\n",
        "        \"\"\"Initialize references to parent values\"\"\"\n",
        "        df['gelp_open'] = df['parent_open']\n",
        "\n",
        "        # Running high/low against parent\n",
        "        df['gelp_high'] = df.apply(\n",
        "            lambda x: x['parent_high'] if x['trading_bop'] == 1\n",
        "            else max(x['parent_high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_low'] = df.apply(\n",
        "            lambda x: x['parent_low'] if x['trading_bop'] == 1\n",
        "            else min(x['parent_low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_close'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_ranges(self, df):\n",
        "        \"\"\"Calculate ranges and percentages against parent\"\"\"\n",
        "        df['gelp_range'] = df['gelp_high'] - df['gelp_low']\n",
        "        df['gelp_percent_r'] = (df['gelp_close'] - df['gelp_low']) / df['gelp_range']\n",
        "\n",
        "        df['gelp_ce_percent'] = df.apply(\n",
        "            lambda x: 1 - x['gelp_percent_r'] if x['gelp_percent_r'] >= 0.5\n",
        "            else x['gelp_percent_r'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_expansions(self, df):\n",
        "        \"\"\"Calculate expansions against parent values\"\"\"\n",
        "        # Calculate REU/RED against parent\n",
        "        df['gelp_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['high'] - x['gelp_high'] if x['high'] > x['gelp_high']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['low'] - x['gelp_low']) if x['low'] < x['gelp_low']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gelp_reu_flag'] = (df['gelp_reu_value'] > 0).astype(int)\n",
        "        df['gelp_red_flag'] = (df['gelp_red_value'] > 0).astype(int)\n",
        "        df['gelp_re_value'] = df['gelp_reu_value'] + df['gelp_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_patterns(self, df):\n",
        "        \"\"\"Calculate pattern indicators against parent\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gelp_epc'] = np.ceil(df['gelp_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gelp_epc_dir'] = (df['gelp_percent_r'] >= 0.5).astype(int)\n",
        "        df['gelp_epc_hp_flag'] = (df['gelp_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate direction and RPC\n",
        "        df['gelp_dir'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_dir'].shift(1) if x['gelp_re_flag'] == 0\n",
        "            else 0 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == 1\n",
        "            else 1 if x['gelp_reu_flag'] == 1\n",
        "            else x['gelp_dir'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_rpc'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_rpc'].shift(1) if x['gelp_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 2 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 1, axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class SummaryGenerator:\n",
        "    \"\"\"Generates summary statistics and analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate complete summary statistics\"\"\"\n",
        "        summary = {}\n",
        "\n",
        "        # Parent level statistics\n",
        "        summary.update(self._generate_parent_stats(parent_df))\n",
        "\n",
        "        # Child level statistics\n",
        "        summary.update(self._generate_child_stats(child_df))\n",
        "\n",
        "        # Pattern analysis\n",
        "        summary.update(self._analyze_patterns(parent_df, child_df))\n",
        "\n",
        "        # Export summary\n",
        "        self._export_summary(summary, ticker)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _generate_parent_stats(self, df):\n",
        "        \"\"\"Generate parent level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        # E1 FRE flag by EPC HP\n",
        "        e1_hp_stats = df[df['epc_hp'] == 1]['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_hp_counts'] = e1_hp_stats.to_dict()\n",
        "        stats['e1_fre_flag_hp_percentages'] = (e1_hp_stats / len(df[df['epc_hp'] == 1]) * 100).to_dict()\n",
        "\n",
        "        # Range histogram\n",
        "        stats['range_histogram'] = df['range'].describe().to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _generate_child_stats(self, df):\n",
        "        \"\"\"Generate child level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['child_e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['child_e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _analyze_patterns(self, parent_df, child_df):\n",
        "        \"\"\"Analyze patterns across parent and child data\"\"\"\n",
        "        patterns = {}\n",
        "\n",
        "        # Analyze expansion patterns\n",
        "        patterns['avg_expansion_by_period'] = child_df.groupby('trading_bop')['re_value'].mean().to_dict()\n",
        "\n",
        "        # Analyze direction persistence\n",
        "        patterns['direction_persistence'] = self._calculate_direction_persistence(child_df)\n",
        "\n",
        "        # Analyze high/low positioning\n",
        "        patterns['hl_position_stats'] = self._analyze_hl_positions(child_df)\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def _calculate_direction_persistence(self, df):\n",
        "        \"\"\"Calculate statistics about direction persistence\"\"\"\n",
        "        return {\n",
        "            'avg_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().mean(),\n",
        "            'max_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().max()\n",
        "        }\n",
        "\n",
        "    def _analyze_hl_positions(self, df):\n",
        "        \"\"\"Analyze high/low position patterns\"\"\"\n",
        "        return {\n",
        "            'early_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) & (df['trading_bop'] <= 2)]),\n",
        "            'middle_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                               (df['trading_bop'] > 2) & (df['trading_bop'] < df['parent_duration'] - 1)]),\n",
        "            'late_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                             (df['trading_bop'] >= df['parent_duration'] - 1)])\n",
        "        }\n",
        "\n",
        "    def _export_summary(self, summary, ticker):\n",
        "        \"\"\"Export summary statistics to CSV\"\"\"\n",
        "        # Convert nested dict to flat format for CSV\n",
        "        flat_summary = self._flatten_dict(summary)\n",
        "\n",
        "        # Create DataFrame and export\n",
        "        summary_df = pd.DataFrame([flat_summary])\n",
        "        summary_df.to_csv(f'output_gel_sum/{ticker}_summary.csv', index=False)\n",
        "\n",
        "    def _flatten_dict(self, d, parent_key='', sep='_'):\n",
        "        \"\"\"Flatten nested dictionary for CSV export\"\"\"\n",
        "        items = []\n",
        "        for k, v in d.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "            if isinstance(v, dict):\n",
        "                items.extend(self._flatten_dict(v, new_key, sep=sep).items())\n",
        "            else:\n",
        "                items.append((new_key, v))\n",
        "        return dict(items)\n",
        "\n",
        "class ParentUpdater:\n",
        "    \"\"\"Updates parent file with aggregated child data\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def update_parent(self, parent_df, child_df):\n",
        "        \"\"\"Update parent with aggregated child data\"\"\"\n",
        "        # Calculate intrabar counts\n",
        "        intrabar_counts = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).agg({\n",
        "            'reu_flag': 'sum',\n",
        "            'red_flag': 'sum',\n",
        "            'rpc': 'sum'\n",
        "        }).rename(columns={\n",
        "            'reu_flag': 'intrabar_reu_count',\n",
        "            'red_flag': 'intrabar_red_count',\n",
        "            'rpc': 'intrabar_rpc'\n",
        "        })\n",
        "\n",
        "        # Calculate priorbar counts\n",
        "        priorbar_counts = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).agg({\n",
        "            'gelp_reu_flag': 'sum',\n",
        "            'gelp_red_flag': 'sum',\n",
        "            'gelp_red_flag': 'sum'  # Using red_flag for rpc as per spec\n",
        "        }).rename(columns={\n",
        "            'gelp_reu_flag': 'priorbar_reu_count',\n",
        "            'gelp_red_flag': 'priorbar_red_count',\n",
        "            'gelp_red_flag': 'priorbar_rpc'\n",
        "        })\n",
        "\n",
        "        # Find first/last RE positions\n",
        "        def get_positions(group):\n",
        "            re_bars = group[group['gelp_re_flag'] == 1]['trading_bop']\n",
        "            return pd.Series({\n",
        "                'priorbar_first_re': re_bars.iloc[0] if len(re_bars) > 0 else None,\n",
        "                'priorbar_last_re': re_bars.iloc[-1] if len(re_bars) > 0 else None\n",
        "            })\n",
        "\n",
        "        positions = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).apply(get_positions)\n",
        "\n",
        "        # Merge all updates into parent\n",
        "        parent_df = parent_df.join(intrabar_counts, how='left')\n",
        "        parent_df = parent_df.join(priorbar_counts, how='left')\n",
        "        parent_df = parent_df.join(positions, how='left')\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "def main():\n",
        "    # Initialize processor\n",
        "    processor = GetSetsProcessor(child_period='D', parent_period='M')\n",
        "\n",
        "    # Process all files in input directory\n",
        "    input_dir = Path('/content/input')\n",
        "\n",
        "    if not input_dir.exists():\n",
        "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
        "\n",
        "    # Process each CSV file\n",
        "    for file_path in input_dir.glob('*.csv'):\n",
        "        try:\n",
        "            print(f\"\\nProcessing file: {file_path}\")\n",
        "            processor.process_file(file_path)\n",
        "            print(f\"Successfully processed: {file_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {str(e)}\")\n",
        "            logging.error(f\"Error processing {file_path}: {str(e)}\", exc_info=True)\n",
        "\n",
        "# Run the processor\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfvIhnTi1RFz",
        "outputId": "25138098-d280-4cdf-dac2-4844bfe4f80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-9ca5f3d6ce1b>:190: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  return df.groupby(pd.Grouper(key='date', freq='M'))\n",
            "ERROR:GetSets:Error processing file /content/input/AAPL_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:Error processing /content/input/AAPL_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 658, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 60, in process_file\n",
            "    parent_df = self._create_parent_file(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 120, in _create_parent_file\n",
            "    return parent_processor.create_parent_file(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 166, in create_parent_file\n",
            "    grouped = self._group_by_parent_period(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 190, in _group_by_parent_period\n",
            "    return df.groupby(pd.Grouper(key='date', freq='M'))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\", line 9183, in groupby\n",
            "    return DataFrameGroupBy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\", line 1329, in __init__\n",
            "    grouper, exclusions, obj = get_grouper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\", line 929, in get_grouper\n",
            "    grouper, obj = key._get_grouper(obj, validate=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/resample.py\", line 2282, in _get_grouper\n",
            "    r = self._get_resampler(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/resample.py\", line 2272, in _get_resampler\n",
            "    raise TypeError(\n",
            "TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "<ipython-input-4-9ca5f3d6ce1b>:190: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  return df.groupby(pd.Grouper(key='date', freq='M'))\n",
            "ERROR:GetSets:Error processing file /content/input/MMM_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:Error processing /content/input/MMM_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 658, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 60, in process_file\n",
            "    parent_df = self._create_parent_file(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 120, in _create_parent_file\n",
            "    return parent_processor.create_parent_file(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 166, in create_parent_file\n",
            "    grouped = self._group_by_parent_period(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 190, in _group_by_parent_period\n",
            "    return df.groupby(pd.Grouper(key='date', freq='M'))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\", line 9183, in groupby\n",
            "    return DataFrameGroupBy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\", line 1329, in __init__\n",
            "    grouper, exclusions, obj = get_grouper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\", line 929, in get_grouper\n",
            "    grouper, obj = key._get_grouper(obj, validate=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/resample.py\", line 2282, in _get_grouper\n",
            "    r = self._get_resampler(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/resample.py\", line 2272, in _get_resampler\n",
            "    raise TypeError(\n",
            "TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "<ipython-input-4-9ca5f3d6ce1b>:190: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  return df.groupby(pd.Grouper(key='date', freq='M'))\n",
            "ERROR:GetSets:Error processing file /content/input/XLB_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:Error processing /content/input/XLB_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 658, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 60, in process_file\n",
            "    parent_df = self._create_parent_file(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 120, in _create_parent_file\n",
            "    return parent_processor.create_parent_file(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 166, in create_parent_file\n",
            "    grouped = self._group_by_parent_period(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 190, in _group_by_parent_period\n",
            "    return df.groupby(pd.Grouper(key='date', freq='M'))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\", line 9183, in groupby\n",
            "    return DataFrameGroupBy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\", line 1329, in __init__\n",
            "    grouper, exclusions, obj = get_grouper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\", line 929, in get_grouper\n",
            "    grouper, obj = key._get_grouper(obj, validate=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/resample.py\", line 2282, in _get_grouper\n",
            "    r = self._get_resampler(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/resample.py\", line 2272, in _get_resampler\n",
            "    raise TypeError(\n",
            "TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "<ipython-input-4-9ca5f3d6ce1b>:190: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  return df.groupby(pd.Grouper(key='date', freq='M'))\n",
            "ERROR:GetSets:Error processing file /content/input/AFL_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "ERROR:root:Error processing /content/input/AFL_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 658, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 60, in process_file\n",
            "    parent_df = self._create_parent_file(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 120, in _create_parent_file\n",
            "    return parent_processor.create_parent_file(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 166, in create_parent_file\n",
            "    grouped = self._group_by_parent_period(df)\n",
            "  File \"<ipython-input-4-9ca5f3d6ce1b>\", line 190, in _group_by_parent_period\n",
            "    return df.groupby(pd.Grouper(key='date', freq='M'))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\", line 9183, in groupby\n",
            "    return DataFrameGroupBy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\", line 1329, in __init__\n",
            "    grouper, exclusions, obj = get_grouper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\", line 929, in get_grouper\n",
            "    grouper, obj = key._get_grouper(obj, validate=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/resample.py\", line 2282, in _get_grouper\n",
            "    r = self._get_resampler(obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/resample.py\", line 2272, in _get_resampler\n",
            "    raise TypeError(\n",
            "TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing file: /content/input/AAPL_D_1.csv\n",
            "Error processing /content/input/AAPL_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "\n",
            "Processing file: /content/input/MMM_D_1.csv\n",
            "Error processing /content/input/MMM_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "\n",
            "Processing file: /content/input/XLB_D_1.csv\n",
            "Error processing /content/input/XLB_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n",
            "\n",
            "Processing file: /content/input/AFL_D_1.csv\n",
            "Error processing /content/input/AFL_D_1.csv: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "class GetSetsProcessor:\n",
        "    \"\"\"Main processor for Get Sets analysis\"\"\"\n",
        "\n",
        "    def __init__(self, child_period='D', parent_period='M', jobname='Gelset'):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "        self.setup_logging()\n",
        "\n",
        "        # Validate period combinations\n",
        "        self._validate_periods()\n",
        "\n",
        "        # Setup paths\n",
        "        self.setup_directories()\n",
        "\n",
        "    def _validate_periods(self):\n",
        "        \"\"\"Validate period combinations\"\"\"\n",
        "        valid_combinations = {\n",
        "            ('D', 'W'), ('D', 'M'),\n",
        "            ('M', 'Q'), ('M', 'Y'),\n",
        "            ('Q', 'Y'), ('D', 'Q')\n",
        "        }\n",
        "        if (self.child_period, self.parent_period) not in valid_combinations:\n",
        "            raise ValueError(f\"Invalid period combination: {self.child_period}/{self.parent_period}\")\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Initialize logging\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(f'getsets_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger('GetSets')\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create required output directories\"\"\"\n",
        "        directories = ['output_child', 'output_parent', 'output_gel_sum']\n",
        "        for dir_name in directories:\n",
        "            Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "    def process_file(self, filepath):\n",
        "        \"\"\"Process a single input file\"\"\"\n",
        "        try:\n",
        "            # Extract file information\n",
        "            ticker, temporal_period, rolling_range = self._parse_filename(filepath)\n",
        "\n",
        "            # Load and validate input data\n",
        "            df = self._load_input_file(filepath)\n",
        "\n",
        "            # Create parent file\n",
        "            parent_df = self._create_parent_file(df)\n",
        "\n",
        "            # Process child calculations\n",
        "            child_df = self._process_child_calculations(df, parent_df)\n",
        "\n",
        "            # Update parent with child data\n",
        "            parent_df = self._update_parent_with_child_data(parent_df, child_df)\n",
        "\n",
        "            # Generate summary statistics\n",
        "            self._generate_summary(parent_df, child_df, ticker)\n",
        "\n",
        "            # Export results\n",
        "            self._export_results(parent_df, child_df, ticker)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_filename(self, filepath):\n",
        "        \"\"\"Parse input filename for ticker and metadata\"\"\"\n",
        "        filename = Path(filepath).stem\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) != 3:\n",
        "            raise ValueError(f\"Invalid filename format: {filename}\")\n",
        "        return parts[0], parts[1], parts[2]\n",
        "\n",
        "    def _load_input_file(self, filepath):\n",
        "        \"\"\"Load and validate input file\"\"\"\n",
        "        # Read CSV with date parsing\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Convert date to datetime and set as index\n",
        "        try:\n",
        "            df['date'] = pd.to_datetime(df['date'])\n",
        "            df.sort_values('date', inplace=True)\n",
        "            df.set_index('date', inplace=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing date column: {str(e)}\")\n",
        "\n",
        "        # Validate OHLC relationships\n",
        "        valid_mask = (\n",
        "            (df['low'] <= df['open']) &\n",
        "            (df['low'] <= df['close']) &\n",
        "            (df['high'] >= df['open']) &\n",
        "            (df['high'] >= df['close']) &\n",
        "            (df['high'] - df['low'] > 0)\n",
        "        )\n",
        "\n",
        "        invalid_rows = df[~valid_mask]\n",
        "        if len(invalid_rows) > 0:\n",
        "            self.logger.warning(f\"Removing {len(invalid_rows)} invalid rows\")\n",
        "            df = df[valid_mask]\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _create_parent_file(self, df):\n",
        "        \"\"\"Create parent file from child data\"\"\"\n",
        "        parent_processor = ParentProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return parent_processor.create_parent_file(df)\n",
        "\n",
        "    def _process_child_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        child_processor = ChildProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return child_processor.process_calculations(df, parent_df)\n",
        "\n",
        "    def _update_parent_with_child_data(self, parent_df, child_df):\n",
        "        \"\"\"Update parent file with aggregated child data\"\"\"\n",
        "        updater = ParentUpdater(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return updater.update_parent(parent_df, child_df)\n",
        "\n",
        "    def _generate_summary(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate summary statistics\"\"\"\n",
        "        summary = SummaryGenerator()\n",
        "        return summary.generate(parent_df, child_df, ticker)\n",
        "\n",
        "    def _export_results(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Export results to CSV files\"\"\"\n",
        "        # Export child file\n",
        "        child_path = f'output_child/{ticker}_child_{self.child_period}.csv'\n",
        "        child_df.to_csv(child_path, index=False)\n",
        "\n",
        "        # Export parent file\n",
        "        parent_path = f'output_parent/{ticker}_parent_{self.parent_period}.csv'\n",
        "        parent_df.to_csv(parent_path, index=False)\n",
        "\n",
        "        self.logger.info(f\"Results exported: {child_path}, {parent_path}\")\n",
        "\n",
        "\n",
        "class ParentProcessor:\n",
        "    \"\"\"Handles creation and processing of parent file\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def create_parent_file(self, df):\n",
        "        \"\"\"Create parent file by aggregating child data\"\"\"\n",
        "        # Group by parent period\n",
        "        grouped = self._group_by_parent_period(df)\n",
        "\n",
        "        # Aggregate OHLC\n",
        "        parent_df = grouped.agg({\n",
        "            'open': 'first',\n",
        "            'high': 'max',\n",
        "            'low': 'min',\n",
        "            'close': 'last',\n",
        "            'volume': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Add reference fields\n",
        "        parent_df = self._add_reference_fields(parent_df)\n",
        "\n",
        "        # Calculate basic indicators\n",
        "        parent_df = self._calculate_basic_indicators(parent_df)\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "    def _group_by_parent_period(self, df):\n",
        "        \"\"\"Group data by parent period\"\"\"\n",
        "        if self.parent_period == 'W':\n",
        "            return df.groupby(pd.Grouper(freq='W-FRI'))  # End on Friday\n",
        "        elif self.parent_period == 'M':\n",
        "            return df.groupby(pd.Grouper(freq='ME'))  # Month End\n",
        "        elif self.parent_period == 'Q':\n",
        "            return df.groupby(pd.Grouper(freq='Q-DEC'))  # Quarter End\n",
        "        elif self.parent_period == 'Y':\n",
        "            return df.groupby(pd.Grouper(freq='Y'))  # Year End\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid parent period: {self.parent_period}\")\n",
        "\n",
        "    def _add_reference_fields(self, df):\n",
        "        \"\"\"Add reference fields to parent dataframe\"\"\"\n",
        "        df['serial_id'] = self._generate_serial_ids(df)\n",
        "        df['model_type'] = 1  # bar/prior bar\n",
        "        df['child_period'] = self.child_period\n",
        "        df['parent_period'] = self.parent_period\n",
        "        df['create_date'] = datetime.now().strftime('%Y-%m-%d')\n",
        "        df['create_time'] = datetime.now().strftime('%H:%M:%S')\n",
        "        return df\n",
        "\n",
        "    def _generate_serial_ids(self, df):\n",
        "        \"\"\"Generate unique 13-digit serial IDs\"\"\"\n",
        "        base = int(datetime.now().strftime('%Y%m%d%H%M'))\n",
        "        return [f\"{base}{i:03d}\" for i in range(len(df))]\n",
        "\n",
        "    def _calculate_basic_indicators(self, df):\n",
        "        \"\"\"Calculate basic technical indicators\"\"\"\n",
        "        # Calculate range\n",
        "        df['range'] = df['high'] - df['low']\n",
        "\n",
        "        # Calculate percent_r\n",
        "        df['percent_r'] = (df['close'] - df['low']) / df['range']\n",
        "\n",
        "        # Add prior bar references\n",
        "        df['ro'] = df['open'].shift(1)\n",
        "        df['rh'] = df['high'].shift(1)\n",
        "        df['rl'] = df['low'].shift(1)\n",
        "        df['rc'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class ChildProcessor:\n",
        "    \"\"\"Handles child calculations including bar/prior bar and gel calculations\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def process_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        # Add trading_bop\n",
        "        df = self._add_trading_bop(df)\n",
        "\n",
        "        # Calculate bar/prior bar\n",
        "        df = self._calculate_bar_prior_bar(df)\n",
        "\n",
        "        # Calculate gel values\n",
        "        df = self._calculate_gel_values(df)\n",
        "\n",
        "        # Calculate prior parent values\n",
        "        df = self._calculate_prior_parent(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_trading_bop(self, df):\n",
        "        \"\"\"Add trading bar of parent field\"\"\"\n",
        "        # Group by parent period and assign sequential numbers\n",
        "        if self.parent_period == 'W':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='W')).cumcount() + 1\n",
        "        elif self.parent_period == 'M':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='M')).cumcount() + 1\n",
        "        elif self.parent_period == 'Q':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Q')).cumcount() + 1\n",
        "        elif self.parent_period == 'Y':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Y')).cumcount() + 1\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_bar_prior_bar(self, df):\n",
        "        \"\"\"Calculate bar/prior bar values\"\"\"\n",
        "        # REU/RED calculations\n",
        "        df['reu_value'] = df.apply(\n",
        "            lambda x: x['high'] - x['high'].shift(1) if x['high'] > x['high'].shift(1) else 0\n",
        "        )\n",
        "        df['red_value'] = df.apply(\n",
        "            lambda x: abs(x['low'] - x['low'].shift(1)) if x['low'] < x['low'].shift(1) else 0\n",
        "        )\n",
        "\n",
        "        # Flags\n",
        "        df['reu_flag'] = (df['reu_value'] > 0).astype(int)\n",
        "        df['red_flag'] = (df['red_value'] > 0).astype(int)\n",
        "        df['re_value'] = df['reu_value'] + df['red_value']\n",
        "        df['re_flag'] = ((df['reu_flag'] == 1) | (df['red_flag'] == 1)).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "class GelCalculator:\n",
        "    \"\"\"Handles Gel calculations including expansions and pattern recognition\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_gel_values(self, df):\n",
        "        \"\"\"Calculate all gel-related values\"\"\"\n",
        "        # Initialize gel OHLC\n",
        "        df = self._initialize_gel_ohlc(df)\n",
        "\n",
        "        # Calculate gel ranges and percentages\n",
        "        df = self._calculate_gel_ranges(df)\n",
        "\n",
        "        # Calculate gel expansions\n",
        "        df = self._calculate_gel_expansions(df)\n",
        "\n",
        "        # Calculate gel patterns\n",
        "        df = self._calculate_gel_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_gel_ohlc(self, df):\n",
        "        \"\"\"Initialize gel OHLC values\"\"\"\n",
        "        # First bar of parent sets initial values\n",
        "        df['gel_open'] = df.apply(\n",
        "            lambda x: x['open'] if x['trading_bop'] == 1\n",
        "            else x['gel_open'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        # Running high/low within parent\n",
        "        df['gel_high'] = df.apply(\n",
        "            lambda x: x['high'] if x['trading_bop'] == 1\n",
        "            else max(x['high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_low'] = df.apply(\n",
        "            lambda x: x['low'] if x['trading_bop'] == 1\n",
        "            else min(x['low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_close'] = df['close']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_ranges(self, df):\n",
        "        \"\"\"Calculate gel ranges and percentages\"\"\"\n",
        "        df['gel_range'] = df['gel_high'] - df['gel_low']\n",
        "        df['gel_percent_r'] = (df['gel_close'] - df['gel_low']) / df['gel_range']\n",
        "\n",
        "        # Calculate gel ce_percent\n",
        "        df['gel_ce_percent'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else 1 - x['gel_percent_r'].shift(1) if x['gel_percent_r'].shift(1) >= 0.5\n",
        "            else x['gel_percent_r'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_expansions(self, df):\n",
        "        \"\"\"Calculate gel expansion values\"\"\"\n",
        "        # Calculate REU/RED for gel\n",
        "        df['gel_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['gel_high'] - x['gel_high'].shift(1) if x['gel_high'] > x['gel_high'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['gel_low'] - x['gel_low'].shift(1)) if x['gel_low'] < x['gel_low'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gel_reu_flag'] = (df['gel_reu_value'] > 0).astype(int)\n",
        "        df['gel_red_flag'] = (df['gel_red_value'] > 0).astype(int)\n",
        "        df['gel_re_value'] = df['gel_reu_value'] + df['gel_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_patterns(self, df):\n",
        "        \"\"\"Calculate gel pattern indicators\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gel_epc'] = np.ceil(df['gel_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gel_epc_dir'] = (df['gel_percent_r'].shift(1) >= 0.5).astype(int)\n",
        "        df['gel_epc_hp'] = (df['gel_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate E1/E2 values\n",
        "        df['gel_e1_value'] = df.apply(\n",
        "            lambda x: x['gel_reu_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_red_value'], axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_e2_value'] = df.apply(\n",
        "            lambda x: x['gel_red_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_reu_value'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class PriorParentCalculator:\n",
        "    \"\"\"Handles calculations related to prior parent period relationships\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_prior_parent(self, df):\n",
        "        \"\"\"Calculate all prior parent related values\"\"\"\n",
        "        # Initialize parent reference values\n",
        "        df = self._initialize_parent_refs(df)\n",
        "\n",
        "        # Calculate ranges and percentages\n",
        "        df = self._calculate_parent_ranges(df)\n",
        "\n",
        "        # Calculate expansions against prior parent\n",
        "        df = self._calculate_parent_expansions(df)\n",
        "\n",
        "        # Calculate patterns and directions\n",
        "        df = self._calculate_parent_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_parent_refs(self, df):\n",
        "        \"\"\"Initialize references to parent values\"\"\"\n",
        "        df['gelp_open'] = df['parent_open']\n",
        "\n",
        "        # Running high/low against parent\n",
        "        df['gelp_high'] = df.apply(\n",
        "            lambda x: x['parent_high'] if x['trading_bop'] == 1\n",
        "            else max(x['parent_high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_low'] = df.apply(\n",
        "            lambda x: x['parent_low'] if x['trading_bop'] == 1\n",
        "            else min(x['parent_low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_close'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_ranges(self, df):\n",
        "        \"\"\"Calculate ranges and percentages against parent\"\"\"\n",
        "        df['gelp_range'] = df['gelp_high'] - df['gelp_low']\n",
        "        df['gelp_percent_r'] = (df['gelp_close'] - df['gelp_low']) / df['gelp_range']\n",
        "\n",
        "        df['gelp_ce_percent'] = df.apply(\n",
        "            lambda x: 1 - x['gelp_percent_r'] if x['gelp_percent_r'] >= 0.5\n",
        "            else x['gelp_percent_r'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_expansions(self, df):\n",
        "        \"\"\"Calculate expansions against parent values\"\"\"\n",
        "        # Calculate REU/RED against parent\n",
        "        df['gelp_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['high'] - x['gelp_high'] if x['high'] > x['gelp_high']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['low'] - x['gelp_low']) if x['low'] < x['gelp_low']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gelp_reu_flag'] = (df['gelp_reu_value'] > 0).astype(int)\n",
        "        df['gelp_red_flag'] = (df['gelp_red_value'] > 0).astype(int)\n",
        "        df['gelp_re_value'] = df['gelp_reu_value'] + df['gelp_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_patterns(self, df):\n",
        "        \"\"\"Calculate pattern indicators against parent\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gelp_epc'] = np.ceil(df['gelp_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gelp_epc_dir'] = (df['gelp_percent_r'] >= 0.5).astype(int)\n",
        "        df['gelp_epc_hp_flag'] = (df['gelp_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate direction and RPC\n",
        "        df['gelp_dir'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_dir'].shift(1) if x['gelp_re_flag'] == 0\n",
        "            else 0 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == 1\n",
        "            else 1 if x['gelp_reu_flag'] == 1\n",
        "            else x['gelp_dir'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_rpc'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_rpc'].shift(1) if x['gelp_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 2 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 1, axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class SummaryGenerator:\n",
        "    \"\"\"Generates summary statistics and analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate complete summary statistics\"\"\"\n",
        "        summary = {}\n",
        "\n",
        "        # Parent level statistics\n",
        "        summary.update(self._generate_parent_stats(parent_df))\n",
        "\n",
        "        # Child level statistics\n",
        "        summary.update(self._generate_child_stats(child_df))\n",
        "\n",
        "        # Pattern analysis\n",
        "        summary.update(self._analyze_patterns(parent_df, child_df))\n",
        "\n",
        "        # Export summary\n",
        "        self._export_summary(summary, ticker)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _generate_parent_stats(self, df):\n",
        "        \"\"\"Generate parent level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        # E1 FRE flag by EPC HP\n",
        "        e1_hp_stats = df[df['epc_hp'] == 1]['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_hp_counts'] = e1_hp_stats.to_dict()\n",
        "        stats['e1_fre_flag_hp_percentages'] = (e1_hp_stats / len(df[df['epc_hp'] == 1]) * 100).to_dict()\n",
        "\n",
        "        # Range histogram\n",
        "        stats['range_histogram'] = df['range'].describe().to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _generate_child_stats(self, df):\n",
        "        \"\"\"Generate child level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['child_e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['child_e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _analyze_patterns(self, parent_df, child_df):\n",
        "        \"\"\"Analyze patterns across parent and child data\"\"\"\n",
        "        patterns = {}\n",
        "\n",
        "        # Analyze expansion patterns\n",
        "        patterns['avg_expansion_by_period'] = child_df.groupby('trading_bop')['re_value'].mean().to_dict()\n",
        "\n",
        "        # Analyze direction persistence\n",
        "        patterns['direction_persistence'] = self._calculate_direction_persistence(child_df)\n",
        "\n",
        "        # Analyze high/low positioning\n",
        "        patterns['hl_position_stats'] = self._analyze_hl_positions(child_df)\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def _calculate_direction_persistence(self, df):\n",
        "        \"\"\"Calculate statistics about direction persistence\"\"\"\n",
        "        return {\n",
        "            'avg_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().mean(),\n",
        "            'max_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().max()\n",
        "        }\n",
        "\n",
        "    def _analyze_hl_positions(self, df):\n",
        "        \"\"\"Analyze high/low position patterns\"\"\"\n",
        "        return {\n",
        "            'early_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) & (df['trading_bop'] <= 2)]),\n",
        "            'middle_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                               (df['trading_bop'] > 2) & (df['trading_bop'] < df['parent_duration'] - 1)]),\n",
        "            'late_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                             (df['trading_bop'] >= df['parent_duration'] - 1)])\n",
        "        }\n",
        "\n",
        "    def _export_summary(self, summary, ticker):\n",
        "        \"\"\"Export summary statistics to CSV\"\"\"\n",
        "        # Convert nested dict to flat format for CSV\n",
        "        flat_summary = self._flatten_dict(summary)\n",
        "\n",
        "        # Create DataFrame and export\n",
        "        summary_df = pd.DataFrame([flat_summary])\n",
        "        summary_df.to_csv(f'output_gel_sum/{ticker}_summary.csv', index=False)\n",
        "\n",
        "    def _flatten_dict(self, d, parent_key='', sep='_'):\n",
        "        \"\"\"Flatten nested dictionary for CSV export\"\"\"\n",
        "        items = []\n",
        "        for k, v in d.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "            if isinstance(v, dict):\n",
        "                items.extend(self._flatten_dict(v, new_key, sep=sep).items())\n",
        "            else:\n",
        "                items.append((new_key, v))\n",
        "        return dict(items)\n",
        "\n",
        "class ParentUpdater:\n",
        "    \"\"\"Updates parent file with aggregated child data\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def update_parent(self, parent_df, child_df):\n",
        "        \"\"\"Update parent with aggregated child data\"\"\"\n",
        "        # Calculate intrabar counts\n",
        "        intrabar_counts = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).agg({\n",
        "            'reu_flag': 'sum',\n",
        "            'red_flag': 'sum',\n",
        "            'rpc': 'sum'\n",
        "        }).rename(columns={\n",
        "            'reu_flag': 'intrabar_reu_count',\n",
        "            'red_flag': 'intrabar_red_count',\n",
        "            'rpc': 'intrabar_rpc'\n",
        "        })\n",
        "\n",
        "        # Calculate priorbar counts\n",
        "        priorbar_counts = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).agg({\n",
        "            'gelp_reu_flag': 'sum',\n",
        "            'gelp_red_flag': 'sum',\n",
        "            'gelp_red_flag': 'sum'  # Using red_flag for rpc as per spec\n",
        "        }).rename(columns={\n",
        "            'gelp_reu_flag': 'priorbar_reu_count',\n",
        "            'gelp_red_flag': 'priorbar_red_count',\n",
        "            'gelp_red_flag': 'priorbar_rpc'\n",
        "        })\n",
        "\n",
        "        # Find first/last RE positions\n",
        "        def get_positions(group):\n",
        "            re_bars = group[group['gelp_re_flag'] == 1]['trading_bop']\n",
        "            return pd.Series({\n",
        "                'priorbar_first_re': re_bars.iloc[0] if len(re_bars) > 0 else None,\n",
        "                'priorbar_last_re': re_bars.iloc[-1] if len(re_bars) > 0 else None\n",
        "            })\n",
        "\n",
        "        positions = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).apply(get_positions)\n",
        "\n",
        "        # Merge all updates into parent\n",
        "        parent_df = parent_df.join(intrabar_counts, how='left')\n",
        "        parent_df = parent_df.join(priorbar_counts, how='left')\n",
        "        parent_df = parent_df.join(positions, how='left')\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Initialize processor\n",
        "    processor = GetSetsProcessor(child_period='D', parent_period='M')\n",
        "\n",
        "    # Process all files in input directory\n",
        "    input_dir = Path('/content/input')\n",
        "\n",
        "    if not input_dir.exists():\n",
        "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
        "\n",
        "    # Process each CSV file\n",
        "    for file_path in input_dir.glob('*.csv'):\n",
        "        try:\n",
        "            print(f\"\\nProcessing file: {file_path}\")\n",
        "            processor.process_file(file_path)\n",
        "            print(f\"Successfully processed: {file_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {str(e)}\")\n",
        "            logging.error(f\"Error processing {file_path}: {str(e)}\", exc_info=True)\n",
        "\n",
        "# Run the processor\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CByDyxJV3gqJ",
        "outputId": "c1dc7d4a-18d5-4392-ba90-08c8788e0797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:GetSets:Error processing file /content/input/AAPL_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "ERROR:root:Error processing /content/input/AAPL_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 668, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 60, in process_file\n",
            "    parent_df = self._create_parent_file(df)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 129, in _create_parent_file\n",
            "    return parent_processor.create_parent_file(df)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 178, in create_parent_file\n",
            "    parent_df = grouped.agg({\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1432, in aggregate\n",
            "    result = op.agg()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 190, in agg\n",
            "    return self.agg_dict_like()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 423, in agg_dict_like\n",
            "    return self.agg_or_apply_dict_like(op_name=\"agg\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 1608, in agg_or_apply_dict_like\n",
            "    result_index, result_data = self.compute_dict_like(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 462, in compute_dict_like\n",
            "    func = self.normalize_dictlike_arg(op_name, selected_obj, func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 663, in normalize_dictlike_arg\n",
            "    raise KeyError(f\"Column(s) {list(cols)} do not exist\")\n",
            "KeyError: \"Column(s) ['volume'] do not exist\"\n",
            "ERROR:GetSets:Error processing file /content/input/MMM_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "ERROR:root:Error processing /content/input/MMM_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 668, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 60, in process_file\n",
            "    parent_df = self._create_parent_file(df)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 129, in _create_parent_file\n",
            "    return parent_processor.create_parent_file(df)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 178, in create_parent_file\n",
            "    parent_df = grouped.agg({\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1432, in aggregate\n",
            "    result = op.agg()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 190, in agg\n",
            "    return self.agg_dict_like()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 423, in agg_dict_like\n",
            "    return self.agg_or_apply_dict_like(op_name=\"agg\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 1608, in agg_or_apply_dict_like\n",
            "    result_index, result_data = self.compute_dict_like(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 462, in compute_dict_like\n",
            "    func = self.normalize_dictlike_arg(op_name, selected_obj, func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 663, in normalize_dictlike_arg\n",
            "    raise KeyError(f\"Column(s) {list(cols)} do not exist\")\n",
            "KeyError: \"Column(s) ['volume'] do not exist\"\n",
            "ERROR:GetSets:Error processing file /content/input/XLB_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "ERROR:root:Error processing /content/input/XLB_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 668, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 60, in process_file\n",
            "    parent_df = self._create_parent_file(df)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 129, in _create_parent_file\n",
            "    return parent_processor.create_parent_file(df)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 178, in create_parent_file\n",
            "    parent_df = grouped.agg({\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1432, in aggregate\n",
            "    result = op.agg()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 190, in agg\n",
            "    return self.agg_dict_like()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 423, in agg_dict_like\n",
            "    return self.agg_or_apply_dict_like(op_name=\"agg\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 1608, in agg_or_apply_dict_like\n",
            "    result_index, result_data = self.compute_dict_like(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 462, in compute_dict_like\n",
            "    func = self.normalize_dictlike_arg(op_name, selected_obj, func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 663, in normalize_dictlike_arg\n",
            "    raise KeyError(f\"Column(s) {list(cols)} do not exist\")\n",
            "KeyError: \"Column(s) ['volume'] do not exist\"\n",
            "ERROR:GetSets:Error processing file /content/input/AFL_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "ERROR:root:Error processing /content/input/AFL_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 668, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 60, in process_file\n",
            "    parent_df = self._create_parent_file(df)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 129, in _create_parent_file\n",
            "    return parent_processor.create_parent_file(df)\n",
            "  File \"<ipython-input-5-7cf191bc6a55>\", line 178, in create_parent_file\n",
            "    parent_df = grouped.agg({\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1432, in aggregate\n",
            "    result = op.agg()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 190, in agg\n",
            "    return self.agg_dict_like()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 423, in agg_dict_like\n",
            "    return self.agg_or_apply_dict_like(op_name=\"agg\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 1608, in agg_or_apply_dict_like\n",
            "    result_index, result_data = self.compute_dict_like(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 462, in compute_dict_like\n",
            "    func = self.normalize_dictlike_arg(op_name, selected_obj, func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\", line 663, in normalize_dictlike_arg\n",
            "    raise KeyError(f\"Column(s) {list(cols)} do not exist\")\n",
            "KeyError: \"Column(s) ['volume'] do not exist\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing file: /content/input/AAPL_D_1.csv\n",
            "Error processing /content/input/AAPL_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "\n",
            "Processing file: /content/input/MMM_D_1.csv\n",
            "Error processing /content/input/MMM_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "\n",
            "Processing file: /content/input/XLB_D_1.csv\n",
            "Error processing /content/input/XLB_D_1.csv: \"Column(s) ['volume'] do not exist\"\n",
            "\n",
            "Processing file: /content/input/AFL_D_1.csv\n",
            "Error processing /content/input/AFL_D_1.csv: \"Column(s) ['volume'] do not exist\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "class GetSetsProcessor:\n",
        "    \"\"\"Main processor for Get Sets analysis\"\"\"\n",
        "\n",
        "    def __init__(self, child_period='D', parent_period='M', jobname='Gelset'):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "        self.setup_logging()\n",
        "\n",
        "        # Validate period combinations\n",
        "        self._validate_periods()\n",
        "\n",
        "        # Setup paths\n",
        "        self.setup_directories()\n",
        "\n",
        "    def _validate_periods(self):\n",
        "        \"\"\"Validate period combinations\"\"\"\n",
        "        valid_combinations = {\n",
        "            ('D', 'W'), ('D', 'M'),\n",
        "            ('M', 'Q'), ('M', 'Y'),\n",
        "            ('Q', 'Y'), ('D', 'Q')\n",
        "        }\n",
        "        if (self.child_period, self.parent_period) not in valid_combinations:\n",
        "            raise ValueError(f\"Invalid period combination: {self.child_period}/{self.parent_period}\")\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Initialize logging\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(f'getsets_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger('GetSets')\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create required output directories\"\"\"\n",
        "        directories = ['output_child', 'output_parent', 'output_gel_sum']\n",
        "        for dir_name in directories:\n",
        "            Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "    def process_file(self, filepath):\n",
        "        \"\"\"Process a single input file\"\"\"\n",
        "        try:\n",
        "            # Extract file information\n",
        "            ticker, temporal_period, rolling_range = self._parse_filename(filepath)\n",
        "\n",
        "            # Load and validate input data\n",
        "            df = self._load_input_file(filepath)\n",
        "\n",
        "            # Create parent file\n",
        "            parent_df = self._create_parent_file(df)\n",
        "\n",
        "            # Process child calculations\n",
        "            child_df = self._process_child_calculations(df, parent_df)\n",
        "\n",
        "            # Update parent with child data\n",
        "            parent_df = self._update_parent_with_child_data(parent_df, child_df)\n",
        "\n",
        "            # Generate summary statistics\n",
        "            self._generate_summary(parent_df, child_df, ticker)\n",
        "\n",
        "            # Export results\n",
        "            self._export_results(parent_df, child_df, ticker)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_filename(self, filepath):\n",
        "        \"\"\"Parse input filename for ticker and metadata\"\"\"\n",
        "        filename = Path(filepath).stem\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) != 3:\n",
        "            raise ValueError(f\"Invalid filename format: {filename}\")\n",
        "        return parts[0], parts[1], parts[2]\n",
        "\n",
        "    def _load_input_file(self, filepath):\n",
        "        \"\"\"Load and validate input file\"\"\"\n",
        "        # Read CSV with date parsing\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Convert date to datetime and set as index\n",
        "        try:\n",
        "            df['date'] = pd.to_datetime(df['date'])\n",
        "            df.sort_values('date', inplace=True)\n",
        "            df.set_index('date', inplace=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing date column: {str(e)}\")\n",
        "\n",
        "        # Validate OHLC relationships\n",
        "        valid_mask = (\n",
        "            (df['low'] <= df['open']) &\n",
        "            (df['low'] <= df['close']) &\n",
        "            (df['high'] >= df['open']) &\n",
        "            (df['high'] >= df['close']) &\n",
        "            (df['high'] - df['low'] > 0)\n",
        "        )\n",
        "\n",
        "        invalid_rows = df[~valid_mask]\n",
        "        if len(invalid_rows) > 0:\n",
        "            self.logger.warning(f\"Removing {len(invalid_rows)} invalid rows\")\n",
        "            df = df[valid_mask]\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _create_parent_file(self, df):\n",
        "        \"\"\"Create parent file from child data\"\"\"\n",
        "        parent_processor = ParentProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return parent_processor.create_parent_file(df)\n",
        "\n",
        "    def _process_child_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        child_processor = ChildProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return child_processor.process_calculations(df, parent_df)\n",
        "\n",
        "    def _update_parent_with_child_data(self, parent_df, child_df):\n",
        "        \"\"\"Update parent file with aggregated child data\"\"\"\n",
        "        updater = ParentUpdater(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return updater.update_parent(parent_df, child_df)\n",
        "\n",
        "    def _generate_summary(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate summary statistics\"\"\"\n",
        "        summary = SummaryGenerator()\n",
        "        return summary.generate(parent_df, child_df, ticker)\n",
        "\n",
        "    def _export_results(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Export results to CSV files\"\"\"\n",
        "        # Export child file\n",
        "        child_path = f'output_child/{ticker}_child_{self.child_period}.csv'\n",
        "        child_df.to_csv(child_path, index=False)\n",
        "\n",
        "        # Export parent file\n",
        "        parent_path = f'output_parent/{ticker}_parent_{self.parent_period}.csv'\n",
        "        parent_df.to_csv(parent_path, index=False)\n",
        "\n",
        "        self.logger.info(f\"Results exported: {child_path}, {parent_path}\")\n",
        "\n",
        "\n",
        "class ParentProcessor:\n",
        "    \"\"\"Handles creation and processing of parent file\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def create_parent_file(self, df):\n",
        "        \"\"\"Create parent file by aggregating child data\"\"\"\n",
        "        # Group by parent period\n",
        "        grouped = self._group_by_parent_period(df)\n",
        "\n",
        "        # Define base OHLC aggregation\n",
        "        agg_dict = {\n",
        "            'open': 'first',\n",
        "            'high': 'max',\n",
        "            'low': 'min',\n",
        "            'close': 'last'\n",
        "        }\n",
        "\n",
        "        # Add volume if it exists\n",
        "        if 'volume' in df.columns:\n",
        "            agg_dict['volume'] = 'sum'\n",
        "\n",
        "        # Aggregate using available columns\n",
        "        parent_df = grouped.agg(agg_dict).reset_index()\n",
        "\n",
        "        # Add reference fields\n",
        "        parent_df = self._add_reference_fields(parent_df)\n",
        "\n",
        "        # Calculate basic indicators\n",
        "        parent_df = self._calculate_basic_indicators(parent_df)\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "    def _group_by_parent_period(self, df):\n",
        "        \"\"\"Group data by parent period\"\"\"\n",
        "        if self.parent_period == 'W':\n",
        "            return df.groupby(pd.Grouper(freq='W-FRI'))  # End on Friday\n",
        "        elif self.parent_period == 'M':\n",
        "            return df.groupby(pd.Grouper(freq='ME'))  # Month End\n",
        "        elif self.parent_period == 'Q':\n",
        "            return df.groupby(pd.Grouper(freq='Q-DEC'))  # Quarter End\n",
        "        elif self.parent_period == 'Y':\n",
        "            return df.groupby(pd.Grouper(freq='Y'))  # Year End\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid parent period: {self.parent_period}\")\n",
        "\n",
        "    def _add_reference_fields(self, df):\n",
        "        \"\"\"Add reference fields to parent dataframe\"\"\"\n",
        "        df['serial_id'] = self._generate_serial_ids(df)\n",
        "        df['model_type'] = 1  # bar/prior bar\n",
        "        df['child_period'] = self.child_period\n",
        "        df['parent_period'] = self.parent_period\n",
        "        df['create_date'] = datetime.now().strftime('%Y-%m-%d')\n",
        "        df['create_time'] = datetime.now().strftime('%H:%M:%S')\n",
        "        return df\n",
        "\n",
        "    def _generate_serial_ids(self, df):\n",
        "        \"\"\"Generate unique 13-digit serial IDs\"\"\"\n",
        "        base = int(datetime.now().strftime('%Y%m%d%H%M'))\n",
        "        return [f\"{base}{i:03d}\" for i in range(len(df))]\n",
        "\n",
        "    def _calculate_basic_indicators(self, df):\n",
        "        \"\"\"Calculate basic technical indicators\"\"\"\n",
        "        # Calculate range\n",
        "        df['range'] = df['high'] - df['low']\n",
        "\n",
        "        # Calculate percent_r\n",
        "        df['percent_r'] = (df['close'] - df['low']) / df['range']\n",
        "\n",
        "        # Add prior bar references\n",
        "        df['ro'] = df['open'].shift(1)\n",
        "        df['rh'] = df['high'].shift(1)\n",
        "        df['rl'] = df['low'].shift(1)\n",
        "        df['rc'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class ChildProcessor:\n",
        "    \"\"\"Handles child calculations including bar/prior bar and gel calculations\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def process_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        # Add trading_bop\n",
        "        df = self._add_trading_bop(df)\n",
        "\n",
        "        # Calculate bar/prior bar\n",
        "        df = self._calculate_bar_prior_bar(df)\n",
        "\n",
        "        # Calculate gel values\n",
        "        df = self._calculate_gel_values(df)\n",
        "\n",
        "        # Calculate prior parent values\n",
        "        df = self._calculate_prior_parent(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_trading_bop(self, df):\n",
        "        \"\"\"Add trading bar of parent field\"\"\"\n",
        "        # Group by parent period and assign sequential numbers\n",
        "        if self.parent_period == 'W':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='W')).cumcount() + 1\n",
        "        elif self.parent_period == 'M':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='M')).cumcount() + 1\n",
        "        elif self.parent_period == 'Q':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Q')).cumcount() + 1\n",
        "        elif self.parent_period == 'Y':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Y')).cumcount() + 1\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_bar_prior_bar(self, df):\n",
        "        \"\"\"Calculate bar/prior bar values\"\"\"\n",
        "        # REU/RED calculations\n",
        "        df['reu_value'] = df.apply(\n",
        "            lambda x: x['high'] - x['high'].shift(1) if x['high'] > x['high'].shift(1) else 0\n",
        "        )\n",
        "        df['red_value'] = df.apply(\n",
        "            lambda x: abs(x['low'] - x['low'].shift(1)) if x['low'] < x['low'].shift(1) else 0\n",
        "        )\n",
        "\n",
        "        # Flags\n",
        "        df['reu_flag'] = (df['reu_value'] > 0).astype(int)\n",
        "        df['red_flag'] = (df['red_value'] > 0).astype(int)\n",
        "        df['re_value'] = df['reu_value'] + df['red_value']\n",
        "        df['re_flag'] = ((df['reu_flag'] == 1) | (df['red_flag'] == 1)).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "class GelCalculator:\n",
        "    \"\"\"Handles Gel calculations including expansions and pattern recognition\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_gel_values(self, df):\n",
        "        \"\"\"Calculate all gel-related values\"\"\"\n",
        "        # Initialize gel OHLC\n",
        "        df = self._initialize_gel_ohlc(df)\n",
        "\n",
        "        # Calculate gel ranges and percentages\n",
        "        df = self._calculate_gel_ranges(df)\n",
        "\n",
        "        # Calculate gel expansions\n",
        "        df = self._calculate_gel_expansions(df)\n",
        "\n",
        "        # Calculate gel patterns\n",
        "        df = self._calculate_gel_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_gel_ohlc(self, df):\n",
        "        \"\"\"Initialize gel OHLC values\"\"\"\n",
        "        # First bar of parent sets initial values\n",
        "        df['gel_open'] = df.apply(\n",
        "            lambda x: x['open'] if x['trading_bop'] == 1\n",
        "            else x['gel_open'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        # Running high/low within parent\n",
        "        df['gel_high'] = df.apply(\n",
        "            lambda x: x['high'] if x['trading_bop'] == 1\n",
        "            else max(x['high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_low'] = df.apply(\n",
        "            lambda x: x['low'] if x['trading_bop'] == 1\n",
        "            else min(x['low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_close'] = df['close']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_ranges(self, df):\n",
        "        \"\"\"Calculate gel ranges and percentages\"\"\"\n",
        "        df['gel_range'] = df['gel_high'] - df['gel_low']\n",
        "        df['gel_percent_r'] = (df['gel_close'] - df['gel_low']) / df['gel_range']\n",
        "\n",
        "        # Calculate gel ce_percent\n",
        "        df['gel_ce_percent'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else 1 - x['gel_percent_r'].shift(1) if x['gel_percent_r'].shift(1) >= 0.5\n",
        "            else x['gel_percent_r'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_expansions(self, df):\n",
        "        \"\"\"Calculate gel expansion values\"\"\"\n",
        "        # Calculate REU/RED for gel\n",
        "        df['gel_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['gel_high'] - x['gel_high'].shift(1) if x['gel_high'] > x['gel_high'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['gel_low'] - x['gel_low'].shift(1)) if x['gel_low'] < x['gel_low'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gel_reu_flag'] = (df['gel_reu_value'] > 0).astype(int)\n",
        "        df['gel_red_flag'] = (df['gel_red_value'] > 0).astype(int)\n",
        "        df['gel_re_value'] = df['gel_reu_value'] + df['gel_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_patterns(self, df):\n",
        "        \"\"\"Calculate gel pattern indicators\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gel_epc'] = np.ceil(df['gel_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gel_epc_dir'] = (df['gel_percent_r'].shift(1) >= 0.5).astype(int)\n",
        "        df['gel_epc_hp'] = (df['gel_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate E1/E2 values\n",
        "        df['gel_e1_value'] = df.apply(\n",
        "            lambda x: x['gel_reu_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_red_value'], axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_e2_value'] = df.apply(\n",
        "            lambda x: x['gel_red_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_reu_value'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class PriorParentCalculator:\n",
        "    \"\"\"Handles calculations related to prior parent period relationships\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_prior_parent(self, df):\n",
        "        \"\"\"Calculate all prior parent related values\"\"\"\n",
        "        # Initialize parent reference values\n",
        "        df = self._initialize_parent_refs(df)\n",
        "\n",
        "        # Calculate ranges and percentages\n",
        "        df = self._calculate_parent_ranges(df)\n",
        "\n",
        "        # Calculate expansions against prior parent\n",
        "        df = self._calculate_parent_expansions(df)\n",
        "\n",
        "        # Calculate patterns and directions\n",
        "        df = self._calculate_parent_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_parent_refs(self, df):\n",
        "        \"\"\"Initialize references to parent values\"\"\"\n",
        "        df['gelp_open'] = df['parent_open']\n",
        "\n",
        "        # Running high/low against parent\n",
        "        df['gelp_high'] = df.apply(\n",
        "            lambda x: x['parent_high'] if x['trading_bop'] == 1\n",
        "            else max(x['parent_high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_low'] = df.apply(\n",
        "            lambda x: x['parent_low'] if x['trading_bop'] == 1\n",
        "            else min(x['parent_low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_close'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_ranges(self, df):\n",
        "        \"\"\"Calculate ranges and percentages against parent\"\"\"\n",
        "        df['gelp_range'] = df['gelp_high'] - df['gelp_low']\n",
        "        df['gelp_percent_r'] = (df['gelp_close'] - df['gelp_low']) / df['gelp_range']\n",
        "\n",
        "        df['gelp_ce_percent'] = df.apply(\n",
        "            lambda x: 1 - x['gelp_percent_r'] if x['gelp_percent_r'] >= 0.5\n",
        "            else x['gelp_percent_r'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_expansions(self, df):\n",
        "        \"\"\"Calculate expansions against parent values\"\"\"\n",
        "        # Calculate REU/RED against parent\n",
        "        df['gelp_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['high'] - x['gelp_high'] if x['high'] > x['gelp_high']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['low'] - x['gelp_low']) if x['low'] < x['gelp_low']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gelp_reu_flag'] = (df['gelp_reu_value'] > 0).astype(int)\n",
        "        df['gelp_red_flag'] = (df['gelp_red_value'] > 0).astype(int)\n",
        "        df['gelp_re_value'] = df['gelp_reu_value'] + df['gelp_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_patterns(self, df):\n",
        "        \"\"\"Calculate pattern indicators against parent\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gelp_epc'] = np.ceil(df['gelp_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gelp_epc_dir'] = (df['gelp_percent_r'] >= 0.5).astype(int)\n",
        "        df['gelp_epc_hp_flag'] = (df['gelp_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate direction and RPC\n",
        "        df['gelp_dir'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_dir'].shift(1) if x['gelp_re_flag'] == 0\n",
        "            else 0 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == 1\n",
        "            else 1 if x['gelp_reu_flag'] == 1\n",
        "            else x['gelp_dir'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_rpc'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_rpc'].shift(1) if x['gelp_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 2 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 1, axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class SummaryGenerator:\n",
        "    \"\"\"Generates summary statistics and analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate complete summary statistics\"\"\"\n",
        "        summary = {}\n",
        "\n",
        "        # Parent level statistics\n",
        "        summary.update(self._generate_parent_stats(parent_df))\n",
        "\n",
        "        # Child level statistics\n",
        "        summary.update(self._generate_child_stats(child_df))\n",
        "\n",
        "        # Pattern analysis\n",
        "        summary.update(self._analyze_patterns(parent_df, child_df))\n",
        "\n",
        "        # Export summary\n",
        "        self._export_summary(summary, ticker)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _generate_parent_stats(self, df):\n",
        "        \"\"\"Generate parent level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        # E1 FRE flag by EPC HP\n",
        "        e1_hp_stats = df[df['epc_hp'] == 1]['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_hp_counts'] = e1_hp_stats.to_dict()\n",
        "        stats['e1_fre_flag_hp_percentages'] = (e1_hp_stats / len(df[df['epc_hp'] == 1]) * 100).to_dict()\n",
        "\n",
        "        # Range histogram\n",
        "        stats['range_histogram'] = df['range'].describe().to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _generate_child_stats(self, df):\n",
        "        \"\"\"Generate child level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['child_e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['child_e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _analyze_patterns(self, parent_df, child_df):\n",
        "        \"\"\"Analyze patterns across parent and child data\"\"\"\n",
        "        patterns = {}\n",
        "\n",
        "        # Analyze expansion patterns\n",
        "        patterns['avg_expansion_by_period'] = child_df.groupby('trading_bop')['re_value'].mean().to_dict()\n",
        "\n",
        "        # Analyze direction persistence\n",
        "        patterns['direction_persistence'] = self._calculate_direction_persistence(child_df)\n",
        "\n",
        "        # Analyze high/low positioning\n",
        "        patterns['hl_position_stats'] = self._analyze_hl_positions(child_df)\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def _calculate_direction_persistence(self, df):\n",
        "        \"\"\"Calculate statistics about direction persistence\"\"\"\n",
        "        return {\n",
        "            'avg_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().mean(),\n",
        "            'max_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().max()\n",
        "        }\n",
        "\n",
        "    def _analyze_hl_positions(self, df):\n",
        "        \"\"\"Analyze high/low position patterns\"\"\"\n",
        "        return {\n",
        "            'early_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) & (df['trading_bop'] <= 2)]),\n",
        "            'middle_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                               (df['trading_bop'] > 2) & (df['trading_bop'] < df['parent_duration'] - 1)]),\n",
        "            'late_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                             (df['trading_bop'] >= df['parent_duration'] - 1)])\n",
        "        }\n",
        "\n",
        "    def _export_summary(self, summary, ticker):\n",
        "        \"\"\"Export summary statistics to CSV\"\"\"\n",
        "        # Convert nested dict to flat format for CSV\n",
        "        flat_summary = self._flatten_dict(summary)\n",
        "\n",
        "        # Create DataFrame and export\n",
        "        summary_df = pd.DataFrame([flat_summary])\n",
        "        summary_df.to_csv(f'output_gel_sum/{ticker}_summary.csv', index=False)\n",
        "\n",
        "    def _flatten_dict(self, d, parent_key='', sep='_'):\n",
        "        \"\"\"Flatten nested dictionary for CSV export\"\"\"\n",
        "        items = []\n",
        "        for k, v in d.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "            if isinstance(v, dict):\n",
        "                items.extend(self._flatten_dict(v, new_key, sep=sep).items())\n",
        "            else:\n",
        "                items.append((new_key, v))\n",
        "        return dict(items)"
      ],
      "metadata": {
        "id": "fMWweRHB4TRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "class GetSetsProcessor:\n",
        "    \"\"\"Main processor for Get Sets analysis\"\"\"\n",
        "\n",
        "    def __init__(self, child_period='D', parent_period='M', jobname='Gelset'):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "        self.setup_logging()\n",
        "\n",
        "        # Validate period combinations\n",
        "        self._validate_periods()\n",
        "\n",
        "        # Setup paths\n",
        "        self.setup_directories()\n",
        "\n",
        "    def _validate_periods(self):\n",
        "        \"\"\"Validate period combinations\"\"\"\n",
        "        valid_combinations = {\n",
        "            ('D', 'W'), ('D', 'M'),\n",
        "            ('M', 'Q'), ('M', 'Y'),\n",
        "            ('Q', 'Y'), ('D', 'Q')\n",
        "        }\n",
        "        if (self.child_period, self.parent_period) not in valid_combinations:\n",
        "            raise ValueError(f\"Invalid period combination: {self.child_period}/{self.parent_period}\")\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Initialize logging\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(f'getsets_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger('GetSets')\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create required output directories\"\"\"\n",
        "        directories = ['output_child', 'output_parent', 'output_gel_sum']\n",
        "        for dir_name in directories:\n",
        "            Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "    def process_file(self, filepath):\n",
        "        \"\"\"Process a single input file\"\"\"\n",
        "        try:\n",
        "            # Extract file information\n",
        "            ticker, temporal_period, rolling_range = self._parse_filename(filepath)\n",
        "\n",
        "            # Load and validate input data\n",
        "            df = self._load_input_file(filepath)\n",
        "\n",
        "            # Create parent file\n",
        "            parent_df = self._create_parent_file(df)\n",
        "\n",
        "            # Process child calculations\n",
        "            child_df = self._process_child_calculations(df, parent_df)\n",
        "\n",
        "            # Update parent with child data\n",
        "            parent_df = self._update_parent_with_child_data(parent_df, child_df)\n",
        "\n",
        "            # Generate summary statistics\n",
        "            self._generate_summary(parent_df, child_df, ticker)\n",
        "\n",
        "            # Export results\n",
        "            self._export_results(parent_df, child_df, ticker)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_filename(self, filepath):\n",
        "        \"\"\"Parse input filename for ticker and metadata\"\"\"\n",
        "        filename = Path(filepath).stem\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) != 3:\n",
        "            raise ValueError(f\"Invalid filename format: {filename}\")\n",
        "        return parts[0], parts[1], parts[2]\n",
        "\n",
        "    def _load_input_file(self, filepath):\n",
        "        \"\"\"Load and validate input file\"\"\"\n",
        "        # Read CSV with date parsing\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Convert date to datetime and set as index\n",
        "        try:\n",
        "            df['date'] = pd.to_datetime(df['date'])\n",
        "            df.sort_values('date', inplace=True)\n",
        "            df.set_index('date', inplace=True)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error processing date column: {str(e)}\")\n",
        "\n",
        "        # Validate OHLC relationships\n",
        "        valid_mask = (\n",
        "            (df['low'] <= df['open']) &\n",
        "            (df['low'] <= df['close']) &\n",
        "            (df['high'] >= df['open']) &\n",
        "            (df['high'] >= df['close']) &\n",
        "            (df['high'] - df['low'] > 0)\n",
        "        )\n",
        "\n",
        "        invalid_rows = df[~valid_mask]\n",
        "        if len(invalid_rows) > 0:\n",
        "            self.logger.warning(f\"Removing {len(invalid_rows)} invalid rows\")\n",
        "            df = df[valid_mask]\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _create_parent_file(self, df):\n",
        "        \"\"\"Create parent file from child data\"\"\"\n",
        "        parent_processor = ParentProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return parent_processor.create_parent_file(df)\n",
        "\n",
        "    def _process_child_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        child_processor = ChildProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return child_processor.process_calculations(df, parent_df)\n",
        "\n",
        "    def _update_parent_with_child_data(self, parent_df, child_df):\n",
        "        \"\"\"Update parent file with aggregated child data\"\"\"\n",
        "        updater = ParentUpdater(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return updater.update_parent(parent_df, child_df)\n",
        "\n",
        "    def _generate_summary(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate summary statistics\"\"\"\n",
        "        summary = SummaryGenerator()\n",
        "        return summary.generate(parent_df, child_df, ticker)\n",
        "\n",
        "    def _export_results(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Export results to CSV files\"\"\"\n",
        "        # Export child file\n",
        "        child_path = f'output_child/{ticker}_child_{self.child_period}.csv'\n",
        "        child_df.to_csv(child_path, index=False)\n",
        "\n",
        "        # Export parent file\n",
        "        parent_path = f'output_parent/{ticker}_parent_{self.parent_period}.csv'\n",
        "        parent_df.to_csv(parent_path, index=False)\n",
        "\n",
        "        self.logger.info(f\"Results exported: {child_path}, {parent_path}\")\n",
        "\n",
        "\n",
        "class ParentProcessor:\n",
        "    \"\"\"Handles creation and processing of parent file\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def create_parent_file(self, df):\n",
        "        \"\"\"Create parent file by aggregating child data\"\"\"\n",
        "        # Group by parent period\n",
        "        grouped = self._group_by_parent_period(df)\n",
        "\n",
        "        # Define base OHLC aggregation\n",
        "        agg_dict = {\n",
        "            'open': 'first',\n",
        "            'high': 'max',\n",
        "            'low': 'min',\n",
        "            'close': 'last'\n",
        "        }\n",
        "\n",
        "        # Add volume if it exists\n",
        "        if 'volume' in df.columns:\n",
        "            agg_dict['volume'] = 'sum'\n",
        "\n",
        "        # Aggregate using available columns\n",
        "        parent_df = grouped.agg(agg_dict).reset_index()\n",
        "\n",
        "        # Add reference fields\n",
        "        parent_df = self._add_reference_fields(parent_df)\n",
        "\n",
        "        # Calculate basic indicators\n",
        "        parent_df = self._calculate_basic_indicators(parent_df)\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "    def _group_by_parent_period(self, df):\n",
        "        \"\"\"Group data by parent period\"\"\"\n",
        "        if self.parent_period == 'W':\n",
        "            return df.groupby(pd.Grouper(freq='W-FRI'))  # End on Friday\n",
        "        elif self.parent_period == 'M':\n",
        "            return df.groupby(pd.Grouper(freq='ME'))  # Month End\n",
        "        elif self.parent_period == 'Q':\n",
        "            return df.groupby(pd.Grouper(freq='Q-DEC'))  # Quarter End\n",
        "        elif self.parent_period == 'Y':\n",
        "            return df.groupby(pd.Grouper(freq='Y'))  # Year End\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid parent period: {self.parent_period}\")\n",
        "\n",
        "    def _add_reference_fields(self, df):\n",
        "        \"\"\"Add reference fields to parent dataframe\"\"\"\n",
        "        df['serial_id'] = self._generate_serial_ids(df)\n",
        "        df['model_type'] = 1  # bar/prior bar\n",
        "        df['child_period'] = self.child_period\n",
        "        df['parent_period'] = self.parent_period\n",
        "        df['create_date'] = datetime.now().strftime('%Y-%m-%d')\n",
        "        df['create_time'] = datetime.now().strftime('%H:%M:%S')\n",
        "        return df\n",
        "\n",
        "    def _generate_serial_ids(self, df):\n",
        "        \"\"\"Generate unique 13-digit serial IDs\"\"\"\n",
        "        base = int(datetime.now().strftime('%Y%m%d%H%M'))\n",
        "        return [f\"{base}{i:03d}\" for i in range(len(df))]\n",
        "\n",
        "    def _calculate_basic_indicators(self, df):\n",
        "        \"\"\"Calculate basic technical indicators\"\"\"\n",
        "        # Calculate range\n",
        "        df['range'] = df['high'] - df['low']\n",
        "\n",
        "        # Calculate percent_r\n",
        "        df['percent_r'] = (df['close'] - df['low']) / df['range']\n",
        "\n",
        "        # Add prior bar references\n",
        "        df['ro'] = df['open'].shift(1)\n",
        "        df['rh'] = df['high'].shift(1)\n",
        "        df['rl'] = df['low'].shift(1)\n",
        "        df['rc'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class ChildProcessor:\n",
        "    \"\"\"Handles child calculations including bar/prior bar and gel calculations\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def process_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        # Add trading_bop\n",
        "        df = self._add_trading_bop(df)\n",
        "\n",
        "        # Calculate bar/prior bar\n",
        "        df = self._calculate_bar_prior_bar(df)\n",
        "\n",
        "        # Calculate gel values\n",
        "        df = self._calculate_gel_values(df)\n",
        "\n",
        "        # Calculate prior parent values\n",
        "        df = self._calculate_prior_parent(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_trading_bop(self, df):\n",
        "        \"\"\"Add trading bar of parent field\"\"\"\n",
        "        # Group by parent period and assign sequential numbers\n",
        "        if self.parent_period == 'W':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='W')).cumcount() + 1\n",
        "        elif self.parent_period == 'M':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='M')).cumcount() + 1\n",
        "        elif self.parent_period == 'Q':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Q')).cumcount() + 1\n",
        "        elif self.parent_period == 'Y':\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(key='date', freq='Y')).cumcount() + 1\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_bar_prior_bar(self, df):\n",
        "        \"\"\"Calculate bar/prior bar values\"\"\"\n",
        "        # REU/RED calculations\n",
        "        df['reu_value'] = df.apply(\n",
        "            lambda x: x['high'] - x['high'].shift(1) if x['high'] > x['high'].shift(1) else 0\n",
        "        )\n",
        "        df['red_value'] = df.apply(\n",
        "            lambda x: abs(x['low'] - x['low'].shift(1)) if x['low'] < x['low'].shift(1) else 0\n",
        "        )\n",
        "\n",
        "        # Flags\n",
        "        df['reu_flag'] = (df['reu_value'] > 0).astype(int)\n",
        "        df['red_flag'] = (df['red_value'] > 0).astype(int)\n",
        "        df['re_value'] = df['reu_value'] + df['red_value']\n",
        "        df['re_flag'] = ((df['reu_flag'] == 1) | (df['red_flag'] == 1)).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "class GelCalculator:\n",
        "    \"\"\"Handles Gel calculations including expansions and pattern recognition\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_gel_values(self, df):\n",
        "        \"\"\"Calculate all gel-related values\"\"\"\n",
        "        # Initialize gel OHLC\n",
        "        df = self._initialize_gel_ohlc(df)\n",
        "\n",
        "        # Calculate gel ranges and percentages\n",
        "        df = self._calculate_gel_ranges(df)\n",
        "\n",
        "        # Calculate gel expansions\n",
        "        df = self._calculate_gel_expansions(df)\n",
        "\n",
        "        # Calculate gel patterns\n",
        "        df = self._calculate_gel_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_gel_ohlc(self, df):\n",
        "        \"\"\"Initialize gel OHLC values\"\"\"\n",
        "        # First bar of parent sets initial values\n",
        "        df['gel_open'] = df.apply(\n",
        "            lambda x: x['open'] if x['trading_bop'] == 1\n",
        "            else x['gel_open'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        # Running high/low within parent\n",
        "        df['gel_high'] = df.apply(\n",
        "            lambda x: x['high'] if x['trading_bop'] == 1\n",
        "            else max(x['high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_low'] = df.apply(\n",
        "            lambda x: x['low'] if x['trading_bop'] == 1\n",
        "            else min(x['low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_close'] = df['close']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_ranges(self, df):\n",
        "        \"\"\"Calculate gel ranges and percentages\"\"\"\n",
        "        df['gel_range'] = df['gel_high'] - df['gel_low']\n",
        "        df['gel_percent_r'] = (df['gel_close'] - df['gel_low']) / df['gel_range']\n",
        "\n",
        "        # Calculate gel ce_percent\n",
        "        df['gel_ce_percent'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else 1 - x['gel_percent_r'].shift(1) if x['gel_percent_r'].shift(1) >= 0.5\n",
        "            else x['gel_percent_r'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_expansions(self, df):\n",
        "        \"\"\"Calculate gel expansion values\"\"\"\n",
        "        # Calculate REU/RED for gel\n",
        "        df['gel_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['gel_high'] - x['gel_high'].shift(1) if x['gel_high'] > x['gel_high'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['gel_low'] - x['gel_low'].shift(1)) if x['gel_low'] < x['gel_low'].shift(1)\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gel_reu_flag'] = (df['gel_reu_value'] > 0).astype(int)\n",
        "        df['gel_red_flag'] = (df['gel_red_value'] > 0).astype(int)\n",
        "        df['gel_re_value'] = df['gel_reu_value'] + df['gel_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_gel_patterns(self, df):\n",
        "        \"\"\"Calculate gel pattern indicators\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gel_epc'] = np.ceil(df['gel_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gel_epc_dir'] = (df['gel_percent_r'].shift(1) >= 0.5).astype(int)\n",
        "        df['gel_epc_hp'] = (df['gel_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate E1/E2 values\n",
        "        df['gel_e1_value'] = df.apply(\n",
        "            lambda x: x['gel_reu_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_red_value'], axis=1\n",
        "        )\n",
        "\n",
        "        df['gel_e2_value'] = df.apply(\n",
        "            lambda x: x['gel_red_value'] if x['gel_epc_dir'] == 1\n",
        "            else x['gel_reu_value'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class PriorParentCalculator:\n",
        "    \"\"\"Handles calculations related to prior parent period relationships\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_prior_parent(self, df):\n",
        "        \"\"\"Calculate all prior parent related values\"\"\"\n",
        "        # Initialize parent reference values\n",
        "        df = self._initialize_parent_refs(df)\n",
        "\n",
        "        # Calculate ranges and percentages\n",
        "        df = self._calculate_parent_ranges(df)\n",
        "\n",
        "        # Calculate expansions against prior parent\n",
        "        df = self._calculate_parent_expansions(df)\n",
        "\n",
        "        # Calculate patterns and directions\n",
        "        df = self._calculate_parent_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_parent_refs(self, df):\n",
        "        \"\"\"Initialize references to parent values\"\"\"\n",
        "        df['gelp_open'] = df['parent_open']\n",
        "\n",
        "        # Running high/low against parent\n",
        "        df['gelp_high'] = df.apply(\n",
        "            lambda x: x['parent_high'] if x['trading_bop'] == 1\n",
        "            else max(x['parent_high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_low'] = df.apply(\n",
        "            lambda x: x['parent_low'] if x['trading_bop'] == 1\n",
        "            else min(x['parent_low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_close'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_ranges(self, df):\n",
        "        \"\"\"Calculate ranges and percentages against parent\"\"\"\n",
        "        df['gelp_range'] = df['gelp_high'] - df['gelp_low']\n",
        "        df['gelp_percent_r'] = (df['gelp_close'] - df['gelp_low']) / df['gelp_range']\n",
        "\n",
        "        df['gelp_ce_percent'] = df.apply(\n",
        "            lambda x: 1 - x['gelp_percent_r'] if x['gelp_percent_r'] >= 0.5\n",
        "            else x['gelp_percent_r'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_expansions(self, df):\n",
        "        \"\"\"Calculate expansions against parent values\"\"\"\n",
        "        # Calculate REU/RED against parent\n",
        "        df['gelp_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['high'] - x['gelp_high'] if x['high'] > x['gelp_high']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['low'] - x['gelp_low']) if x['low'] < x['gelp_low']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gelp_reu_flag'] = (df['gelp_reu_value'] > 0).astype(int)\n",
        "        df['gelp_red_flag'] = (df['gelp_red_value'] > 0).astype(int)\n",
        "        df['gelp_re_value'] = df['gelp_reu_value'] + df['gelp_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_patterns(self, df):\n",
        "        \"\"\"Calculate pattern indicators against parent\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gelp_epc'] = np.ceil(df['gelp_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gelp_epc_dir'] = (df['gelp_percent_r'] >= 0.5).astype(int)\n",
        "        df['gelp_epc_hp_flag'] = (df['gelp_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Calculate direction and RPC\n",
        "        df['gelp_dir'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_dir'].shift(1) if x['gelp_re_flag'] == 0\n",
        "            else 0 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == 1\n",
        "            else 1 if x['gelp_reu_flag'] == 1\n",
        "            else x['gelp_dir'].shift(1), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_rpc'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else x['gelp_rpc'].shift(1) if x['gelp_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 2 if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == x['gelp_dir'].shift(1)\n",
        "            else 1, axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class SummaryGenerator:\n",
        "    \"\"\"Generates summary statistics and analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate complete summary statistics\"\"\"\n",
        "        summary = {}\n",
        "\n",
        "        # Parent level statistics\n",
        "        summary.update(self._generate_parent_stats(parent_df))\n",
        "\n",
        "        # Child level statistics\n",
        "        summary.update(self._generate_child_stats(child_df))\n",
        "\n",
        "        # Pattern analysis\n",
        "        summary.update(self._analyze_patterns(parent_df, child_df))\n",
        "\n",
        "        # Export summary\n",
        "        self._export_summary(summary, ticker)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _generate_parent_stats(self, df):\n",
        "        \"\"\"Generate parent level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        # E1 FRE flag by EPC HP\n",
        "        e1_hp_stats = df[df['epc_hp'] == 1]['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_hp_counts'] = e1_hp_stats.to_dict()\n",
        "        stats['e1_fre_flag_hp_percentages'] = (e1_hp_stats / len(df[df['epc_hp'] == 1]) * 100).to_dict()\n",
        "\n",
        "        # Range histogram\n",
        "        stats['range_histogram'] = df['range'].describe().to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _generate_child_stats(self, df):\n",
        "        \"\"\"Generate child level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['child_e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['child_e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _analyze_patterns(self, parent_df, child_df):\n",
        "        \"\"\"Analyze patterns across parent and child data\"\"\"\n",
        "        patterns = {}\n",
        "\n",
        "        # Analyze expansion patterns\n",
        "        patterns['avg_expansion_by_period'] = child_df.groupby('trading_bop')['re_value'].mean().to_dict()\n",
        "\n",
        "        # Analyze direction persistence\n",
        "        patterns['direction_persistence'] = self._calculate_direction_persistence(child_df)\n",
        "\n",
        "        # Analyze high/low positioning\n",
        "        patterns['hl_position_stats'] = self._analyze_hl_positions(child_df)\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def _calculate_direction_persistence(self, df):\n",
        "        \"\"\"Calculate statistics about direction persistence\"\"\"\n",
        "        return {\n",
        "            'avg_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().mean(),\n",
        "            'max_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().max()\n",
        "        }\n",
        "\n",
        "    def _analyze_hl_positions(self, df):\n",
        "        \"\"\"Analyze high/low position patterns\"\"\"\n",
        "        return {\n",
        "            'early_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) & (df['trading_bop'] <= 2)]),\n",
        "            'middle_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                               (df['trading_bop'] > 2) & (df['trading_bop'] < df['parent_duration'] - 1)]),\n",
        "            'late_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                             (df['trading_bop'] >= df['parent_duration'] - 1)])\n",
        "        }\n",
        "\n",
        "    def _export_summary(self, summary, ticker):\n",
        "        \"\"\"Export summary statistics to CSV\"\"\"\n",
        "        # Convert nested dict to flat format for CSV\n",
        "        flat_summary = self._flatten_dict(summary)\n",
        "\n",
        "        # Create DataFrame and export\n",
        "        summary_df = pd.DataFrame([flat_summary])\n",
        "        summary_df.to_csv(f'output_gel_sum/{ticker}_summary.csv', index=False)\n",
        "\n",
        "    def _flatten_dict(self, d, parent_key='', sep='_'):\n",
        "        \"\"\"Flatten nested dictionary for CSV export\"\"\"\n",
        "        items = []\n",
        "        for k, v in d.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "            if isinstance(v, dict):\n",
        "                items.extend(self._flatten_dict(v, new_key, sep=sep).items())\n",
        "            else:\n",
        "                items.append((new_key, v))\n",
        "        return dict(items)"
      ],
      "metadata": {
        "id": "7VcnVjsQ4ZRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "class ProcessorBase:\n",
        "    \"\"\"Base class for all processors with common functionality\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.logger = logging.getLogger('GetSets')\n",
        "\n",
        "class GetSetsProcessor(ProcessorBase):\n",
        "    \"\"\"Main processor for Get Sets analysis\"\"\"\n",
        "\n",
        "    def __init__(self, child_period='D', parent_period='M', jobname='Gelset'):\n",
        "        super().__init__()\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.jobname = jobname\n",
        "        self.setup_logging()\n",
        "\n",
        "        # Validate period combinations\n",
        "        self._validate_periods()\n",
        "\n",
        "        # Setup paths\n",
        "        self.setup_directories()\n",
        "\n",
        "    def _validate_periods(self):\n",
        "        \"\"\"Validate period combinations\"\"\"\n",
        "        valid_combinations = {\n",
        "            ('D', 'W'), ('D', 'M'),\n",
        "            ('M', 'Q'), ('M', 'Y'),\n",
        "            ('Q', 'Y'), ('D', 'Q')\n",
        "        }\n",
        "        if (self.child_period, self.parent_period) not in valid_combinations:\n",
        "            raise ValueError(f\"Invalid period combination: {self.child_period}/{self.parent_period}\")\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Initialize logging\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(f'getsets_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger('GetSets')\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create required output directories\"\"\"\n",
        "        directories = ['output_child', 'output_parent', 'output_gel_sum']\n",
        "        for dir_name in directories:\n",
        "            Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "    def process_file(self, filepath):\n",
        "        \"\"\"Process a single input file\"\"\"\n",
        "        try:\n",
        "            # Extract file information\n",
        "            ticker, temporal_period, rolling_range = self._parse_filename(filepath)\n",
        "\n",
        "            # Load and validate input data\n",
        "            df = self._load_input_file(filepath)\n",
        "\n",
        "            # Create parent file\n",
        "            parent_df = self._create_parent_file(df)\n",
        "\n",
        "            # Process child calculations\n",
        "            child_df = self._process_child_calculations(df, parent_df)\n",
        "\n",
        "            # Update parent with child data\n",
        "            parent_df = self._update_parent_with_child_data(parent_df, child_df)\n",
        "\n",
        "            # Generate summary statistics\n",
        "            self._generate_summary(parent_df, child_df, ticker)\n",
        "\n",
        "            # Export results\n",
        "            self._export_results(parent_df, child_df, ticker)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing file {filepath}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_filename(self, filepath):\n",
        "        \"\"\"Parse input filename for ticker and metadata\"\"\"\n",
        "        filename = Path(filepath).stem\n",
        "        parts = filename.split('_')\n",
        "        if len(parts) != 3:\n",
        "            raise ValueError(f\"Invalid filename format: {filename}\")\n",
        "        return parts[0], parts[1], parts[2]\n",
        "\n",
        "    def _load_input_file(self, filepath):\n",
        "        \"\"\"Load and validate input file\"\"\"\n",
        "        # Read CSV with date parsing\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        self.logger.info(f\"Initial columns: {df.columns.tolist()}\")\n",
        "        self.logger.info(f\"Initial shape: {df.shape}\")\n",
        "\n",
        "        # Define required and optional columns\n",
        "        required_cols = ['date', 'open', 'high', 'low', 'close']\n",
        "        optional_cols = ['volume', 'fre_dir_given', 'rpc_given',\n",
        "                        'timestamp_high', 'timestamp_low', 'bar_of_h', 'bar_of_l']\n",
        "\n",
        "        # Validate required columns\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Convert date to datetime and set as index\n",
        "        try:\n",
        "            df['date'] = pd.to_datetime(df['date'])\n",
        "            self.logger.info(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "            df.sort_values('date', inplace=True)\n",
        "            df.set_index('date', inplace=True)\n",
        "            self.logger.info(f\"Successfully set datetime index: {type(df.index)}\")\n",
        "            self.logger.info(f\"First few index values: {df.index[:5]}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing date: {str(e)}\")\n",
        "            self.logger.error(f\"Date column sample: {df['date'].head()}\")\n",
        "            raise ValueError(f\"Error processing date column: {str(e)}\")\n",
        "\n",
        "        # Validate OHLC relationships\n",
        "        valid_mask = (\n",
        "            (df['low'] <= df['open']) &\n",
        "            (df['low'] <= df['close']) &\n",
        "            (df['high'] >= df['open']) &\n",
        "            (df['high'] >= df['close']) &\n",
        "            (df['high'] - df['low'] > 0)\n",
        "        )\n",
        "\n",
        "        invalid_rows = df[~valid_mask]\n",
        "        if len(invalid_rows) > 0:\n",
        "            self.logger.warning(f\"Removing {len(invalid_rows)} invalid rows\")\n",
        "            df = df[valid_mask]\n",
        "\n",
        "        self.logger.info(f\"Final shape: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    def _create_parent_file(self, df):\n",
        "        \"\"\"Create parent file from child data\"\"\"\n",
        "        parent_processor = ParentProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return parent_processor.create_parent_file(df)\n",
        "\n",
        "    def _process_child_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        child_processor = ChildProcessor(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return child_processor.process_calculations(df, parent_df)\n",
        "\n",
        "    def _update_parent_with_child_data(self, parent_df, child_df):\n",
        "        \"\"\"Update parent file with aggregated child data\"\"\"\n",
        "        updater = ParentUpdater(\n",
        "            child_period=self.child_period,\n",
        "            parent_period=self.parent_period\n",
        "        )\n",
        "        return updater.update_parent(parent_df, child_df)\n",
        "\n",
        "    def _generate_summary(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate summary statistics\"\"\"\n",
        "        summary = SummaryGenerator()\n",
        "        return summary.generate(parent_df, child_df, ticker)\n",
        "\n",
        "    def _export_results(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Export results to CSV files\"\"\"\n",
        "        # Export child file\n",
        "        child_path = f'output_child/{ticker}_child_{self.child_period}.csv'\n",
        "        child_df.to_csv(child_path, index=False)\n",
        "\n",
        "        # Export parent file\n",
        "        parent_path = f'output_parent/{ticker}_parent_{self.parent_period}.csv'\n",
        "        parent_df.to_csv(parent_path, index=False)\n",
        "\n",
        "        self.logger.info(f\"Results exported: {child_path}, {parent_path}\")\n",
        "\n",
        "\n",
        "class ParentProcessor(ProcessorBase):\n",
        "    \"\"\"Handles creation and processing of parent file\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        super().__init__()\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def create_parent_file(self, df):\n",
        "        \"\"\"Create parent file by aggregating child data\"\"\"\n",
        "        # Group by parent period\n",
        "        grouped = self._group_by_parent_period(df)\n",
        "\n",
        "        # Define base OHLC aggregation\n",
        "        agg_dict = {\n",
        "            'open': 'first',\n",
        "            'high': 'max',\n",
        "            'low': 'min',\n",
        "            'close': 'last'\n",
        "        }\n",
        "\n",
        "        # Add volume if it exists\n",
        "        if 'volume' in df.columns:\n",
        "            agg_dict['volume'] = 'sum'\n",
        "\n",
        "        # Aggregate using available columns\n",
        "        parent_df = grouped.agg(agg_dict).reset_index()\n",
        "\n",
        "        # Add reference fields\n",
        "        parent_df = self._add_reference_fields(parent_df)\n",
        "\n",
        "        # Calculate basic indicators\n",
        "        parent_df = self._calculate_basic_indicators(parent_df)\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "    def _group_by_parent_period(self, df):\n",
        "        \"\"\"Group data by parent period\"\"\"\n",
        "        self.logger.info(f\"Grouping by {self.parent_period}, index type: {type(df.index)}\")\n",
        "\n",
        "        try:\n",
        "            if self.parent_period == 'W':\n",
        "                return df.groupby(pd.Grouper(freq='W-FRI'))\n",
        "            elif self.parent_period == 'M':\n",
        "                return df.groupby(pd.Grouper(freq='ME'))\n",
        "            elif self.parent_period == 'Q':\n",
        "                return df.groupby(pd.Grouper(freq='Q-DEC'))\n",
        "            elif self.parent_period == 'Y':\n",
        "                return df.groupby(pd.Grouper(freq='Y'))\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid parent period: {self.parent_period}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in grouping: {str(e)}\")\n",
        "            self.logger.error(f\"DataFrame info: {df.info()}\")\n",
        "            raise\n",
        "\n",
        "    def _add_reference_fields(self, df):\n",
        "        \"\"\"Add reference fields to parent dataframe\"\"\"\n",
        "        df['serial_id'] = self._generate_serial_ids(df)\n",
        "        df['model_type'] = 1  # bar/prior bar\n",
        "        df['child_period'] = self.child_period\n",
        "        df['parent_period'] = self.parent_period\n",
        "        df['create_date'] = datetime.now().strftime('%Y-%m-%d')\n",
        "        df['create_time'] = datetime.now().strftime('%H:%M:%S')\n",
        "        return df\n",
        "\n",
        "    def _generate_serial_ids(self, df):\n",
        "        \"\"\"Generate unique 13-digit serial IDs\"\"\"\n",
        "        base = int(datetime.now().strftime('%Y%m%d%H%M'))\n",
        "        return [f\"{base}{i:03d}\" for i in range(len(df))]\n",
        "\n",
        "    def _calculate_basic_indicators(self, df):\n",
        "        \"\"\"Calculate basic technical indicators\"\"\"\n",
        "        # Calculate range\n",
        "        df['range'] = df['high'] - df['low']\n",
        "\n",
        "        # Calculate percent_r\n",
        "        df['percent_r'] = (df['close'] - df['low']) / df['range']\n",
        "\n",
        "        # Add prior bar references\n",
        "        df['ro'] = df['open'].shift(1)\n",
        "        df['rh'] = df['high'].shift(1)\n",
        "        df['rl'] = df['low'].shift(1)\n",
        "        df['rc'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class ChildProcessor(ProcessorBase):\n",
        "    \"\"\"Handles child calculations including bar/prior bar and gel calculations\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        super().__init__()\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "        self.gel_calculator = GelCalculator()\n",
        "        self.prior_parent_calculator = PriorParentCalculator()\n",
        "\n",
        "    def process_calculations(self, df, parent_df):\n",
        "        \"\"\"Process all child calculations\"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Starting child calculations\")\n",
        "\n",
        "            # Add trading_bop\n",
        "            df = self._add_trading_bop(df)\n",
        "            self.logger.info(\"Added trading_bop\")\n",
        "\n",
        "            # Calculate bar/prior bar\n",
        "            df = self._calculate_bar_prior_bar(df)\n",
        "            self.logger.info(\"Calculated bar/prior bar\")\n",
        "\n",
        "            # Calculate gel values\n",
        "            df = self.gel_calculator.calculate_gel_values(df)\n",
        "            self.logger.info(\"Calculated gel values\")\n",
        "\n",
        "            # Map parent data\n",
        "            df = self._map_parent_data(df, parent_df)\n",
        "            self.logger.info(\"Mapped parent data\")\n",
        "\n",
        "            # Calculate prior parent values\n",
        "            df = self.prior_parent_calculator.calculate_prior_parent(df)\n",
        "            self.logger.info(\"Calculated prior parent values\")\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in process_calculations: {str(e)}\")\n",
        "            self.logger.error(f\"DataFrame info: {df.info()}\")\n",
        "            raise\n",
        "\n",
        "    def _add_trading_bop(self, df):\n",
        "        \"\"\"Add trading bar of parent field\"\"\"\n",
        "        try:\n",
        "            # Get appropriate frequency for parent period\n",
        "            if self.parent_period == 'W':\n",
        "                freq = 'W-FRI'\n",
        "            elif self.parent_period == 'M':\n",
        "                freq = 'ME'\n",
        "            elif self.parent_period == 'Q':\n",
        "                freq = 'Q-DEC'\n",
        "            elif self.parent_period == 'Y':\n",
        "                freq = 'Y'\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid parent period: {self.parent_period}\")\n",
        "\n",
        "            # Calculate trading_bop\n",
        "            df['trading_bop'] = df.groupby(pd.Grouper(freq=freq)).cumcount() + 1\n",
        "\n",
        "            self.logger.info(f\"Trading_bop range: {df['trading_bop'].min()} to {df['trading_bop'].max()}\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in _add_trading_bop: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_bar_prior_bar(self, df):\n",
        "        \"\"\"Calculate bar/prior bar values\"\"\"\n",
        "        try:\n",
        "            # REU/RED calculations\n",
        "            high_diff = df['high'].diff().fillna(0.0)\n",
        "            low_diff = df['low'].diff().fillna(0.0)\n",
        "\n",
        "            # REU calculations\n",
        "            df['reu_value'] = np.where(high_diff > 0, high_diff, 0).astype(float)\n",
        "            df['reu_flag'] = (df['reu_value'] > 0).astype(int)\n",
        "\n",
        "            # RED calculations\n",
        "            df['red_value'] = np.where(low_diff < 0, abs(low_diff), 0).astype(float)\n",
        "            df['red_flag'] = (df['red_value'] > 0).astype(int)\n",
        "\n",
        "            # Combined calculations\n",
        "            df['re_value'] = df['reu_value'] + df['red_value']\n",
        "            df['re_flag'] = ((df['reu_flag'] == 1) | (df['red_flag'] == 1)).astype(int)\n",
        "\n",
        "            self.logger.info(\"Bar/prior bar calculations completed\")\n",
        "            self.logger.info(f\"REU flags: {df['reu_flag'].sum()}, RED flags: {df['red_flag'].sum()}\")\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in _calculate_bar_prior_bar: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _map_parent_data(self, df, parent_df):\n",
        "        \"\"\"Map parent data to child DataFrame\"\"\"\n",
        "        try:\n",
        "            # Create parent lookup date based on child date\n",
        "            parent_df = parent_df.copy()\n",
        "            df = df.copy()\n",
        "\n",
        "            # Add parent OHLC data\n",
        "            df['parent_open'] = self._lookup_parent_data(df, parent_df, 'open')\n",
        "            df['parent_high'] = self._lookup_parent_data(df, parent_df, 'high')\n",
        "            df['parent_low'] = self._lookup_parent_data(df, parent_df, 'low')\n",
        "            df['parent_close'] = self._lookup_parent_data(df, parent_df, 'close')\n",
        "\n",
        "            # Calculate parent derived fields\n",
        "            df['parent_range'] = df['parent_high'] - df['parent_low']\n",
        "            df['parent_percent_r'] = (df['parent_close'] - df['parent_low']) / df['parent_range']\n",
        "\n",
        "            # Calculate parent ce_percent\n",
        "            shifted_percent_r = df['parent_percent_r'].shift(1)\n",
        "            df['parent_ce_percent'] = np.where(\n",
        "                shifted_percent_r >= 0.5,\n",
        "                1 - shifted_percent_r,\n",
        "                shifted_percent_r\n",
        "            )\n",
        "\n",
        "            # Calculate parent EPC fields\n",
        "            df['parent_epc'] = np.ceil(df['parent_ce_percent'] / 0.1).clip(1, 5)\n",
        "            df['parent_epc_dir'] = (df['parent_percent_r'].shift(1) >= 0.5).astype(int)\n",
        "            df['parent_epc_hp'] = (df['parent_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "            self.logger.info(\"Parent data mapping completed\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error mapping parent data: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _lookup_parent_data(self, child_df, parent_df, column):\n",
        "        \"\"\"Look up parent data for each child row\"\"\"\n",
        "        try:\n",
        "            # Get appropriate frequency for parent period\n",
        "            if self.parent_period == 'W':\n",
        "                freq = 'W-FRI'\n",
        "            elif self.parent_period == 'M':\n",
        "                freq = 'ME'\n",
        "            elif self.parent_period == 'Q':\n",
        "                freq = 'Q-DEC'\n",
        "            elif self.parent_period == 'Y':\n",
        "                freq = 'Y'\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid parent period: {self.parent_period}\")\n",
        "\n",
        "            # Create parent period index\n",
        "            parent_dates = pd.date_range(\n",
        "                start=child_df.index.min(),\n",
        "                end=child_df.index.max(),\n",
        "                freq=freq\n",
        "            )\n",
        "\n",
        "            # Create lookup series\n",
        "            lookup = pd.Series(index=parent_dates, data=parent_df[column].values)\n",
        "\n",
        "            # Forward fill to align with child dates\n",
        "            return lookup.reindex(child_df.index, method='ffill')\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error looking up parent data for column {column}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _validate_results(self, df):\n",
        "        \"\"\"Validate calculation results\"\"\"\n",
        "        try:\n",
        "            # Check for missing values\n",
        "            missing_vals = df.isnull().sum()\n",
        "            if missing_vals.any():\n",
        "                self.logger.warning(f\"Missing values found:\\n{missing_vals[missing_vals > 0]}\")\n",
        "\n",
        "            # Validate numeric ranges\n",
        "            if (df['reu_value'] < 0).any() or (df['red_value'] < 0).any():\n",
        "                raise ValueError(\"Found negative REU/RED values\")\n",
        "\n",
        "            # Validate flags\n",
        "            flag_cols = [col for col in df.columns if col.endswith('_flag')]\n",
        "            for col in flag_cols:\n",
        "                if not df[col].isin([0, 1, np.nan]).all():\n",
        "                    raise ValueError(f\"Invalid flag values in {col}\")\n",
        "\n",
        "            # Validate trading_bop sequence\n",
        "            bop_gaps = df.groupby(pd.Grouper(freq=self._get_parent_freq()))['trading_bop'].apply(\n",
        "                lambda x: not x.reset_index(drop=True).equals(pd.Series(range(1, len(x) + 1)))\n",
        "            )\n",
        "            if bop_gaps.any():\n",
        "                self.logger.warning(\"Found gaps in trading_bop sequence\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Validation error: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _get_parent_freq(self):\n",
        "        \"\"\"Get pandas frequency string for parent period\"\"\"\n",
        "        freq_map = {\n",
        "            'W': 'W-FRI',\n",
        "            'M': 'ME',\n",
        "            'Q': 'Q-DEC',\n",
        "            'Y': 'Y'\n",
        "        }\n",
        "        return freq_map.get(self.parent_period, 'ME')\n",
        "\n",
        "\n",
        "class GelCalculator(ProcessorBase):\n",
        "    \"\"\"Handles Gel calculations including expansions and pattern recognition\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def calculate_gel_values(self, df):\n",
        "        \"\"\"Calculate all gel-related values\"\"\"\n",
        "        try:\n",
        "            # Initialize gel OHLC\n",
        "            df = self._initialize_gel_ohlc(df)\n",
        "\n",
        "            # Calculate gel ranges and percentages\n",
        "            df = self._calculate_gel_ranges(df)\n",
        "\n",
        "            # Calculate gel expansions\n",
        "            df = self._calculate_gel_expansions(df)\n",
        "\n",
        "            # Calculate gel patterns\n",
        "            df = self._calculate_gel_patterns(df)\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in calculate_gel_values: {str(e)}\")\n",
        "            self.logger.error(f\"DataFrame info: {df.info()}\")\n",
        "            raise\n",
        "\n",
        "    def _initialize_gel_ohlc(self, df):\n",
        "        \"\"\"Initialize gel OHLC values\"\"\"\n",
        "        try:\n",
        "            # Initialize gel_open\n",
        "            df['gel_open'] = df['open'].copy()\n",
        "            mask = (df['trading_bop'] != 1)\n",
        "            df.loc[mask, 'gel_open'] = df['gel_open'].shift(1)\n",
        "\n",
        "            # Initialize gel_high with high values\n",
        "            df['gel_high'] = df['high'].copy()\n",
        "            df.loc[mask, 'gel_high'] = df.groupby(pd.Grouper(freq='ME'))['high'].transform('cummax')\n",
        "\n",
        "            # Initialize gel_low with low values\n",
        "            df['gel_low'] = df['low'].copy()\n",
        "            df.loc[mask, 'gel_low'] = df.groupby(pd.Grouper(freq='ME'))['low'].transform('cummin')\n",
        "\n",
        "            # Initialize gel_close\n",
        "            df['gel_close'] = df['close']\n",
        "\n",
        "            self.logger.info(\"Gel OHLC initialization completed\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in initialize_gel_ohlc: {str(e)}\")\n",
        "            self.logger.error(f\"DataFrame columns: {df.columns.tolist()}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_gel_ranges(self, df):\n",
        "        \"\"\"Calculate gel ranges and percentages\"\"\"\n",
        "        try:\n",
        "            df['gel_range'] = df['gel_high'] - df['gel_low']\n",
        "            df['gel_percent_r'] = (df['gel_close'] - df['gel_low']) / df['gel_range']\n",
        "\n",
        "            # Calculate gel ce_percent\n",
        "            mask = (df['trading_bop'] != 1)\n",
        "            shifted_percent_r = df['gel_percent_r'].shift(1)\n",
        "            df['gel_ce_percent'] = np.nan\n",
        "            df.loc[mask & (shifted_percent_r >= 0.5), 'gel_ce_percent'] = 1 - shifted_percent_r[mask & (shifted_percent_r >= 0.5)]\n",
        "            df.loc[mask & (shifted_percent_r < 0.5), 'gel_ce_percent'] = shifted_percent_r[mask & (shifted_percent_r < 0.5)]\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in calculate_gel_ranges: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_gel_expansions(self, df):\n",
        "        \"\"\"Calculate gel expansion values\"\"\"\n",
        "        try:\n",
        "            # Initialize columns with zeros\n",
        "            df['gel_reu_value'] = 0.0\n",
        "            df['gel_red_value'] = 0.0\n",
        "\n",
        "            mask = (df['trading_bop'] != 1)\n",
        "\n",
        "            # Calculate differences\n",
        "            high_diff = df['gel_high'].diff().fillna(0.0)\n",
        "            low_diff = df['gel_low'].diff().fillna(0.0)\n",
        "\n",
        "            # Update values using numpy where conditions\n",
        "            df.loc[mask & (high_diff > 0), 'gel_reu_value'] = high_diff[mask & (high_diff > 0)].astype(float)\n",
        "            df.loc[mask & (low_diff < 0), 'gel_red_value'] = abs(low_diff[mask & (low_diff < 0)]).astype(float)\n",
        "\n",
        "            # Set expansion flags\n",
        "            df['gel_reu_flag'] = (df['gel_reu_value'] > 0).astype(int)\n",
        "            df['gel_red_flag'] = (df['gel_red_value'] > 0).astype(int)\n",
        "            df['gel_re_value'] = df['gel_reu_value'] + df['gel_red_value']\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in calculate_gel_expansions: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_gel_patterns(self, df):\n",
        "        \"\"\"Calculate gel pattern indicators\"\"\"\n",
        "        try:\n",
        "            # Calculate EPC and related fields\n",
        "            df['gel_epc'] = np.ceil(df['gel_ce_percent'] / 0.1).clip(1, 5)\n",
        "            df['gel_epc_dir'] = (df['gel_percent_r'].shift(1) >= 0.5).astype(int)\n",
        "            df['gel_epc_hp'] = (df['gel_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "            # Calculate E1/E2 values\n",
        "            df['gel_e1_value'] = np.where(df['gel_epc_dir'] == 1,\n",
        "                                      df['gel_reu_value'],\n",
        "                                      df['gel_red_value'])\n",
        "\n",
        "            df['gel_e2_value'] = np.where(df['gel_epc_dir'] == 1,\n",
        "                                      df['gel_red_value'],\n",
        "                                      df['gel_reu_value'])\n",
        "\n",
        "            # Calculate flags\n",
        "            df['gel_e1_flag'] = (df['gel_e1_value'] > 0).astype(int)\n",
        "            df['gel_e2_flag'] = (df['gel_e2_value'] > 0).astype(int)\n",
        "            df['gel_e1_fre_flag'] = df['e1_fre_flag']  # Map from input\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in calculate_gel_patterns: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _initialize_gel_ohlc(self, df):\n",
        "        \"\"\"Initialize gel OHLC values\"\"\"\n",
        "        try:\n",
        "            # Initialize gel_open\n",
        "            df['gel_open'] = df['open'].copy()\n",
        "            mask = (df['trading_bop'] != 1)\n",
        "            df.loc[mask, 'gel_open'] = df['gel_open'].shift(1)\n",
        "\n",
        "            # Initialize gel_high with high values\n",
        "            df['gel_high'] = df['high'].copy()\n",
        "            df.loc[mask, 'gel_high'] = np.maximum(df['high'], df['gel_high'].shift(1))\n",
        "\n",
        "            # Initialize gel_low with low values\n",
        "            df['gel_low'] = df['low'].copy()\n",
        "            df.loc[mask, 'gel_low'] = np.minimum(df['low'], df['gel_low'].shift(1))\n",
        "\n",
        "            # Initialize gel_close\n",
        "            df['gel_close'] = df['close']\n",
        "\n",
        "            self.logger.info(\"Gel OHLC initialization completed\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in initialize_gel_ohlc: {str(e)}\")\n",
        "            self.logger.error(f\"DataFrame columns: {df.columns.tolist()}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_gel_ranges(self, df):\n",
        "        \"\"\"Calculate gel ranges and percentages\"\"\"\n",
        "        try:\n",
        "            df['gel_range'] = df['gel_high'] - df['gel_low']\n",
        "            df['gel_percent_r'] = (df['gel_close'] - df['gel_low']) / df['gel_range']\n",
        "\n",
        "            # Calculate gel ce_percent\n",
        "            mask = (df['trading_bop'] != 1)\n",
        "            shifted_percent_r = df['gel_percent_r'].shift(1)\n",
        "            df['gel_ce_percent'] = np.nan\n",
        "            df.loc[mask & (shifted_percent_r >= 0.5), 'gel_ce_percent'] = 1 - shifted_percent_r\n",
        "            df.loc[mask & (shifted_percent_r < 0.5), 'gel_ce_percent'] = shifted_percent_r\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in calculate_gel_ranges: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_gel_expansions(self, df):\n",
        "        \"\"\"Calculate gel expansion values\"\"\"\n",
        "        try:\n",
        "            # Calculate REU/RED for gel\n",
        "            mask = (df['trading_bop'] != 1)\n",
        "\n",
        "            # Initialize with zeros\n",
        "            df['gel_reu_value'] = 0\n",
        "            df['gel_red_value'] = 0\n",
        "\n",
        "            # Calculate expansions where needed\n",
        "            high_diff = df['gel_high'] - df['gel_high'].shift(1)\n",
        "            low_diff = df['gel_low'] - df['gel_low'].shift(1)\n",
        "\n",
        "            df.loc[mask & (high_diff > 0), 'gel_reu_value'] = high_diff\n",
        "            df.loc[mask & (low_diff < 0), 'gel_red_value'] = abs(low_diff)\n",
        "\n",
        "            # Set expansion flags\n",
        "            df['gel_reu_flag'] = (df['gel_reu_value'] > 0).astype(int)\n",
        "            df['gel_red_flag'] = (df['gel_red_value'] > 0).astype(int)\n",
        "            df['gel_re_value'] = df['gel_reu_value'] + df['gel_red_value']\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in calculate_gel_expansions: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_gel_patterns(self, df):\n",
        "        \"\"\"Calculate gel pattern indicators\"\"\"\n",
        "        try:\n",
        "            # Calculate EPC and related fields\n",
        "            df['gel_epc'] = np.ceil(df['gel_ce_percent'] / 0.1).clip(1, 5)\n",
        "            df['gel_epc_dir'] = (df['gel_percent_r'].shift(1) >= 0.5).astype(int)\n",
        "            df['gel_epc_hp'] = (df['gel_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "            # Calculate E1/E2 values\n",
        "            df['gel_e1_value'] = np.where(df['gel_epc_dir'] == 1,\n",
        "                                        df['gel_reu_value'],\n",
        "                                        df['gel_red_value'])\n",
        "\n",
        "            df['gel_e2_value'] = np.where(df['gel_epc_dir'] == 1,\n",
        "                                        df['gel_red_value'],\n",
        "                                        df['gel_reu_value'])\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in calculate_gel_patterns: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class PriorParentCalculator:\n",
        "    \"\"\"Handles calculations related to prior parent period relationships\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calculate_prior_parent(self, df):\n",
        "        \"\"\"Calculate all prior parent related values\"\"\"\n",
        "        # Initialize parent reference values\n",
        "        df = self._initialize_parent_refs(df)\n",
        "\n",
        "        # Calculate ranges and percentages\n",
        "        df = self._calculate_parent_ranges(df)\n",
        "\n",
        "        # Calculate expansions against prior parent\n",
        "        df = self._calculate_parent_expansions(df)\n",
        "\n",
        "        # Calculate patterns and directions\n",
        "        df = self._calculate_parent_patterns(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _initialize_parent_refs(self, df):\n",
        "        \"\"\"Initialize references to parent values\"\"\"\n",
        "        df['gelp_open'] = df['parent_open']\n",
        "\n",
        "        # Running high/low against parent\n",
        "        df['gelp_high'] = df.apply(\n",
        "            lambda x: x['parent_high'] if x['trading_bop'] == 1\n",
        "            else max(x['parent_high'], x['gel_high'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_low'] = df.apply(\n",
        "            lambda x: x['parent_low'] if x['trading_bop'] == 1\n",
        "            else min(x['parent_low'], x['gel_low'].shift(1)), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_close'] = df['close'].shift(1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_ranges(self, df):\n",
        "        \"\"\"Calculate ranges and percentages against parent\"\"\"\n",
        "        df['gelp_range'] = df['gelp_high'] - df['gelp_low']\n",
        "        df['gelp_percent_r'] = (df['gelp_close'] - df['gelp_low']) / df['gelp_range']\n",
        "\n",
        "        df['gelp_ce_percent'] = df.apply(\n",
        "            lambda x: 1 - x['gelp_percent_r'] if x['gelp_percent_r'] >= 0.5\n",
        "            else x['gelp_percent_r'], axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_expansions(self, df):\n",
        "        \"\"\"Calculate expansions against parent values\"\"\"\n",
        "        # Calculate REU/RED against parent\n",
        "        df['gelp_reu_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else x['high'] - x['gelp_high'] if x['high'] > x['gelp_high']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_red_value'] = df.apply(\n",
        "            lambda x: np.nan if x['trading_bop'] == 1\n",
        "            else abs(x['low'] - x['gelp_low']) if x['low'] < x['gelp_low']\n",
        "            else 0, axis=1\n",
        "        )\n",
        "\n",
        "        # Set expansion flags\n",
        "        df['gelp_reu_flag'] = (df['gelp_reu_value'] > 0).astype(int)\n",
        "        df['gelp_red_flag'] = (df['gelp_red_value'] > 0).astype(int)\n",
        "        df['gelp_re_value'] = df['gelp_reu_value'] + df['gelp_red_value']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_patterns(self, df):\n",
        "        \"\"\"Calculate pattern indicators against parent\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gelp_epc'] = np.ceil(df['gelp_ce_percent'] / 0.1).clip(1, 5).fillna(0).astype(int)\n",
        "        df['gelp_epc_dir'] = (df['gelp_percent_r'] >= 0.5).astype(int).fillna(0).astype(int)\n",
        "        df['gelp_epc_hp_flag'] = (df['gelp_ce_percent'] < 0.25).astype(int).fillna(0).astype(int)\n",
        "\n",
        "        # Initialize 'gelp_rpc' as string type\n",
        "        df['gelp_rpc'] = ''\n",
        "\n",
        "        # Ensure 'gelp_dir' is string before shifting\n",
        "        df['gelp_dir'] = df['gelp_dir'].astype(str)\n",
        "\n",
        "        # Calculate direction and RPC\n",
        "        df['gelp_dir'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name]) if x['gelp_re_flag'] == 0\n",
        "            else \"0\" if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == 1\n",
        "            else \"1\" if x['gelp_reu_flag'] == 1\n",
        "            else str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name]), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_rpc'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else str(df['gelp_rpc'].shift(1).fillna(\"\").loc[x.name]) if str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name]) == str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name])\n",
        "            else \"2\" if x['gelp_twoway'] == 1 and str(df['gelp_fre_dir'].fillna(\"\").loc[x.name]) == str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name])\n",
        "            else \"1\", axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _calculate_parent_patterns(self, df):\n",
        "        \"\"\"Calculate pattern indicators against parent\"\"\"\n",
        "        # Calculate EPC and related fields\n",
        "        df['gelp_epc'] = np.ceil(df['gelp_ce_percent'] / 0.1).clip(1, 5)\n",
        "        df['gelp_epc_dir'] = (df['gelp_percent_r'] >= 0.5).astype(int)\n",
        "        df['gelp_epc_hp_flag'] = (df['gelp_ce_percent'] < 0.25).astype(int)\n",
        "\n",
        "        # Initialize 'gelp_rpc' as string type\n",
        "        df['gelp_rpc'] = ''\n",
        "\n",
        "        # Ensure 'gelp_dir' is string before shifting\n",
        "        df['gelp_dir'] = df['gelp_dir'].astype(str)\n",
        "\n",
        "        # Calculate direction and RPC\n",
        "        df['gelp_dir'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name]) if x['gelp_re_flag'] == 0\n",
        "            else \"0\" if x['gelp_twoway'] == 1 and x['gelp_fre_dir'] == 1\n",
        "            else \"1\" if x['gelp_reu_flag'] == 1\n",
        "            else str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name]), axis=1\n",
        "        )\n",
        "\n",
        "        df['gelp_rpc'] = df.apply(\n",
        "            lambda x: \"\" if x['trading_bop'] == 1\n",
        "            else str(df['gelp_rpc'].shift(1).fillna(\"\").loc[x.name]) if str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name]) == str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name])\n",
        "            else \"2\" if x['gelp_twoway'] == 1 and str(df['gelp_fre_dir'].fillna(\"\").loc[x.name]) == str(df['gelp_dir'].shift(1).fillna(\"\").loc[x.name])\n",
        "            else \"1\", axis=1\n",
        "        )\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "class ParentUpdater(ProcessorBase):\n",
        "    \"\"\"Updates parent file with aggregated child data\"\"\"\n",
        "\n",
        "    def __init__(self, child_period, parent_period):\n",
        "        super().__init__()\n",
        "        self.child_period = child_period\n",
        "        self.parent_period = parent_period\n",
        "\n",
        "    def update_parent(self, parent_df, child_df):\n",
        "        \"\"\"Update parent with aggregated child data\"\"\"\n",
        "        # Calculate intrabar counts\n",
        "        intrabar_counts = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).agg({\n",
        "            'reu_flag': 'sum',\n",
        "            'red_flag': 'sum',\n",
        "            'rpc': 'sum'\n",
        "        }).rename(columns={\n",
        "            'reu_flag': 'intrabar_reu_count',\n",
        "            'red_flag': 'intrabar_red_count',\n",
        "            'rpc': 'intrabar_rpc'\n",
        "        })\n",
        "\n",
        "        # Calculate priorbar counts\n",
        "        priorbar_counts = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).agg({\n",
        "            'gelp_reu_flag': 'sum',\n",
        "            'gelp_red_flag': 'sum',\n",
        "            'gelp_red_flag': 'sum'  # Using red_flag for rpc as per spec\n",
        "        }).rename(columns={\n",
        "            'gelp_reu_flag': 'priorbar_reu_count',\n",
        "            'gelp_red_flag': 'priorbar_red_count',\n",
        "            'gelp_red_flag': 'priorbar_rpc'\n",
        "        })\n",
        "\n",
        "        # Find first/last RE positions\n",
        "        def get_positions(group):\n",
        "            re_bars = group[group['gelp_re_flag'] == 1]['trading_bop']\n",
        "            return pd.Series({\n",
        "                'priorbar_first_re': re_bars.iloc[0] if len(re_bars) > 0 else None,\n",
        "                'priorbar_last_re': re_bars.iloc[-1] if len(re_bars) > 0 else None\n",
        "            })\n",
        "\n",
        "        positions = child_df.groupby(pd.Grouper(key='date', freq=self.parent_period)).apply(get_positions)\n",
        "\n",
        "        # Merge all updates into parent\n",
        "        parent_df = parent_df.join(intrabar_counts, how='left')\n",
        "        parent_df = parent_df.join(priorbar_counts, how='left')\n",
        "        parent_df = parent_df.join(positions, how='left')\n",
        "\n",
        "        return parent_df\n",
        "\n",
        "class SummaryGenerator(ProcessorBase):\n",
        "    \"\"\"Generates summary statistics and analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def generate(self, parent_df, child_df, ticker):\n",
        "        \"\"\"Generate complete summary statistics\"\"\"\n",
        "        summary = {}\n",
        "\n",
        "        # Parent level statistics\n",
        "        summary.update(self._generate_parent_stats(parent_df))\n",
        "\n",
        "        # Child level statistics\n",
        "        summary.update(self._generate_child_stats(child_df))\n",
        "\n",
        "        # Pattern analysis\n",
        "        summary.update(self._analyze_patterns(parent_df, child_df))\n",
        "\n",
        "        # Export summary\n",
        "        self._export_summary(summary, ticker)\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _generate_parent_stats(self, df):\n",
        "        \"\"\"Generate parent level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        # E1 FRE flag by EPC HP\n",
        "        e1_hp_stats = df[df['epc_hp'] == 1]['e1_fre_flag'].value_counts()\n",
        "        stats['e1_fre_flag_hp_counts'] = e1_hp_stats.to_dict()\n",
        "        stats['e1_fre_flag_hp_percentages'] = (e1_hp_stats / len(df[df['epc_hp'] == 1]) * 100).to_dict()\n",
        "\n",
        "        # Range histogram\n",
        "        stats['range_histogram'] = df['range'].describe().to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _generate_child_stats(self, df):\n",
        "        \"\"\"Generate child level statistics\"\"\"\n",
        "        stats = {}\n",
        "\n",
        "        # E1 FRE flag analysis\n",
        "        e1_stats = df['e1_fre_flag'].value_counts()\n",
        "        stats['child_e1_fre_flag_counts'] = e1_stats.to_dict()\n",
        "        stats['child_e1_fre_flag_percentages'] = (e1_stats / len(df) * 100).to_dict()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _analyze_patterns(self, parent_df, child_df):\n",
        "        \"\"\"Analyze patterns across parent and child data\"\"\"\n",
        "        patterns = {}\n",
        "\n",
        "        # Analyze expansion patterns\n",
        "        patterns['avg_expansion_by_period'] = child_df.groupby('trading_bop')['re_value'].mean().to_dict()\n",
        "\n",
        "        # Analyze direction persistence\n",
        "        patterns['direction_persistence'] = self._calculate_direction_persistence(child_df)\n",
        "\n",
        "        # Analyze high/low positioning\n",
        "        patterns['hl_position_stats'] = self._analyze_hl_positions(child_df)\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def _calculate_direction_persistence(self, df):\n",
        "        \"\"\"Calculate statistics about direction persistence\"\"\"\n",
        "        return {\n",
        "            'avg_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().mean(),\n",
        "            'max_streak_length': df.groupby((df['gelp_dir'] != df['gelp_dir'].shift(1)).cumsum())['gelp_dir'].count().max()\n",
        "        }\n",
        "\n",
        "    def _analyze_hl_positions(self, df):\n",
        "        \"\"\"Analyze high/low position patterns\"\"\"\n",
        "        return {\n",
        "            'early_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) & (df['trading_bop'] <= 2)]),\n",
        "            'middle_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                               (df['trading_bop'] > 2) & (df['trading_bop'] < df['parent_duration'] - 1)]),\n",
        "            'late_hl': len(df[(df['bar_of_h'].notna() | df['bar_of_l'].notna()) &\n",
        "                             (df['trading_bop'] >= df['parent_duration'] - 1)])\n",
        "        }\n",
        "\n",
        "    def _export_summary(self, summary, ticker):\n",
        "        \"\"\"Export summary statistics to CSV\"\"\"\n",
        "        # Convert nested dict to flat format for CSV\n",
        "        flat_summary = self._flatten_dict(summary)\n",
        "\n",
        "        # Create DataFrame and export\n",
        "        summary_df = pd.DataFrame([flat_summary])\n",
        "        summary_df.to_csv(f'output_gel_sum/{ticker}_summary.csv', index=False)\n",
        "\n",
        "    def _flatten_dict(self, d, parent_key='', sep='_'):\n",
        "        \"\"\"Flatten nested dictionary for CSV export\"\"\"\n",
        "        items = []\n",
        "        for k, v in d.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "            if isinstance(v, dict):\n",
        "                items.extend(self._flatten_dict(v, new_key, sep=sep).items())\n",
        "            else:\n",
        "                items.append((new_key, v))\n",
        "        return dict(items)\n",
        "\n",
        "def main():\n",
        "    # Initialize processor\n",
        "    processor = GetSetsProcessor(child_period='D', parent_period='M')\n",
        "\n",
        "    # Process all files in input directory\n",
        "    input_dir = Path('/content/input')\n",
        "\n",
        "    if not input_dir.exists():\n",
        "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
        "\n",
        "    # Process each CSV file\n",
        "    for file_path in input_dir.glob('*.csv'):\n",
        "        try:\n",
        "            print(f\"\\nProcessing file: {file_path}\")\n",
        "            processor.process_file(file_path)\n",
        "            print(f\"Successfully processed: {file_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {str(e)}\")\n",
        "            logging.error(f\"Error processing {file_path}: {str(e)}\", exc_info=True)\n",
        "\n",
        "# Run the processor\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgEes75P4h4Z",
        "outputId": "c6118269-aa69-4edc-8d13-2f8e829fa5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-3de07a088b74>:671: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.19998930e-01 3.95000460e-01 1.25000000e-01 8.17499160e-01\n",
            " 1.74999200e-02 1.77499770e-01 3.24993100e-02 1.22501380e-01\n",
            " 1.02499010e-01 5.32499310e-01 3.40000150e-01 1.70000080e-01\n",
            " 6.50005300e-02 3.14998630e-01 5.25016800e-02 3.00006900e-02\n",
            " 2.04999920e-01 5.10000230e-01 1.19998940e-01 1.00002200e-02\n",
            " 1.57501230e-01 5.67499160e-01 2.82499310e-01 4.00009200e-02\n",
            " 7.49969000e-03 2.87500380e-01 3.85000230e-01 6.57499310e-01\n",
            " 5.47500610e-01 4.75006100e-02 4.32498930e-01 1.25007700e-02\n",
            " 4.14999010e-01 4.00009100e-02 4.02500160e-01 7.74993900e-02\n",
            " 1.27500530e-01 5.50003100e-02 4.40000530e-01 2.24998470e-01\n",
            " 4.12500390e-01 2.47501370e-01 9.05000690e-01 2.99987800e-02\n",
            " 7.99999300e-02 2.22499840e-01 3.04998400e-01 2.09999080e-01\n",
            " 9.74998500e-02 1.90000530e-01 1.24988600e-02 3.22500230e-01\n",
            " 7.75012900e-02 2.07498550e-01 8.25004600e-02 1.35000230e-01\n",
            " 1.37750054e+00 2.49996200e-02 2.50015200e-02 4.12500380e-01\n",
            " 1.80000310e-01 1.42499920e-01 1.52500150e-01 1.72500610e-01\n",
            " 2.25009900e-02 2.99999240e-01 7.50007600e-02 1.14999770e-01\n",
            " 7.67499920e-01 1.05999946e+00 6.75001150e-01 9.99984700e-02\n",
            " 1.25007700e-02 2.04999920e-01 3.12500000e-01 3.14998630e-01\n",
            " 7.49969000e-03 5.50003100e-02 5.47500610e-01 4.85000610e-01\n",
            " 4.74987000e-02 1.00002300e-02 9.00001600e-02 1.55000680e-01\n",
            " 3.02499780e-01 6.05001450e-01 2.99987800e-02 4.75006100e-02\n",
            " 3.62499240e-01 1.07500070e-01 1.49999620e-01 6.75010700e-02\n",
            " 2.07500460e-01 3.09999470e-01 5.67499160e-01 7.50007600e-02\n",
            " 2.29999540e-01 6.99997000e-02 1.32501600e-01 1.62498470e-01\n",
            " 3.00006900e-02 3.20001600e-01 5.49984000e-02 4.50000700e-02\n",
            " 8.74996200e-02 3.25000770e-01 3.17499160e-01 1.25000000e-01\n",
            " 1.54998780e-01 6.50005300e-02 9.00001500e-02 3.22500230e-01\n",
            " 8.50009900e-02 2.77500150e-01 3.97499080e-01 3.25012300e-02\n",
            " 5.74989300e-02 1.22501370e-01 2.20001220e-01 3.17497250e-01\n",
            " 2.95001990e-01 2.12501530e-01 9.24987800e-02 9.00001500e-02\n",
            " 3.25012200e-02 3.74984700e-02 1.74980200e-02 5.50003000e-02\n",
            " 2.75001530e-01 6.75010700e-02 1.19998930e-01 3.25000760e-01\n",
            " 3.49998400e-02 5.74996950e-01 1.12503050e-01 2.49863000e-03\n",
            " 1.92501070e-01 1.42501830e-01 2.20001220e-01 2.57499700e-01\n",
            " 2.37499230e-01 2.22499840e-01 3.72497560e-01 1.18000031e+00\n",
            " 2.95001980e-01 5.87497710e-01 5.74989300e-02 1.50001530e-01\n",
            " 7.99980100e-02 1.99966400e-02 5.29998780e-01 9.00001500e-02\n",
            " 4.24995400e-02 1.25007600e-02 5.60001370e-01 3.24974100e-02\n",
            " 1.15001680e-01 2.79998770e-01 2.99999240e-01 5.74989300e-02\n",
            " 5.77503200e-01 2.09999090e-01 3.92498010e-01 1.30001070e-01\n",
            " 8.00018300e-02 1.74999240e-01 3.49998470e-01 2.24990900e-02\n",
            " 1.50032000e-02 2.38249969e+00 3.80001070e-01 7.27500920e-01\n",
            " 5.25016800e-02 4.97497560e-01 7.74993900e-02 1.25000000e-01\n",
            " 1.17500310e-01 6.75010600e-02 3.14998630e-01 2.79998780e-01\n",
            " 1.92501070e-01 1.57501220e-01 4.77500920e-01 2.52498630e-01\n",
            " 4.12498470e-01 2.00000770e-01 1.59999840e-01 8.75015300e-02\n",
            " 1.25007600e-02 3.09997560e-01 3.17501070e-01 6.57501220e-01\n",
            " 2.17498780e-01 6.99997000e-02 1.44250107e+00 1.11750030e+00\n",
            " 3.94996640e-01 1.07999802e+00 1.82502740e-01 6.49986300e-02\n",
            " 2.47501370e-01 5.77499390e-01 3.25000760e-01 1.25000000e-01\n",
            " 2.37499240e-01 1.39999390e-01 4.72499850e-01 1.62498470e-01\n",
            " 1.57501220e-01 7.57499700e-01 1.50001530e-01 9.50012200e-02\n",
            " 5.62500000e-01 2.04998020e-01 6.00013700e-02 1.07501980e-01\n",
            " 4.67498780e-01 5.07499700e-01 1.77501680e-01 7.22499850e-01\n",
            " 2.15000150e-01 6.97498320e-01 1.38750076e+00 4.32502750e-01\n",
            " 3.82499690e-01 9.35001380e-01 2.72499080e-01 3.49998500e-02\n",
            " 1.27498630e-01 7.20001220e-01 5.97499850e-01 2.77500150e-01\n",
            " 1.05003360e-01 5.12496940e-01 7.67498020e-01 5.55000300e-01\n",
            " 2.27500920e-01 2.50000000e-01 2.09999080e-01 8.75015300e-02\n",
            " 6.87500000e-01 3.82499700e-01 2.13750076e+00 1.62500000e+00\n",
            " 8.54999540e-01 7.42500310e-01 1.12499240e-01 9.00001500e-02\n",
            " 2.02499390e-01 7.90000910e-01 1.30001070e-01 3.49998500e-02\n",
            " 2.99987800e-02 1.52500150e-01 6.75010700e-02 2.87502290e-01\n",
            " 9.50012200e-02 1.87500000e-01 1.62498480e-01 1.19998930e-01\n",
            " 5.62500000e-01 1.50001520e-01 3.25012300e-02 1.07498160e-01\n",
            " 2.02499390e-01 1.70001980e-01 3.07502750e-01 2.97500610e-01\n",
            " 2.77500150e-01 1.65500259e+00 9.00001500e-02 1.27498630e-01\n",
            " 6.25000000e-02 6.99996900e-02 2.92499550e-01 7.67498020e-01\n",
            " 1.03499985e+00 3.07498930e-01 4.22500610e-01 4.49996950e-01\n",
            " 7.37503050e-01 1.19249726e+00 1.52500150e-01 1.22501370e-01\n",
            " 1.74999240e-01 8.37501530e-01 1.07498160e-01 3.65001680e-01\n",
            " 2.32498170e-01 6.72500610e-01 1.45000460e-01 8.67500310e-01\n",
            " 2.75001500e-02 5.25001520e-01 2.17498780e-01 1.89998630e-01\n",
            " 1.33499908e+00 1.49993900e-02 1.22501380e-01 1.58499908e+00\n",
            " 3.77502440e-01 3.25012200e-02 1.62502290e-01 3.22502140e-01\n",
            " 2.09999080e-01 6.99997000e-02 7.47501370e-01 6.77497860e-01\n",
            " 6.22501370e-01 4.44999700e-01 5.50003000e-02 7.47501370e-01\n",
            " 2.00499725e+00 7.12501530e-01 6.70001990e-01 8.54999540e-01\n",
            " 1.22501370e-01 3.17497250e-01 4.05002590e-01 7.17498780e-01\n",
            " 6.50001530e-01 1.16999817e+00 8.87500760e-01 1.57501220e-01\n",
            " 2.00000770e-01 8.07498930e-01 2.64999390e-01 1.50001520e-01\n",
            " 1.25000000e-01 1.70999909e+00 3.40000150e-01 8.00018300e-02\n",
            " 6.95003510e-01 5.09998320e-01 1.50001530e-01 7.82497400e-01\n",
            " 6.55002600e-01 3.07498930e-01 5.02502440e-01 1.92497250e-01\n",
            " 1.97502140e-01 7.02499390e-01 1.82498930e-01 5.12500760e-01\n",
            " 1.80000310e-01 4.77500920e-01 1.29000091e+00 1.19998940e-01\n",
            " 1.61249923e+00 8.62499240e-01 1.57501220e-01 1.97498320e-01\n",
            " 1.33249664e+00 8.00018300e-02 6.00013800e-02 2.07500450e-01\n",
            " 1.45000460e-01 1.59999850e-01 5.55000300e-01 1.65000920e-01\n",
            " 3.69998930e-01 6.00013700e-02 1.54998780e-01 1.82498930e-01\n",
            " 4.20001990e-01 5.99975500e-02 2.25029000e-02 1.22497560e-01\n",
            " 2.27500920e-01 2.68249893e+00 2.27500920e-01 9.92500300e-01\n",
            " 2.34500122e+00 1.80000310e-01 1.39249801e+00 1.55002600e-01\n",
            " 7.49969400e-02 1.97502140e-01 1.92501070e-01 2.82497410e-01\n",
            " 6.25000000e-01 1.12250138e+00 1.12499230e-01 5.05001070e-01\n",
            " 8.49990800e-02 1.73250199e+00 6.77497860e-01 7.50351000e-03\n",
            " 5.07499700e-01 2.27497100e-01 9.04998780e-01 9.77500910e-01\n",
            " 6.09996800e-01 5.95001220e-01 1.79999924e+00 1.22501370e-01\n",
            " 3.57501990e-01 8.52500910e-01 3.02497870e-01 2.60002130e-01\n",
            " 3.89999390e-01 4.82498170e-01 6.30001070e-01 1.25000000e-01\n",
            " 4.80003360e-01 8.49990800e-02 5.40000920e-01 2.24990800e-02\n",
            " 5.07499700e-01 8.00018300e-02 4.97497550e-01 2.50015300e-02\n",
            " 2.24998470e-01 4.12498480e-01 1.42501830e-01 6.07498170e-01\n",
            " 1.80000310e-01 2.05001830e-01 4.99725000e-03 6.45004270e-01\n",
            " 1.27749634e+00 7.50045800e-02 3.64997860e-01 6.84997560e-01\n",
            " 1.37250519e+00 2.44995110e-01 3.25012200e-02 1.87500000e-01\n",
            " 4.00001530e-01 1.60003660e-01 1.27249909e+00 9.97497560e-01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[mask & (high_diff > 0), 'gel_reu_value'] = high_diff\n",
            "<ipython-input-25-3de07a088b74>:672: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[5.32499310e-01 8.60000610e-01 9.99832000e-03 3.90001290e-01\n",
            " 9.49993200e-02 4.85000610e-01 7.50007700e-02 1.18250084e+00\n",
            " 2.37499230e-01 2.80000690e-01 4.99992300e-02 9.74998500e-02\n",
            " 1.62500380e-01 3.35001000e-01 7.24983200e-02 3.12500000e-01\n",
            " 3.07500840e-01 1.39999390e-01 3.25012200e-02 2.99987800e-02\n",
            " 7.99999200e-02 2.50054000e-03 5.50003000e-02 2.69998550e-01\n",
            " 2.67499920e-01 6.97500230e-01 1.77499770e-01 4.25014500e-02\n",
            " 1.35000230e-01 2.24998470e-01 2.75001600e-02 1.49999610e-01\n",
            " 2.05750084e+00 3.57500080e-01 4.34999470e-01 2.50000000e-01\n",
            " 2.07500460e-01 6.59999840e-01 4.25001150e-01 5.50003100e-02\n",
            " 3.40000150e-01 8.74996200e-02 1.70000080e-01 1.92499160e-01\n",
            " 6.75010700e-02 8.74996100e-02 6.49999620e-01 2.87500380e-01\n",
            " 2.17500690e-01 2.24990800e-02 5.24997700e-02 2.04999920e-01\n",
            " 3.47499850e-01 1.25000000e-01 1.02500920e-01 1.27500530e-01\n",
            " 4.24995400e-02 2.50000000e-01 9.25006900e-02 4.99916000e-03\n",
            " 1.97500230e-01 4.57500450e-01 5.27500160e-01 1.49999620e-01\n",
            " 5.99994700e-02 1.84999470e-01 1.74999200e-02 2.22499850e-01\n",
            " 1.34998320e-01 1.19998930e-01 7.44998930e-01 9.22500610e-01\n",
            " 6.25000000e-02 2.44998930e-01 3.60000610e-01 3.52499010e-01\n",
            " 5.55000300e-01 4.37500000e-01 2.19999320e-01 4.50000700e-02\n",
            " 1.49999620e-01 2.60000230e-01 1.25007700e-02 1.92499160e-01\n",
            " 2.25009900e-02 5.75008400e-02 2.34998700e-01 1.00002300e-02\n",
            " 2.07500460e-01 4.34997560e-01 4.00009200e-02 4.32502750e-01\n",
            " 4.50019800e-02 4.49981700e-02 9.25026000e-02 7.09999080e-01\n",
            " 3.49998500e-02 1.04999540e-01 1.75018300e-02 9.99832000e-03\n",
            " 1.72500610e-01 1.25249863e+00 6.00013800e-02 2.32498170e-01\n",
            " 2.09499740e+00 8.77502440e-01 4.07497400e-01 2.50244000e-03\n",
            " 3.72501370e-01 1.14997860e-01 2.20001230e-01 9.50012200e-02\n",
            " 7.74993900e-02 2.67498020e-01 1.12500000e+00 9.09999850e-01\n",
            " 5.75000770e-01 2.79998770e-01 4.02500160e-01 7.67501830e-01\n",
            " 9.99832000e-03 4.00009200e-02 4.57500460e-01 2.15000150e-01\n",
            " 1.04249954e+00 2.70000460e-01 5.47500610e-01 3.49998470e-01\n",
            " 1.74999240e-01 6.49986300e-02 1.05249786e+00 5.74989300e-02\n",
            " 8.25004600e-02 1.15001680e-01 5.55000300e-01 6.99996950e-01\n",
            " 2.00004600e-02 3.69998930e-01 1.17499923e+00 2.50015300e-02\n",
            " 4.84996790e-01 7.50351000e-03 2.09999080e-01 1.10500336e+00\n",
            " 1.22501370e-01 1.02500920e-01 1.44996640e-01 2.02499390e-01\n",
            " 8.50002290e-01 6.67499550e-01 1.17500300e-01 7.47497560e-01\n",
            " 5.92502590e-01 1.66499710e+00 1.02500153e+00 5.00000000e-01\n",
            " 1.19749832e+00 1.02500910e-01 5.25016800e-02 6.25000000e-02\n",
            " 3.57501980e-01 4.75006100e-02 9.89997860e-01 6.00002290e-01\n",
            " 6.64997100e-01 9.15000920e-01 3.12500000e-01 9.37500000e-01\n",
            " 1.80750275e+00 3.34999090e-01 7.17498770e-01 4.44999700e-01\n",
            " 5.87497710e-01 2.55001060e-01 2.24990900e-02 1.59999840e-01\n",
            " 5.37498470e-01 5.50003000e-02 4.90001680e-01 2.64999390e-01\n",
            " 9.37500000e-01 6.00013700e-02 9.92500310e-01 2.22499840e-01\n",
            " 4.22500610e-01 3.05000300e-01 3.25012200e-02 5.82496640e-01\n",
            " 2.57499700e-01 5.59997560e-01 4.75006100e-02 3.82499690e-01\n",
            " 9.50000770e-01 1.47499080e-01 1.06000137e+00 1.31250000e+00\n",
            " 3.75022900e-02 4.54998020e-01 1.64997100e-01 1.53749847e+00\n",
            " 9.50012200e-02 1.03749848e+00 9.32498930e-01 2.00004500e-02\n",
            " 9.39998630e-01 6.82498930e-01 4.00009200e-02 4.67498780e-01\n",
            " 1.64500046e+00 2.84500122e+00 1.81499863e+00 4.70001220e-01\n",
            " 2.11500168e+00 5.84999080e-01 1.38000107e+00 4.77497100e-01\n",
            " 2.37000274e+00 8.52497100e-01 4.60002900e-01 1.23500061e+00\n",
            " 1.46250153e+00 5.29998780e-01 1.24250030e+00 9.35001380e-01\n",
            " 6.37500760e-01 9.09999850e-01 9.47498320e-01 1.41749954e+00\n",
            " 7.60002140e-01 3.05749893e+00 4.09999840e-01 1.59999850e-01\n",
            " 2.29999540e-01 5.02502450e-01 4.79999540e-01 7.99980200e-02\n",
            " 1.10000610e-01 7.49970000e-03 4.79999540e-01 6.30001070e-01\n",
            " 2.64999390e-01 8.02497860e-01 5.05001070e-01 4.92496490e-01\n",
            " 7.50000000e-01 7.52498630e-01 2.74997710e-01 1.15750122e+00\n",
            " 6.67499540e-01 1.04249954e+00 9.72499850e-01 2.47999954e+00\n",
            " 1.61999894e+00 1.18500137e+00 4.77500920e-01 2.52498630e-01\n",
            " 7.72499090e-01 7.15000150e-01 7.50007700e-02 1.06999969e+00\n",
            " 5.74989300e-02 2.27500920e-01 1.10000610e-01 1.27750015e+00\n",
            " 2.26250076e+00 3.49998500e-02 2.02499390e-01 2.43750000e+00\n",
            " 5.24978600e-02 1.09996800e-01 1.77497860e-01 4.92500300e-01\n",
            " 6.99997000e-02 1.25007600e-02 1.56750107e+00 6.99996950e-01\n",
            " 3.67500300e-01 7.74993900e-02 3.40000150e-01 9.87503050e-01\n",
            " 2.50244000e-03 9.57504280e-01 1.79000091e+00 9.75036600e-02]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[mask & (low_diff < 0), 'gel_red_value'] = abs(low_diff)\n",
            "ERROR:GetSets:Error looking up parent data for column open: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:Error mapping parent data: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:Error in process_calculations: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:DataFrame info: None\n",
            "ERROR:GetSets:Error processing file /content/input/AAPL_D_1.csv: Length of values (48) does not match length of index (47)\n",
            "ERROR:root:Error processing /content/input/AAPL_D_1.csv: Length of values (48) does not match length of index (47)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 1015, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 70, in process_file\n",
            "    child_df = self._process_child_calculations(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 158, in _process_child_calculations\n",
            "    return child_processor.process_calculations(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 303, in process_calculations\n",
            "    df = self._map_parent_data(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 378, in _map_parent_data\n",
            "    df['parent_open'] = self._lookup_parent_data(df, parent_df, 'open')\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 430, in _lookup_parent_data\n",
            "    lookup = pd.Series(index=parent_dates, data=parent_df[column].values)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\", line 575, in __init__\n",
            "    com.require_length_match(data, index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\", line 573, in require_length_match\n",
            "    raise ValueError(\n",
            "ValueError: Length of values (48) does not match length of index (47)\n",
            "<ipython-input-25-3de07a088b74>:671: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[4.000e-02 2.100e-01 1.480e+00 3.830e+00 2.470e+00 2.530e+00 2.560e+00\n",
            " 1.280e+00 4.000e-02 1.110e+00 1.530e+00 1.030e+00 1.160e+00 1.090e+00\n",
            " 4.200e-01 1.500e-01 3.400e-01 2.400e-01 3.000e-02 1.400e-01 2.000e-02\n",
            " 1.040e+00 6.100e-01 4.400e-01 8.800e-01 8.200e-01 1.400e-01 1.390e+00\n",
            " 4.800e-01 2.300e-01 1.200e-01 6.400e-01 3.400e-01 4.200e-01 8.000e-02\n",
            " 7.300e-01 7.500e-01 3.200e-01 2.100e-01 6.100e-01 1.120e+00 7.300e-01\n",
            " 7.000e-02 1.870e+00 1.310e+00 3.400e-01 1.570e+00 7.600e-01 3.600e-01\n",
            " 1.900e-01 1.280e+00 2.010e+00 1.300e+00 1.830e+00 2.750e+00 1.790e+00\n",
            " 5.700e-01 9.700e-01 4.000e-02 1.380e+00 4.300e-01 4.800e-01 7.000e-02\n",
            " 4.200e-01 2.500e-01 1.840e+00 3.100e-01 6.300e-01 7.800e-01 1.110e+00\n",
            " 8.000e-01 4.600e-01 1.080e+00 1.560e+00 7.900e-01 3.600e-01 9.000e-01\n",
            " 4.400e-01 2.600e+00 4.700e-01 1.060e+00 1.700e-01 1.710e+00 1.800e+00\n",
            " 2.200e+00 3.800e-01 3.200e-01 2.000e-02 5.600e-01 1.040e+00 8.000e-01\n",
            " 2.600e+00 2.400e-01 2.110e+00 7.800e-01 2.100e-01 1.400e-01 5.500e-01\n",
            " 1.700e-01 1.300e-01 3.000e-02 6.000e-02 1.280e+00 3.000e-01 7.500e-01\n",
            " 1.700e-01 1.000e+00 8.000e-01 8.600e-01 1.510e+00 5.100e-01 1.220e+00\n",
            " 1.200e-01 2.000e-02 2.090e+00 1.120e+00 7.900e-01 8.000e-01 1.500e-01\n",
            " 7.100e-01 6.000e-01 4.200e-01 9.500e-01 7.600e-01 2.100e-01 4.100e-01\n",
            " 2.400e-01 8.200e-01 1.950e+00 9.700e-01 1.080e+00 1.900e-01 6.700e-01\n",
            " 1.120e+00 1.400e+00 3.000e-01 5.100e-01 1.700e-01 1.980e+00 2.500e-01\n",
            " 5.400e-01 9.000e-01 1.960e+00 1.200e+00 2.080e+00 7.800e-01 1.210e+00\n",
            " 1.050e+00 9.400e-01 4.400e-01 1.790e+00 4.500e-01 4.800e-01 2.500e-01\n",
            " 1.330e+00 8.700e-01 1.090e+00 5.200e-01 1.920e+00 1.700e+00 8.100e-01\n",
            " 3.900e-01 1.800e-01 6.600e-01 1.900e-01 3.500e-01 7.800e-01 1.820e+00\n",
            " 1.180e+00 3.060e+00 9.900e-01 7.900e-01 1.850e+00 4.400e-01 1.280e+00\n",
            " 1.510e+00 1.960e+00 5.600e-01 3.300e-01 3.000e-02 1.780e+00 4.400e-01\n",
            " 1.730e+00 1.220e+00 1.348e+01 8.700e-01 1.270e+00 3.000e-02 3.010e+00\n",
            " 1.770e+00 5.600e-01 1.170e+00 1.890e+00 4.390e+00 5.100e-01 1.800e-01\n",
            " 5.600e-01 2.200e-01 4.500e-01 1.900e-01 1.980e+00 1.220e+00 3.000e-02\n",
            " 7.100e-01 6.600e-01 2.870e+00 9.900e-01 1.120e+00 3.900e-01 5.400e-01\n",
            " 5.230e+00 4.160e+00 1.320e+00 7.600e-01 1.690e+00 2.960e+00 2.000e-02\n",
            " 5.830e+00 1.850e+00 2.500e-01 1.230e+00 3.070e+00 1.450e+00 7.400e-01\n",
            " 2.000e+00 8.300e-01 5.000e-01 2.020e+00 7.300e-01 2.400e-01 2.710e+00\n",
            " 8.900e-01 9.300e-01 2.190e+00 7.900e-01 3.000e-01 1.280e+00 1.060e+00\n",
            " 3.400e-01 1.630e+00 1.540e+00 7.200e-01 3.000e-02 2.700e-01 4.300e-01\n",
            " 1.630e+00 2.560e+00 2.330e+00 1.450e+00 1.500e+00 1.070e+00 8.000e-02\n",
            " 1.920e+00 3.300e+00 1.810e+00 1.820e+00 1.700e+00 1.390e+00 1.310e+00\n",
            " 6.700e-01 2.000e-01 2.520e+00 1.360e+00 7.100e-01 1.000e-01 5.200e-01\n",
            " 9.700e-01 1.220e+00 2.510e+00 1.280e+00 1.930e+00 2.390e+00 7.300e-01\n",
            " 2.040e+00 1.250e+00 1.050e+00 7.400e-01 1.170e+00 1.000e+00 1.710e+00\n",
            " 1.050e+00 8.000e-02 7.800e-01 4.930e+00 2.400e+00 1.300e-01 3.420e+00\n",
            " 3.880e+00 5.400e-01 2.110e+00 1.250e+00 1.740e+00 5.100e-01 3.660e+00\n",
            " 1.340e+00 8.300e-01 2.700e-01 1.510e+00 1.860e+00 2.920e+00 2.640e+00\n",
            " 2.280e+00 1.900e-01 6.500e-01 1.630e+00 4.670e+00 3.020e+00 1.500e-01\n",
            " 4.600e-01 1.410e+00 2.000e-01 1.900e-01 3.850e+00 1.030e+00 1.010e+00\n",
            " 1.580e+00 2.500e-01 6.700e-01 6.400e-01 2.600e-01 1.030e+00 1.120e+00\n",
            " 1.020e+00 3.160e+00 1.500e-01 1.390e+00 2.800e-01 1.700e-01 5.400e-01\n",
            " 2.350e+00 3.010e+00 6.100e-01 4.400e-01 6.200e-01 2.610e+00 1.200e-01\n",
            " 3.360e+00 4.500e-01 1.230e+00 2.300e-01 9.400e-01 1.370e+00 3.570e+00\n",
            " 7.400e-01 2.510e+00 6.000e-02 2.350e+00 1.890e+00 6.220e+00 1.800e-01\n",
            " 1.000e-02 2.590e+00 1.700e+00 2.500e-01 2.720e+00 9.400e-01 4.000e+00\n",
            " 1.200e+00 1.050e+00 6.600e-01 1.640e+00 5.200e-01 2.100e-01 3.000e-01\n",
            " 5.500e-01 2.400e-01 5.440e+00 2.340e+00 1.360e+00 1.500e-01 1.080e+00\n",
            " 5.500e-01 2.310e+00 1.740e+00 2.000e-01 4.050e+00 3.900e-01 1.040e+00\n",
            " 2.100e-01 3.100e-01 2.180e+00 8.500e-01 2.600e+00 1.220e+00 2.300e-01\n",
            " 5.600e-01 6.600e-01 2.410e+00 3.110e+00 1.190e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[mask & (high_diff > 0), 'gel_reu_value'] = high_diff\n",
            "<ipython-input-25-3de07a088b74>:672: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[1.650e+00 2.340e+00 3.400e-01 6.800e-01 2.300e-01 4.900e-01 1.120e+00\n",
            " 2.140e+00 1.710e+00 6.500e-01 2.610e+00 5.900e-01 1.280e+00 1.600e-01\n",
            " 2.800e-01 9.000e-01 1.080e+00 7.800e-01 3.400e-01 1.100e-01 1.800e-01\n",
            " 4.700e-01 1.010e+00 1.400e+00 2.300e-01 3.100e-01 2.000e-01 7.800e-01\n",
            " 6.100e-01 1.110e+00 2.170e+00 2.100e-01 5.200e-01 6.800e-01 1.270e+00\n",
            " 6.500e-01 4.200e-01 2.170e+00 2.710e+00 1.170e+00 2.300e-01 4.900e-01\n",
            " 2.800e-01 3.700e-01 2.330e+00 2.300e-01 8.000e-02 5.800e-01 7.400e-01\n",
            " 2.000e-01 7.000e-02 5.900e-01 2.800e-01 5.000e-01 2.760e+00 8.000e-01\n",
            " 6.800e-01 2.600e-01 1.160e+00 1.800e-01 6.000e-01 2.680e+00 5.000e-01\n",
            " 4.700e-01 1.120e+00 2.000e-01 8.000e-02 1.500e-01 5.600e-01 1.070e+00\n",
            " 2.180e+00 1.100e-01 1.790e+00 2.800e-01 1.080e+00 5.000e-02 4.700e-01\n",
            " 3.000e-01 3.000e-01 1.140e+00 7.000e-02 4.200e-01 2.800e-01 9.100e-01\n",
            " 4.700e-01 5.300e-01 2.260e+00 9.800e-01 8.800e-01 6.300e-01 2.200e-01\n",
            " 2.000e-02 7.700e-01 8.800e-01 1.460e+00 1.400e-01 2.400e-01 1.500e-01\n",
            " 2.700e-01 3.100e-01 6.400e-01 8.400e-01 1.060e+00 1.260e+00 9.900e-01\n",
            " 1.100e+00 1.000e-02 5.100e-01 3.100e-01 1.950e+00 1.930e+00 7.200e-01\n",
            " 4.000e-02 2.400e-01 1.410e+00 1.029e+01 3.500e-01 8.000e-02 3.400e-01\n",
            " 1.030e+00 1.530e+00 3.700e-01 5.800e-01 3.000e-01 9.000e-02 4.300e-01\n",
            " 2.270e+00 3.560e+00 1.010e+00 8.600e-01 2.800e-01 1.400e+00 6.900e-01\n",
            " 8.400e-01 1.750e+00 7.400e-01 1.800e-01 5.000e-01 5.400e-01 5.400e-01\n",
            " 7.400e-01 1.150e+00 4.100e-01 2.100e-01 3.500e-01 1.740e+00 1.000e-01\n",
            " 1.650e+00 1.510e+00 1.090e+00 1.578e+01 3.480e+00 3.740e+00 1.080e+00\n",
            " 2.600e+00 2.670e+00 2.540e+00 3.290e+00 7.340e+00 6.300e+00 7.000e-02\n",
            " 3.800e-01 1.000e-01 1.430e+00 2.400e-01 1.660e+00 1.494e+01 6.000e-01\n",
            " 1.480e+00 1.800e-01 1.680e+00 2.170e+00 3.000e-01 2.000e-01 1.810e+00\n",
            " 1.530e+00 3.800e-01 1.900e-01 1.900e-01 2.830e+00 1.490e+00 9.000e-01\n",
            " 2.230e+00 7.900e-01 4.600e-01 4.800e-01 8.000e-02 5.200e-01 1.050e+00\n",
            " 4.800e-01 5.940e+00 2.530e+00 1.900e+00 2.920e+00 1.250e+00 8.000e-02\n",
            " 1.920e+00 2.100e-01 1.630e+00 1.700e-01 3.430e+00 4.800e-01 2.010e+00\n",
            " 2.300e-01 9.500e-01 5.000e-02 8.200e-01 1.190e+00 6.760e+00 4.220e+00\n",
            " 4.800e-01 6.900e-01 3.000e-02 1.160e+01 4.400e-01 1.350e+00 3.100e-01\n",
            " 2.670e+00 1.800e-01 4.000e-02 2.020e+00 1.280e+00 1.560e+00 1.000e-02\n",
            " 4.150e+00 3.260e+00 9.900e-01 2.810e+00 3.070e+00 3.340e+00 1.800e+00\n",
            " 3.510e+00 1.550e+00 4.290e+00 1.380e+00 3.180e+00 1.500e-01 1.630e+00\n",
            " 1.200e-01 3.700e-01 1.700e+00 7.300e-01 8.000e-01 5.000e-02 9.000e-02\n",
            " 1.010e+00 1.010e+00 9.700e-01 1.590e+00 9.000e-01 3.560e+00 4.200e-01\n",
            " 1.100e-01 1.100e+00 1.260e+00 1.850e+00 1.380e+00 9.200e-01 7.000e-02\n",
            " 2.306e+01 2.000e-01 2.350e+00 2.120e+00 2.720e+00 1.940e+00 3.030e+00\n",
            " 9.800e-01 1.900e-01 1.910e+00 2.450e+00 2.360e+00 1.330e+00 1.040e+00\n",
            " 2.380e+00 4.200e-01 3.100e-01 5.300e-01 1.520e+00 1.130e+00 5.300e-01\n",
            " 3.700e-01 1.200e-01 2.680e+00 8.000e-01 3.740e+00 2.600e-01 1.600e-01\n",
            " 7.000e-02 4.750e+00 2.200e-01 2.690e+00 4.510e+00 1.270e+00 4.060e+00\n",
            " 4.000e-01 2.410e+00 2.540e+00 6.800e-01 4.080e+00 1.500e-01 9.100e-01\n",
            " 5.900e-01 1.180e+00 1.040e+00 1.660e+00 2.800e-01 4.000e-01 7.400e-01\n",
            " 2.960e+00 3.190e+00 2.460e+00 4.570e+00 2.910e+00 2.100e-01 2.050e+00\n",
            " 6.000e-02 6.300e-01 1.690e+00 2.210e+00 3.210e+00 1.410e+00 2.300e-01\n",
            " 5.400e-01 4.500e-01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[mask & (low_diff < 0), 'gel_red_value'] = abs(low_diff)\n",
            "ERROR:GetSets:Error looking up parent data for column open: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:Error mapping parent data: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:Error in process_calculations: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:DataFrame info: None\n",
            "ERROR:GetSets:Error processing file /content/input/MMM_D_1.csv: Length of values (48) does not match length of index (47)\n",
            "ERROR:root:Error processing /content/input/MMM_D_1.csv: Length of values (48) does not match length of index (47)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 1015, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 70, in process_file\n",
            "    child_df = self._process_child_calculations(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 158, in _process_child_calculations\n",
            "    return child_processor.process_calculations(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 303, in process_calculations\n",
            "    df = self._map_parent_data(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 378, in _map_parent_data\n",
            "    df['parent_open'] = self._lookup_parent_data(df, parent_df, 'open')\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 430, in _lookup_parent_data\n",
            "    lookup = pd.Series(index=parent_dates, data=parent_df[column].values)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\", line 575, in __init__\n",
            "    com.require_length_match(data, index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\", line 573, in require_length_match\n",
            "    raise ValueError(\n",
            "ValueError: Length of values (48) does not match length of index (47)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing file: /content/input/AAPL_D_1.csv\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1005 entries, 2016-01-04 to 2019-12-30\n",
            "Data columns (total 28 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   open            1005 non-null   float64\n",
            " 1   high            1005 non-null   float64\n",
            " 2   low             1005 non-null   float64\n",
            " 3   close           1005 non-null   float64\n",
            " 4   trading_bop     1005 non-null   int64  \n",
            " 5   reu_value       1005 non-null   float64\n",
            " 6   reu_flag        1005 non-null   int64  \n",
            " 7   red_value       1005 non-null   float64\n",
            " 8   red_flag        1005 non-null   int64  \n",
            " 9   re_value        1005 non-null   float64\n",
            " 10  re_flag         1005 non-null   int64  \n",
            " 11  gel_open        1005 non-null   float64\n",
            " 12  gel_high        1005 non-null   float64\n",
            " 13  gel_low         1005 non-null   float64\n",
            " 14  gel_close       1005 non-null   float64\n",
            " 15  gel_range       1005 non-null   float64\n",
            " 16  gel_percent_r   1005 non-null   float64\n",
            " 17  gel_ce_percent  957 non-null    float64\n",
            " 18  gel_reu_value   1005 non-null   float64\n",
            " 19  gel_red_value   1005 non-null   float64\n",
            " 20  gel_reu_flag    1005 non-null   int64  \n",
            " 21  gel_red_flag    1005 non-null   int64  \n",
            " 22  gel_re_value    1005 non-null   float64\n",
            " 23  gel_epc         957 non-null    float64\n",
            " 24  gel_epc_dir     1005 non-null   int64  \n",
            " 25  gel_epc_hp      1005 non-null   int64  \n",
            " 26  gel_e1_value    1005 non-null   float64\n",
            " 27  gel_e2_value    1005 non-null   float64\n",
            "dtypes: float64(20), int64(8)\n",
            "memory usage: 260.0 KB\n",
            "Error processing /content/input/AAPL_D_1.csv: Length of values (48) does not match length of index (47)\n",
            "\n",
            "Processing file: /content/input/MMM_D_1.csv\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1005 entries, 2016-01-04 to 2019-12-30\n",
            "Data columns (total 28 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   open            1005 non-null   float64\n",
            " 1   high            1005 non-null   float64\n",
            " 2   low             1005 non-null   float64\n",
            " 3   close           1005 non-null   float64\n",
            " 4   trading_bop     1005 non-null   int64  \n",
            " 5   reu_value       1005 non-null   float64\n",
            " 6   reu_flag        1005 non-null   int64  \n",
            " 7   red_value       1005 non-null   float64\n",
            " 8   red_flag        1005 non-null   int64  \n",
            " 9   re_value        1005 non-null   float64\n",
            " 10  re_flag         1005 non-null   int64  \n",
            " 11  gel_open        1005 non-null   float64\n",
            " 12  gel_high        1005 non-null   float64\n",
            " 13  gel_low         1005 non-null   float64\n",
            " 14  gel_close       1005 non-null   float64\n",
            " 15  gel_range       1005 non-null   float64\n",
            " 16  gel_percent_r   1005 non-null   float64\n",
            " 17  gel_ce_percent  957 non-null    float64\n",
            " 18  gel_reu_value   1005 non-null   float64\n",
            " 19  gel_red_value   1005 non-null   float64\n",
            " 20  gel_reu_flag    1005 non-null   int64  \n",
            " 21  gel_red_flag    1005 non-null   int64  \n",
            " 22  gel_re_value    1005 non-null   float64\n",
            " 23  gel_epc         957 non-null    float64\n",
            " 24  gel_epc_dir     1005 non-null   int64  \n",
            " 25  gel_epc_hp      1005 non-null   int64  \n",
            " 26  gel_e1_value    1005 non-null   float64\n",
            " 27  gel_e2_value    1005 non-null   float64\n",
            "dtypes: float64(20), int64(8)\n",
            "memory usage: 260.0 KB\n",
            "Error processing /content/input/MMM_D_1.csv: Length of values (48) does not match length of index (47)\n",
            "\n",
            "Processing file: /content/input/XLB_D_1.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-3de07a088b74>:671: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.31 0.39 0.2  ... 1.   0.24 0.01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[mask & (high_diff > 0), 'gel_reu_value'] = high_diff\n",
            "<ipython-input-25-3de07a088b74>:672: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.03 0.63 0.39 ... 0.53 0.47 2.52]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[mask & (low_diff < 0), 'gel_red_value'] = abs(low_diff)\n",
            "ERROR:GetSets:Error looking up parent data for column open: Length of values (313) does not match length of index (312)\n",
            "ERROR:GetSets:Error mapping parent data: Length of values (313) does not match length of index (312)\n",
            "ERROR:GetSets:Error in process_calculations: Length of values (313) does not match length of index (312)\n",
            "ERROR:GetSets:DataFrame info: None\n",
            "ERROR:GetSets:Error processing file /content/input/XLB_D_1.csv: Length of values (313) does not match length of index (312)\n",
            "ERROR:root:Error processing /content/input/XLB_D_1.csv: Length of values (313) does not match length of index (312)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 1015, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 70, in process_file\n",
            "    child_df = self._process_child_calculations(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 158, in _process_child_calculations\n",
            "    return child_processor.process_calculations(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 303, in process_calculations\n",
            "    df = self._map_parent_data(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 378, in _map_parent_data\n",
            "    df['parent_open'] = self._lookup_parent_data(df, parent_df, 'open')\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 430, in _lookup_parent_data\n",
            "    lookup = pd.Series(index=parent_dates, data=parent_df[column].values)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\", line 575, in __init__\n",
            "    com.require_length_match(data, index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\", line 573, in require_length_match\n",
            "    raise ValueError(\n",
            "ValueError: Length of values (313) does not match length of index (312)\n",
            "<ipython-input-25-3de07a088b74>:671: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.22500038 0.07499885 0.45000077 0.43000031 0.15500068 0.09000016\n",
            " 0.22999954 0.11000061 0.52999878 0.10500145 0.25       0.48999978\n",
            " 0.50499916 0.02000045 0.32500077 0.26499939 0.21000099 0.14500046\n",
            " 0.11499977 0.67499924 0.26999855 0.57999992 0.08500099 0.460001\n",
            " 0.07999802 0.26000214 0.49499893 0.42499923 0.44000245 0.1649971\n",
            " 0.34000015 0.25999832 0.39500046 0.06499863 0.12999725 0.0300026\n",
            " 0.06999969 0.125      0.0550003  0.47500229 0.14499664 0.04499817\n",
            " 0.10500336 0.07999801 0.04499817 0.13499832 0.56000137 0.20500183\n",
            " 0.21999741 0.45500183 0.50500106 1.02499771 0.27000046 0.14999771\n",
            " 0.23500061 0.03499985 0.25500107 0.01499938 0.06500244 0.06000137\n",
            " 0.10999679 0.00500107 0.53499985 0.00999832 0.33000184 0.02999878\n",
            " 0.14500046 0.0300026  0.26499939 0.20499801 0.19000244 0.06499863\n",
            " 0.05999755 0.29999923 0.30500031 0.20999908 0.02500152 0.0699997\n",
            " 0.05999755 0.01999664 0.18999862 0.29999924 0.00500107 0.25\n",
            " 0.35499954 0.8199997  0.93999862 0.06000137 0.07499695 0.04000092\n",
            " 0.01000214 0.15999984 0.29999924 0.28000259 0.45499801 0.33000184\n",
            " 0.25       0.18500137 0.125      0.20999908 0.04999923 0.02000046\n",
            " 0.27000046 0.0949974  0.10499954 0.06500245 0.11499786 0.24000168\n",
            " 0.15499878 0.01499939 0.57500076 0.05999756 0.20000076 0.00500107\n",
            " 0.36999893 0.05500031 0.07500077 0.06999969 0.06999969 0.21999741\n",
            " 0.04500198 0.06500244 0.04999924 0.09999847 0.07500077 0.29999923\n",
            " 0.27999878 0.09000016 0.06499862 0.10000229 0.19999695 0.06500244\n",
            " 0.05999756 0.77000046 0.13000107 0.02000046 0.10499954 0.08499909\n",
            " 0.25500107 0.04499817 0.22999954 0.03000259 0.13999939 0.01499939\n",
            " 1.28499984 0.08000183 0.05999756 0.74000168 0.01499939 0.02500152\n",
            " 0.36999894 0.09000015 0.04499817 0.10499954 0.10499954 0.29000091\n",
            " 0.8199997  0.03500366 0.14999771 0.10499954 0.05000306 0.01499939\n",
            " 0.11000061 0.18999862 0.02000046 0.17499924 0.23500061 0.02000045\n",
            " 0.30500031 0.31000137 0.1649971  0.29999924 0.13000107 0.34000016\n",
            " 0.19000244 0.27000046 0.2199974  0.22999954 0.0850029  0.0949974\n",
            " 0.26499939 0.33000183 0.16999817 0.08000183 0.27999878 0.06999969\n",
            " 0.375      0.46500015 0.02999878 0.08499909 0.06999969 0.06999969\n",
            " 0.00500107 0.04999924 0.16500091 0.35500336 0.22999954 0.22500229\n",
            " 0.57999802 0.27000046 0.32500076 0.22499847 0.25500107 0.28499984\n",
            " 0.0699997  0.11999894 0.09000015 0.11999893 0.58999634 0.13000107\n",
            " 0.60000229 0.21500015 0.04000092 0.05000306 0.35499954 0.28499985\n",
            " 0.72999954 0.29000091 0.74499893 0.36999894 0.70500183 0.32500076\n",
            " 0.55500031 0.23500061 0.01499939 0.54000092 0.83499908 0.0300026\n",
            " 0.15499878 0.00999832 0.2100029  0.22999954 0.18000031 0.38000107\n",
            " 0.29000092 0.18999862 0.04999924 0.15999985 0.08000183 0.15999985\n",
            " 0.06999969 0.62999726 0.00999832 0.09000015 0.45999908 0.04999924\n",
            " 0.01000214 0.02000046 0.11999893 0.02999878 0.12000274 0.43999862\n",
            " 0.11000061 0.07999802 0.12000275 0.00999832 0.08000183 0.00999832\n",
            " 0.37000275 0.05999755 0.10000229 0.15000153 0.0399971  0.34000015\n",
            " 0.09000016 0.27000045 0.20999909 0.58000183 1.99000168 0.18999863\n",
            " 0.02000045 0.16999817 0.28000259 0.09999847 0.11999893 0.02000046\n",
            " 0.20000076 0.45000077 0.5699997  0.5399971  0.1800003  0.35000229\n",
            " 0.25999832 0.02000046 0.09999848 0.25       0.22999954 0.11999893\n",
            " 0.74000168 0.35000229 0.60999679 0.29999923 0.16999817 0.33000183\n",
            " 0.99000168 0.39999771 0.70999909 0.23999786 0.2800026  0.26999664\n",
            " 2.18000031 0.02000046 0.83000183 0.47999954 0.09999847 0.0399971\n",
            " 0.04999924 0.13000107 0.08000183 0.43999862 0.20999909 0.61000061\n",
            " 0.24000168 0.45000076 0.21999741 0.22999954 0.60000229 0.28000259\n",
            " 0.66999816 0.27999878 0.0300026  0.02000046 0.04999924 0.14999771\n",
            " 0.11000061 0.12999725 0.13000107 0.25999832 0.26000214 0.09000015\n",
            " 0.45000077 0.26999664 0.24000168 0.14999771 0.20999909 0.31000137\n",
            " 0.23999787 0.11999893 0.01000214 0.81000138 0.07999801 0.30000306\n",
            " 0.70999908 0.0699997  0.09000015 0.75       0.16999817 0.01000213\n",
            " 0.19000245 0.62999725 0.79000092 0.11999893 0.72000122 0.25\n",
            " 0.36999893 0.11999893 0.08000183 0.13999939 0.04000092 0.17999649\n",
            " 0.40000153 0.68999863 0.02999877 0.1400032  0.22000123 0.2800026\n",
            " 0.06000138 0.61000061 0.04999923 0.11999894 0.1400032  0.52999878\n",
            " 0.40999985 0.40000152 0.45999908 0.74000168 0.20999908 0.25\n",
            " 0.47999954 0.27000046 0.22999954 0.40000152 0.02000046 0.37999725\n",
            " 0.92000199 0.5699997  0.63000107 0.12999725 0.06999969 0.11000061\n",
            " 0.84000015 0.20000076 0.04999924 0.3199997  0.55999756 0.05000305\n",
            " 0.09000016 0.18999862 0.0699997  0.12999725 0.39000321 0.25\n",
            " 0.07999801 0.29999923 0.51000214 0.70999909 0.29999924 0.04000092\n",
            " 0.02999877]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[mask & (high_diff > 0), 'gel_reu_value'] = high_diff\n",
            "<ipython-input-25-3de07a088b74>:672: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.125      0.51000023 0.15999984 0.17000008 0.07999992 0.31499863\n",
            " 0.65500068 0.1800003  0.28499985 0.90499878 0.07999992 0.39500046\n",
            " 0.03000069 0.15999984 0.52499962 0.07999992 0.25499916 0.30999946\n",
            " 0.11500168 0.06499863 0.0399971  0.12000275 0.15499878 0.09999847\n",
            " 0.00500107 0.11500168 0.125      0.11000061 0.14499664 0.25500107\n",
            " 0.09500122 0.34000016 0.99500275 0.71500015 0.36500168 0.04999924\n",
            " 0.08000183 0.00999832 0.14500046 0.0150032  0.21500015 0.85499955\n",
            " 0.09000016 0.15999984 0.20499802 0.11000061 0.15000153 0.02499771\n",
            " 0.04500199 0.02500152 0.02999878 0.18000031 0.25       0.34000015\n",
            " 0.01499939 0.04500198 0.14999771 0.02500153 0.49499893 0.125\n",
            " 0.11500168 0.02999878 0.20500183 0.25499725 0.28499985 0.21999741\n",
            " 0.22999954 0.49500275 0.04000092 0.50999832 0.29999923 0.04999923\n",
            " 0.30000306 0.13999939 0.98999787 0.45500183 0.05500031 0.09500122\n",
            " 0.11499786 0.125      0.13499832 0.11500168 0.11999894 0.04499816\n",
            " 0.09500122 0.125      0.06999969 0.125      0.04999924 0.02999878\n",
            " 0.15000152 0.32999802 0.00500107 0.15999984 0.11499786 0.04500198\n",
            " 0.32999801 0.32500077 0.16500091 0.01000214 0.00999832 0.16000366\n",
            " 0.02499771 0.02000046 0.13000107 0.01499939 0.02000046 0.15999984\n",
            " 0.35000229 0.04000092 0.45000077 0.07999801 0.30499649 0.32000351\n",
            " 0.15999985 0.19999695 0.15499878 0.11500168 0.09500122 0.1949997\n",
            " 0.25       0.09000015 0.0300026  0.02999878 0.47999954 0.1949997\n",
            " 0.125      0.28499985 0.54999923 0.63999939 0.16500092 0.25500107\n",
            " 0.17499923 0.00999832 0.77000046 0.20500183 0.02000046 0.13500214\n",
            " 0.11999893 0.08499908 0.15000153 0.03499985 0.11000061 0.1649971\n",
            " 0.27000046 0.21500015 0.07500077 0.15499878 0.04999924 0.09000015\n",
            " 0.08000184 0.29000091 0.1949997  0.05999755 0.04499816 3.01000214\n",
            " 0.48000336 0.33499908 1.16999816 1.3350029  0.07499695 0.20500183\n",
            " 0.14500045 0.23500061 0.27500153 0.25999832 0.01500321 0.04499816\n",
            " 0.61999894 0.47000122 1.11999893 0.02999878 0.04000091 0.04999924\n",
            " 0.20000076 0.07999802 0.00999832 0.93000031 0.13000106 0.29000092\n",
            " 0.15999985 0.69000244 0.09999847 0.11000061 0.15999984 0.29000092\n",
            " 0.17999649 0.24000168 0.27000046 0.16999816 0.3199997  0.4300003\n",
            " 0.39000321 0.09000015 0.47999954 0.13999939 0.15999985 0.24000168\n",
            " 0.11999893 0.37999725 0.06000137 0.13999939 0.16999817 0.05000305\n",
            " 0.23000336 0.20999909 0.29999924 0.15999985 0.05000305 0.04999924\n",
            " 0.64999771 0.11000061 0.25       0.02000046 0.43999862 0.09000016\n",
            " 0.09000015 1.9300003  0.7800026  0.75       0.64000321 0.57999801\n",
            " 0.5699997  0.13000107 0.5        0.13000107 0.38999939 0.45000076\n",
            " 0.11999893 1.18999862 1.63000107 0.40000153 0.15000153 0.43999862\n",
            " 0.54999924 0.04000092 0.73999786 0.45000076 0.25       0.06000137\n",
            " 0.27000046 0.06000138 0.20999908 0.01000214 0.18999863 0.08000183\n",
            " 0.27999877 0.32999801 0.41000366 0.23999786 0.56000137 0.25\n",
            " 0.08000183 0.54000092 0.93999862 0.03000259 0.27999877 0.09000015\n",
            " 0.29999924 0.15999985 0.25       0.00999832 0.15999985 0.43000031\n",
            " 0.25999832 0.04000091 0.00999832 0.66000366 0.27000046 0.18000031\n",
            " 0.54000091 0.30999756 0.5300026  0.16999816 0.22999955 1.10000229\n",
            " 0.59999847 0.11000061 0.09000015 0.41999817 0.30999755 0.63999939\n",
            " 0.15999985 0.05000305 0.11000061 0.24000168 0.77999878 0.44000244\n",
            " 2.82999802 0.56000137 0.27000046 0.20999909 0.27000045 0.30999756\n",
            " 0.29999923 0.02000046 0.04999924 0.91999817 0.04000091 0.18999862\n",
            " 0.04999923 0.19000245 0.09999847 0.12999725 0.29000092 0.61000061\n",
            " 0.04000091 0.18000031 0.20000077 0.09000015 0.00999832 1.34999847\n",
            " 0.0699997  0.47999954 0.22000122 0.22999954 0.00999832]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[mask & (low_diff < 0), 'gel_red_value'] = abs(low_diff)\n",
            "ERROR:GetSets:Error looking up parent data for column open: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:Error mapping parent data: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:Error in process_calculations: Length of values (48) does not match length of index (47)\n",
            "ERROR:GetSets:DataFrame info: None\n",
            "ERROR:GetSets:Error processing file /content/input/AFL_D_1.csv: Length of values (48) does not match length of index (47)\n",
            "ERROR:root:Error processing /content/input/AFL_D_1.csv: Length of values (48) does not match length of index (47)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 1015, in main\n",
            "    processor.process_file(file_path)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 70, in process_file\n",
            "    child_df = self._process_child_calculations(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 158, in _process_child_calculations\n",
            "    return child_processor.process_calculations(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 303, in process_calculations\n",
            "    df = self._map_parent_data(df, parent_df)\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 378, in _map_parent_data\n",
            "    df['parent_open'] = self._lookup_parent_data(df, parent_df, 'open')\n",
            "  File \"<ipython-input-25-3de07a088b74>\", line 430, in _lookup_parent_data\n",
            "    lookup = pd.Series(index=parent_dates, data=parent_df[column].values)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\", line 575, in __init__\n",
            "    com.require_length_match(data, index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\", line 573, in require_length_match\n",
            "    raise ValueError(\n",
            "ValueError: Length of values (48) does not match length of index (47)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 6540 entries, 1998-12-22 to 2024-12-18\n",
            "Data columns (total 28 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   open            6540 non-null   float64\n",
            " 1   high            6540 non-null   float64\n",
            " 2   low             6540 non-null   float64\n",
            " 3   close           6540 non-null   float64\n",
            " 4   trading_bop     6540 non-null   int64  \n",
            " 5   reu_value       6540 non-null   float64\n",
            " 6   reu_flag        6540 non-null   int64  \n",
            " 7   red_value       6540 non-null   float64\n",
            " 8   red_flag        6540 non-null   int64  \n",
            " 9   re_value        6540 non-null   float64\n",
            " 10  re_flag         6540 non-null   int64  \n",
            " 11  gel_open        6540 non-null   float64\n",
            " 12  gel_high        6540 non-null   float64\n",
            " 13  gel_low         6540 non-null   float64\n",
            " 14  gel_close       6540 non-null   float64\n",
            " 15  gel_range       6540 non-null   float64\n",
            " 16  gel_percent_r   6540 non-null   float64\n",
            " 17  gel_ce_percent  6227 non-null   float64\n",
            " 18  gel_reu_value   6540 non-null   float64\n",
            " 19  gel_red_value   6540 non-null   float64\n",
            " 20  gel_reu_flag    6540 non-null   int64  \n",
            " 21  gel_red_flag    6540 non-null   int64  \n",
            " 22  gel_re_value    6540 non-null   float64\n",
            " 23  gel_epc         6227 non-null   float64\n",
            " 24  gel_epc_dir     6540 non-null   int64  \n",
            " 25  gel_epc_hp      6540 non-null   int64  \n",
            " 26  gel_e1_value    6540 non-null   float64\n",
            " 27  gel_e2_value    6540 non-null   float64\n",
            "dtypes: float64(20), int64(8)\n",
            "memory usage: 1.7 MB\n",
            "Error processing /content/input/XLB_D_1.csv: Length of values (313) does not match length of index (312)\n",
            "\n",
            "Processing file: /content/input/AFL_D_1.csv\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1005 entries, 2016-01-04 to 2019-12-30\n",
            "Data columns (total 28 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   open            1005 non-null   float64\n",
            " 1   high            1005 non-null   float64\n",
            " 2   low             1005 non-null   float64\n",
            " 3   close           1005 non-null   float64\n",
            " 4   trading_bop     1005 non-null   int64  \n",
            " 5   reu_value       1005 non-null   float64\n",
            " 6   reu_flag        1005 non-null   int64  \n",
            " 7   red_value       1005 non-null   float64\n",
            " 8   red_flag        1005 non-null   int64  \n",
            " 9   re_value        1005 non-null   float64\n",
            " 10  re_flag         1005 non-null   int64  \n",
            " 11  gel_open        1005 non-null   float64\n",
            " 12  gel_high        1005 non-null   float64\n",
            " 13  gel_low         1005 non-null   float64\n",
            " 14  gel_close       1005 non-null   float64\n",
            " 15  gel_range       1005 non-null   float64\n",
            " 16  gel_percent_r   1005 non-null   float64\n",
            " 17  gel_ce_percent  957 non-null    float64\n",
            " 18  gel_reu_value   1005 non-null   float64\n",
            " 19  gel_red_value   1005 non-null   float64\n",
            " 20  gel_reu_flag    1005 non-null   int64  \n",
            " 21  gel_red_flag    1005 non-null   int64  \n",
            " 22  gel_re_value    1005 non-null   float64\n",
            " 23  gel_epc         957 non-null    float64\n",
            " 24  gel_epc_dir     1005 non-null   int64  \n",
            " 25  gel_epc_hp      1005 non-null   int64  \n",
            " 26  gel_e1_value    1005 non-null   float64\n",
            " 27  gel_e2_value    1005 non-null   float64\n",
            "dtypes: float64(20), int64(8)\n",
            "memory usage: 260.0 KB\n",
            "Error processing /content/input/AFL_D_1.csv: Length of values (48) does not match length of index (47)\n"
          ]
        }
      ]
    }
  ]
}